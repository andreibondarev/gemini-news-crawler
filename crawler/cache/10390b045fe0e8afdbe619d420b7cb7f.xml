<?xml version="1.0" encoding="UTF-8"?><rss xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" version="2.0" xmlns:cc="http://cyber.law.harvard.edu/rss/creativeCommonsRssModule.html">
    <channel>
        <title><![CDATA[Google Cloud - Community - Medium]]></title>
        <description><![CDATA[A collection of technical articles and blogs published or curated by Google Cloud Developer Advocates. The views expressed are those of the authors and don&#39;t necessarily reflect those of Google. - Medium]]></description>
        <link>https://medium.com/google-cloud?source=rss----e52cf94d98af---4</link>
        <image>
            <url>https://cdn-images-1.medium.com/proxy/1*TGH72Nnw24QL3iV9IOm4VA.png</url>
            <title>Google Cloud - Community - Medium</title>
            <link>https://medium.com/google-cloud?source=rss----e52cf94d98af---4</link>
        </image>
        <generator>Medium</generator>
        <lastBuildDate>Mon, 01 Apr 2024 17:02:53 GMT</lastBuildDate>
        <atom:link href="https://medium.com/feed/google-cloud" rel="self" type="application/rss+xml"/>
        <webMaster><![CDATA[yourfriends@medium.com]]></webMaster>
        <atom:link href="http://medium.superfeedr.com" rel="hub"/>
        <item>
            <title><![CDATA[Design your Landing Zone — Design Considerations Part 4— IaC, GitOps and CI/CD (Google Cloud…]]></title>
            <link>https://medium.com/google-cloud/design-your-landing-zone-design-considerations-part-4-iac-gitops-and-ci-cd-google-cloud-ae3f533c6dbd?source=rss----e52cf94d98af---4</link>
            <guid isPermaLink="false">https://medium.com/p/ae3f533c6dbd</guid>
            <category><![CDATA[gitops]]></category>
            <category><![CDATA[landingzone]]></category>
            <category><![CDATA[infrastructure-as-code]]></category>
            <category><![CDATA[google-cloud-platform]]></category>
            <category><![CDATA[cloud-foundation]]></category>
            <dc:creator><![CDATA[Dazbo (Darren Lester)]]></dc:creator>
            <pubDate>Mon, 01 Apr 2024 11:51:00 GMT</pubDate>
            <atom:updated>2024-04-01T11:54:07.419Z</atom:updated>
            <content:encoded><![CDATA[<h3>Design your Landing Zone — Design Considerations Part 4— IaC, GitOps and CI/CD (Google Cloud Adoption Series)</h3><p>Welcome to LZ Design Considerations Part 4, where we’ll wrap up the Landing Zone Design Considerations. This is part of the <a href="https://medium.com/google-cloud/google-cloud-adoption-for-the-enterprise-from-strategy-to-operation-part-0-overview-9091f5a1ddfc">Google Cloud Adoption and Migration: From Strategy to Operation</a> series.</p><p>Previously, we covered <a href="https://medium.com/google-cloud/design-your-landing-zone-design-considerations-part-3-monitoring-logging-billing-and-7b40189a3c81">LZ design decisions relating to monitoring, logging, billing and labelling</a>. In this part, we’ll focus on all things related to automated infra and application deployment, using IaC, GitOps, and CI/CD.</p><h3>12. IaC, GitOps and CI/CD Strategy</h3><figure><img alt="" src="https://cdn-images-1.medium.com/max/677/1*y6Mt0Sgz5pxQ_nwHTvlN1g.png" /><figcaption>Darren’s quote of the day</figcaption></figure><h4>Principles Recap</h4><p>I recommended a number of principles in a previous article, called <a href="https://medium.com/google-cloud/cloud-adoption-and-cloud-engineering-principles-google-cloud-adoption-part-3-660bdb78cebb">Cloud Adoption and Cloud Consumption Principles</a>. I want to recap a couple here:</p><ul><li><em>Automate deployments and installs</em></li><li><em>Immutable infrastructure</em></li></ul><p>Let me review the rationale for these. In our legacy on-prem world, we had:</p><ul><li>Fewer, larger machines.</li><li>Machines tended to built once, and rarely rebuilt.</li><li>VMs needed to be looked after. They were treated as <em>pets</em>.</li><li>We had limited scale and limited elasticity.</li><li>We had to care about the underlying physical hardware.</li></ul><p>But now, in Cloud:</p><ul><li>We have many, smaller machines.</li><li>VMs, applications and services tend to be rebuilt frequently. It’s more effective to replace poorly services, than to try to fix them. We treat them as <em>cattle</em>.</li><li>Applications are designed to be fault-tolerant.</li><li>We have virtually unlimited scale, and most services are extremely elastic.</li><li>We want services to scale down (or be turned off) when not in use.</li><li>For the most part, we don’t care about the underlying hardware.</li></ul><p>So, we want our LZ to align to these principles. <strong>We need an automated, repeatable way to build immutable, replaceable infrastructure.</strong></p><h4>Infrastructure-as-Code (IaC) to the Rescue</h4><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/0*N--Ib58wG_NpNZtm" /><figcaption>IaC, creating infra resources in the Cloud</figcaption></figure><p><strong>IaC is about automated provisioning of infrastructure resources, using code.</strong> It allows us to rapidly provision (and tear down) infrastructure environments in a repeatable, consistent way.</p><p>Some key tenets of IaC:</p><ul><li><strong>All the infrastructure provisioning and dependencies are defined in code</strong>.</li><li>The code should be stored in <strong>source control</strong>, such as GitHub. This way it is managed, versioned, and supports collaboration.</li><li>Our code can be imperative — i.e. follow a set of steps to achieve the outcome. Or our code can be declarative — i.e. <em>“here’s the outcome I need, now you work out how to do it.”</em> <strong>Declarative is best!</strong></li><li>It is easily deployed as part of an automated <strong>CI/CD pipeline</strong>.</li><li>It is <strong>idempotent </strong>— meaning that <strong>we can always repeat</strong> our deployment, regardless of the current state, and end up with the state that we wanted.</li><li>We can use it to <strong>build multiple environments</strong>, and we can be sure they look the same. We can always pass in parameters, to apply environment-specific configuration.</li><li>We can use it to deploy <strong>DR environments on-demand</strong>. (If that is our chosen DR strategy.)</li><li>The code is <strong>self-documenting</strong>. (And supports comments.) This means that an infrastructure engineer can look at our IaC, and understand what it will do. As such, it provides the implementation of our high level design, and eliminates the need for a significant amount of low level design documentation. Why? Because the IaC<em> is the low level design documentation</em>, for the cloud infrastructure.</li><li>It <strong>eliminates configuration drift</strong> — not only between the HLD and the deployed environments, but between the environments themselves.</li><li>It <strong>eliminates human errors</strong>. We don’t have human operators building stuff manually, or tweaking stuff in individual environments.</li></ul><h4>Some Tips and Best Practices for IaC</h4><p>Here’s the thing… If you’re not using IaC, you’re doing Cloud wrong. So here are a few key takeaways:</p><ul><li>For initial resource deployment in a Dev environment, you can provision resources using the Google Cloud Console. But <strong>when you build <em>any </em>cloud infra resources in any other environments (e.g. UAT, OAT, Staging, Prod, whatever), your should be doing so with IaC. </strong>This way, you’re using the same code to deploy to all environments.</li><li>Ensure that your<strong> LZ project factory provides service accounts to your tenants</strong>, and use those service accounts to actually deploy the resources.</li><li><strong>Don’t allow manual (human) infrastructure tweaking in any environments other than Dev.</strong> You can enforce this through policy and IAM. If you allow operators to tweak configuration by hand then you will get configuration drift, and you’ll kill your automation and repeatability benefit.</li><li>If you have any engineers or integrators that say things like, <em>“Let’s just build it manually, and worry about the IaC later”</em> then educate them, or get rid of them. This sort of legacy on-prem thinking kills your cloud agility. I’ve been on projects where system integrators have refused to build the IaC upfront. And the detrimental impact on the project is staggering!</li><li>Create a <strong>CI/CD pipeline</strong> to automate your IaC deployments.</li></ul><h4>The GitOps Approach</h4><p>Building our infrastructure using IaC is a good start. But we need to build a CI/CD pipeline, such that IaC changes can be automatically deployed to our target environment. <strong>Google advocates for the use of GitOps</strong>, which requires that:</p><ul><li>All resources are deployed using <strong>declarative code</strong>.</li><li>Our <strong>code is hosted in a Git repository</strong>.</li><li>All operational changes are made by developers who make a pull request.</li><li>Merging of the pull request results in execution of a build and release pipeline.</li></ul><p>Here’s a sketch of the overall GitOps pipeline, along with some products and tools you might use at each stage:</p><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/1*ANWEEAo6sXrznpDVvMEFAg.png" /><figcaption>GitOps Pipeline</figcaption></figure><p>In the context of deploying cloud infrastructure, our declarative code will be in the form of IaC. Google’s documentation shows this reference example:</p><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/1*9srXojWGJMB5Hm1oMK4lQQ.png" /><figcaption>Google’s reference architecture for GitOps</figcaption></figure><p>In this example:</p><ul><li>Our IaC is written in <strong>Terraform</strong>. Terraform is an open source cloud-agnostic IaC tool that uses a declarative IaC language.</li><li>We use <strong>GitHub </strong>to store our Git repo. (But we could use other Git hosting services like GitLab or BitBucket. If we want to stay fully within the Google Cloud ecosystem, we can also use <a href="http://Google Cloud Source Repositories">Google Cloud Source Repositories</a>, CSR. We can use CSR to host our master Git repos; but we could also synchronise our CSR repos from an upstream repo, like GitHub.)</li><li>Infra developers push IaC changes into a feature branch, triggering <strong>Google Cloud Build </strong>to execute terraform plan. This results in a Terraform manifest, but does not actually apply it. (We could use an alternative tool for executing terraform. For example, if we’re using GitHub for our Git repos, we could use GitHub Actions to trigger terraform.)</li><li>Then the developer raises a <strong>pull request</strong> for the dev branch. When it is <strong>merged</strong>, Cloud Build executes terraform apply, thus deploying our Terraform manifest to the dev environment.</li><li>Once the dev build has been validated, the changes are merged into prod, causing the Terraform manifest to be deployed to the prod environment.</li></ul><h4>Pipeline Layers</h4><p>Google recommends separate pipeline layers, with different teams responsible for each. For example:</p><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/1*e6FxEv3FJai3-WkWf5g9Fw.png" /><figcaption>Pipeline layers</figcaption></figure><p>Here:</p><ul><li>The <strong><em>foundation pipeline</em></strong><em> </em>deploys the foundation resources that make up the LZ. This pipeline will typically be the responsibility of a single <strong>Platform Team</strong>.</li><li>The <strong><em>infrastructure pipeline</em></strong> deploys infrastructure that is used by individual tenants and applications. The pipeline can only be executed by a tenant service account, and this service account can only deploy to resources under this tenant’s folder. Google has example code for creating an application infrastructure pipeline in the GitHub Terraform Example Foundation repo, <a href="https://github.com/terraform-google-modules/terraform-example-foundation/tree/master/4-projects">here</a>.</li><li>The <strong><em>application pipeline</em></strong> deploys application resources, such as images, and GKE application resources.</li></ul><h4>Summary of IaC and GitOps Design Decisions</h4><ul><li><strong>Which IaC tool?</strong> I would recommend Terraform, unless you have a compelling reason not to. Terraform is declarative, open source, is cloud agnostic, and works in the enterprise. It is also Google’s recommended tool for IaC with Google Cloud.</li><li>Assuming you’re using Terraform, <strong>where will you persist your Terraform state? </strong>In the enterprise, you should be storing Terraform state in a remote backend that supports collaborative working, automatic state locking, and granular access control. In the Google Cloud ecosystem, <strong>Google GCS is a great choice</strong>. But other options include Terraform Cloud (Terraform SaaS), and Terraform Enterprise (self-hosted).</li><li><strong>Which source code platform? </strong>E.g. GitHub, GitLab, Google Cloud Source Repos, etc.</li><li><strong>What will be your git branching strategy?</strong> Google recommends having a protected main branch, feature and bug-fix branches, plus a <strong>separate persistent branch for each environment</strong>. This way, changes can be promoted through the environments by merging the changes between the environment branches.</li><li><strong>How will you separate these environments in your IaC repo? </strong>Google recommends using a separate folder in the repo for each environment. Each folder will map to a branch, and each branch will deploy to a specific environment.</li></ul><figure><img alt="" src="https://cdn-images-1.medium.com/max/789/1*CHnBud_J5muryzzRMLm74w.png" /><figcaption>Separating environments in your repo and in branches</figcaption></figure><ul><li><strong>How many environments</strong> will you manage? E.g. dev, uat, staging and prod?</li><li><strong>What Google Cloud resource naming conventions will you adopt?</strong> You need to document your naming standards. But before you invent your own, Google has a set of recommended naming conventions <a href="https://cloud.google.com/architecture/security-foundations/summary#naming-conventions">here</a>.</li></ul><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/1*0DBrkSxFyd3cst32asUw3g.png" /><figcaption>Google’s recommended resource naming conventions</figcaption></figure><ul><li><strong>Will you use IaC to deploy your landing zone?</strong> If so, will you use an existing IaC LZ blueprint, or create your own? Google provides a couple of open source organisation LZ blueprints and implementations which can be used to rapidly <strong>accelerate your LZ deployment</strong>. These are <a href="https://github.com/GoogleCloudPlatform/cloud-foundation-fabric/tree/master/fast">Google Cloud Foundation Fabric FAST</a> and <a href="https://github.com/terraform-google-modules/terraform-example-foundation">Cloud Foundation Toolkit (CFT) Terraform Example Foundation</a>. <strong>Google Cloud Foundation Fabric FAST</strong> is intended to be a pre-composed end-to-end example, which is forked, cloned and modified as required. Whereas <strong>CFT </strong>is intended to be used a library of opinionated Terraform modules which should be composed as required. Google describes the differences between these two approaches <a href="https://github.com/GoogleCloudPlatform/cloud-foundation-fabric/blob/master/FABRIC-AND-CFT.md">here</a>.</li></ul><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/0*wlX4xPvM5yR0TFaQ.png" /><figcaption>Google’s Enterprise LZ IaC Accelerator — Google Cloud Foundation Fabric FAST</figcaption></figure><ul><li><strong>How will you organise and manage access to IaC repos?</strong> Google recommends using the design principle that configurations with different approval and management requirements are separated into different source control repositories. For example, a central platform team may be responsible for the LZ IaC, shared resources, and the <a href="https://github.com/GoogleCloudPlatform/cloud-foundation-fabric/tree/master/modules/project-factory">tenant factory</a>. Whereas application teams may be responsible for all infrastructure resources deployed within their own folders. This approach — making use of <strong>pipeline layers</strong> — is recommended in enterprises, as it delegates control to application teams.</li><li><strong>What CI/CD tools will you use in your GitOps pipeline</strong>. For example, you might choose Google Cloud Build for seamless integration with Google Cloud, if Google Cloud is the only infrastructure target of your IaC. Alternatively, if you’re already using GitHub and want more cloud agnosticity, then GitHub Actions might be a good choice.</li><li><strong>How will tenants execute their IaC?</strong> Best practice is to only allow tenants to execute IaC using provided tenant service accounts.</li><li><strong>IaC standards and best practices?</strong> Establish and document your organisation’s IaC and Terraform standards and best practices. And don’t reinvent the wheel. Google has <a href="https://cloud.google.com/docs/terraform/best-practices-for-terraform">great guidance</a> on this already.</li><li><strong>How will you enforce IaC policies and standards? </strong>Since all your cloud infrastructure will be deployed using IaC, it is important to ensure that the IaC you execute adheres to your organisation’s policies. For example, you might want to prevent deployment of certain resources, enforce use of labels with a limited set of values, or enforce customer-managed encryption keys on GCS buckets. Consider using an automated policy validation tool, such as Hashicorp Sentinel (but only if you’re using a Terraform Cloud or Terraform Enterprise backend), Terratest (which is open source), or Google’s gcloud terraform vet.</li></ul><h3>Wrap-Up</h3><p>After four articles on the topic of Google Cloud LZ design considerations, I think you’ll agree that the design phase is not entirely trivial! There are a lot of considerations, and many implications of your choices!</p><p>In the next part, I’ll show you how to go about making informed decisions. I’ll guide you through the LZ design process, show you how to capture your decisions, and tell you how to get the help you need, so you don’t make any troublesome mistakes!</p><h3>Before You Go</h3><ul><li><strong>Please share</strong> this with anyone that you think will be interested. It might help them, and it really helps me!</li><li>Feel free to <strong>leave a comment</strong> 💬.</li><li><strong>Follow</strong> and <strong>subscribe, </strong>so you don’t miss my content. Go to my <a href="https://medium.com/@derailed.dash">Profile Page</a>, and click on these icons:</li></ul><figure><img alt="" src="https://cdn-images-1.medium.com/max/163/0*fF62z2-FT03ui0O5.png" /><figcaption>Follow and Subscribe</figcaption></figure><h3>Links</h3><ul><li><a href="https://medium.com/google-cloud/landing-zones-on-google-cloud-b42b08e1abaa">Landing Zones on Google Cloud: What It Is, Why You Need One, and How to Create One</a></li><li><a href="https://cloud.google.com/architecture/landing-zones">Landing zone design in Google Cloud</a></li><li><a href="https://cloud.google.com/docs/terraform/resource-management/managing-infrastructure-as-code">Managing infrastructure-as-code with Terraform, Cloud Build, and GitOps</a></li><li><a href="https://cloud.google.com/docs/terraform">Terraform on Google Cloud</a></li><li><a href="https://cloud.google.com/docs/terraform/best-practices-for-terraform">Best practices for Terraform</a></li><li><a href="https://cloud.google.com/build/docs">Google Cloud Build</a></li><li><a href="https://cloud.google.com/architecture/framework/operational-excellence/automate-your-deployments">Automate your deployments</a></li><li><a href="https://cloud.google.com/architecture/security-foundations/deployment-methodology">Deployment methodology</a></li><li><a href="https://cloud.google.com/source-repositories/docs/features">Google Cloud Source Repositories</a></li><li><a href="https://cloud.google.com/docs/terraform/policy-validation">Google Cloud Terraform policy validation with terraform vet</a></li><li><a href="https://cloud.google.com/docs/terraform/policy-validation/create-policy-library">Google Cloud: creating a Terraform policy library</a></li><li><a href="https://cloud.google.com/architecture/security-foundations/summary#naming-conventions">Google Cloud Resource Naming Standards</a></li><li><a href="https://github.com/terraform-google-modules/terraform-example-foundation">Google CFT Terraform Example Foundation</a></li><li><a href="https://github.com/GoogleCloudPlatform/cloud-foundation-fabric/tree/master/fast">Google Cloud Foundation Fabric FAST</a></li><li><a href="https://github.com/GoogleCloudPlatform/cloud-foundation-fabric/blob/master/FABRIC-AND-CFT.md">Cloud Foundation Fabric FAST vs CFT</a></li><li><a href="https://medium.com/google-cloud/resource-factories-a-descriptive-approach-to-terraform-581b3ebb59c">Resource factories</a></li><li><a href="https://github.com/GoogleCloudPlatform/cloud-foundation-fabric/tree/master/blueprints/factories">Resource factories in Cloud Foundation Fabric FAST</a></li><li><a href="https://github.com/GoogleCloudPlatform/cloud-foundation-fabric/tree/master/modules/project-factory">Cloud Foundation Fabric FAST: project and folder factory</a></li><li><a href="https://registry.terraform.io/modules/terraform-google-modules/project-factory/google/latest">Terraform Google Cloud Project-Factory</a></li><li><a href="https://cloud.google.com/architecture/framework">Google Cloud Architecture Framework</a></li><li><a href="https://cloud.google.com/architecture/security-foundations">Enterprise Foundations Blueprint</a></li></ul><h3>Series Navigation</h3><ul><li><a href="https://medium.com/google-cloud/google-cloud-adoption-for-the-enterprise-from-strategy-to-operation-part-0-overview-9091f5a1ddfc">Series overview and structure</a></li><li>Previous: <a href="https://medium.com/google-cloud/design-your-landing-zone-design-considerations-part-3-monitoring-logging-billing-and-7b40189a3c81">Design your Landing Zone — Design Considerations Part 3: Monitoring, Logging, Billing and Labelling</a></li><li>Next: Design your Landing Zone — How To</li></ul><img src="https://medium.com/_/stat?event=post.clientViewed&referrerSource=full_rss&postId=ae3f533c6dbd" width="1" height="1" alt=""><hr><p><a href="https://medium.com/google-cloud/design-your-landing-zone-design-considerations-part-4-iac-gitops-and-ci-cd-google-cloud-ae3f533c6dbd">Design your Landing Zone — Design Considerations Part 4— IaC, GitOps and CI/CD (Google Cloud…</a> was originally published in <a href="https://medium.com/google-cloud">Google Cloud - Community</a> on Medium, where people are continuing the conversation by highlighting and responding to this story.</p>]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Technique for Appending Values to Specific Columns on Google Spreadsheet using Google Apps Script]]></title>
            <link>https://medium.com/google-cloud/technique-for-appending-values-to-specific-columns-on-google-spreadsheet-using-google-apps-script-8fa43d026e1b?source=rss----e52cf94d98af---4</link>
            <guid isPermaLink="false">https://medium.com/p/8fa43d026e1b</guid>
            <category><![CDATA[google-cloud-platform]]></category>
            <category><![CDATA[google-sheets]]></category>
            <category><![CDATA[google-apps-script]]></category>
            <category><![CDATA[google-spreadsheets]]></category>
            <category><![CDATA[gcp-app-dev]]></category>
            <dc:creator><![CDATA[Kanshi Tanaike]]></dc:creator>
            <pubDate>Mon, 01 Apr 2024 05:52:04 GMT</pubDate>
            <atom:updated>2024-04-01T05:52:04.015Z</atom:updated>
            <content:encoded><![CDATA[<figure><img alt="" src="https://cdn-images-1.medium.com/max/1000/0*sqLiSi5cK6pT0Qbx.png" /></figure><h3>Abstract</h3><p>This report addresses the challenge of appending values to specific columns in Google Sheets when columns have uneven last rows. It offers a Google Apps Script solution with a sample script and demonstration image, enabling efficient and flexible data manipulation.</p><h3>Introduction</h3><p>Google Apps Script is a versatile tool that allows for seamless management of various Google Workspace applications, including Docs, Sheets, Slides, Forms, and APIs. Its ability to automate tasks within Google Sheets is particularly powerful.</p><p>There might be a scenario where you need to append values to specific columns in a Google Spreadsheet using Google Apps Script. While the Google Spreadsheet service (SpreadsheetApp) offers the appendRow method of the Sheet class to append values to the sheet, this method isn’t suitable when the last rows of each column differ.</p><p>This report presents a sample script that overcomes this limitation, enabling you to append values to specific columns regardless of their individual last rows. You can refer to the demonstration image at the beginning of the report.</p><h3>Usage</h3><p>In order to test this sample script, please do the following flow.</p><h3>1. Create a Google Spreadsheet</h3><p>Create a new Google Spreadsheet. And, put a sample values like the top demonstration image.</p><p>And, open the script editor.</p><h3>2. Sample script</h3><p>Please copy and paste the following script to the script editor of Spreadsheet. And, please enable Sheets API at Advanced Google services. <a href="https://developers.google.com/apps-script/guides/services/advanced#enable_advanced_services">Ref</a> Sheets API is used for putting the values to each cell.</p><p>In this script, the values of inputValues is appended to “Sheet1”.</p><pre>function myFunction() {<br>  // Sample input values.<br>  const inputValues = {<br>    head1: [&quot;sample1&quot;, &quot;sample1&quot;],<br>    head2: [&quot;sample2&quot;, &quot;sample2&quot;],<br>    head3: [&quot;sample3&quot;, &quot;sample3&quot;, &quot;sample3&quot;],<br>    head4: [&quot;sample4&quot;],<br>    head5: [&quot;sample5&quot;],<br>  };<br><br>  // Retrieve current values from the sheet.<br>  const sheetName = &quot;Sheet1&quot;; // Please set your sheet name.<br>  const ss = SpreadsheetApp.getActiveSpreadsheet();<br>  const sheet = ss.getSheetByName(sheetName);<br>  const currentValues = sheet.getDataRange().getDisplayValues();<br><br>  // Retrieve the last rows of each column.<br>  const transposed = UtlApp.transpose(currentValues);<br>  const lastRowObj = transposed.reduce(<br>    (o, [h, ...v], i) =&gt; (<br>      (o[h] = `${UtlApp.columnIndexToLetter(i)}${<br>        v.flatMap((e, j) =&gt; (e ? [j + 3] : [])).pop() || 2<br>      }`),<br>      o<br>    ),<br>    {}<br>  );<br><br>  // Create a request body for putting values to the sheet.<br>  const data = Object.entries(inputValues).reduce((ar, [k, v]) =&gt; {<br>    if (lastRowObj[k]) {<br>      ar.push({ range: lastRowObj[k], values: v.map((e) =&gt; [e]) });<br>    }<br>    return ar;<br>  }, []);<br><br>  // Put values using Sheets API.<br>  if (data.length == 0) return;<br>  Sheets.Spreadsheets.Values.batchUpdate(<br>    { data, valueInputOption: &quot;USER_ENTERED&quot; },<br>    ss.getId()<br>  );<br>}</pre><h3>3. Testing</h3><p>You can see the input and output situations by this script at the top demonstration image. The values of inputValues are appended. You can see it as the blue background color in the image.</p><h3>References</h3><ul><li><a href="https://developers.google.com/apps-script/reference/spreadsheet/sheet#appendRow(Object)">appendRow(rowContents) of Class Sheet</a></li><li><a href="https://developers.google.com/sheets/api/reference/rest/v4/spreadsheets.values/batchUpdate">Method: spreadsheets.values.batchUpdate</a></li><li>I proposed this method to <a href="https://stackoverflow.com/q/78251515">this thread on Stackoverflow</a> as Python script.</li></ul><img src="https://medium.com/_/stat?event=post.clientViewed&referrerSource=full_rss&postId=8fa43d026e1b" width="1" height="1" alt=""><hr><p><a href="https://medium.com/google-cloud/technique-for-appending-values-to-specific-columns-on-google-spreadsheet-using-google-apps-script-8fa43d026e1b">Technique for Appending Values to Specific Columns on Google Spreadsheet using Google Apps Script</a> was originally published in <a href="https://medium.com/google-cloud">Google Cloud - Community</a> on Medium, where people are continuing the conversation by highlighting and responding to this story.</p>]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Getting Started with Claude 3 on Google Cloud]]></title>
            <link>https://medium.com/google-cloud/claude-3-on-google-cloud-20c65b308f01?source=rss----e52cf94d98af---4</link>
            <guid isPermaLink="false">https://medium.com/p/20c65b308f01</guid>
            <category><![CDATA[anthropic-claude]]></category>
            <category><![CDATA[multimodal]]></category>
            <category><![CDATA[generative-ai]]></category>
            <category><![CDATA[gemini]]></category>
            <category><![CDATA[google-cloud-platform]]></category>
            <dc:creator><![CDATA[Vaibhav Malpani]]></dc:creator>
            <pubDate>Mon, 01 Apr 2024 04:11:36 GMT</pubDate>
            <atom:updated>2024-04-01T04:11:36.635Z</atom:updated>
            <content:encoded><![CDATA[<p>Google Cloud recently announced that <a href="https://www.anthropic.com/news/claude-3-family">Anthropic’s Claude 3 Models</a> will be available on Google Cloud (Sonnet and Haiku for now), and Opus will be added in coming weeks.</p><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/1*GTJap7mGMYHggm-I-NUxnQ.png" /></figure><h3>What is Claude 3?</h3><p>Claude 3 comes with 3 state-of-the-art models: Opus, Sonnet and Haiku.</p><p><strong>Opus:</strong> Excels in complex tasks understanding new situations with impressive human-like ability. It pushes the boundaries of what AI can do.</p><p><strong>Sonnet:</strong> Balances performance and cost, well-suited for businesses needing fast and reliable performance.</p><p><strong>Haiku: </strong>Super fast and small, giving lightning quick answers to questions. This lets you create AI that feels like talking to a real person.</p><h3><strong>Comparison of the Claude 3 models with GPT and Gemini Models.</strong></h3><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/0*DhSMUYbSBL-rnZT0" /></figure><h3><strong>Cost Comparison between 3 Models:</strong></h3><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/0*XhCvOEiuCnbnyUlr" /></figure><h3><strong>How to get started?</strong></h3><ol><li>Go to Model Garden tab in Vertex AI for <a href="https://console.cloud.google.com/vertex-ai/publishers/anthropic/model-garden/claude-3-sonnet">Sonnet</a> or <a href="https://console.cloud.google.com/vertex-ai/publishers/anthropic/model-garden/claude-3-haiku">Haiku</a></li><li>Click on Enable, Fill the basic details about your Organization or just about your self.</li><li>Once Step 2 is done, wait for 2–3 minutes to get the model enabled.</li><li>You can now view the code for interacting with Claude 3 models. It has a lot of examples like Text input, Image input, Streaming responses, Calling via API, Calling via SDK.</li></ol><h3>Steps Interact with Claude 3 using SDK</h3><pre>!pip3 install anthropic[vertex]</pre><pre>MODEL = &quot;claude-3-sonnet@20240229&quot; #for Haiku claude-3-haiku@20240307<br>REGION = &quot;us-central1&quot;<br>PROJECT_ID = &quot;[your-project-id]&quot;<br><br>import vertexai<br>import json<br>vertexai.init(project=PROJECT_ID, location=REGION)</pre><h3>1. Text Input</h3><pre>from anthropic import AnthropicVertex<br><br>client = AnthropicVertex(region=REGION, project_id=PROJECT_ID)<br>message = client.messages.create(<br>    max_tokens=1024,<br>    messages=[<br>        {<br>            &quot;role&quot;: &quot;user&quot;,<br>            &quot;content&quot;: &quot;Send me a recipe for Pizza.&quot;,<br>        }<br>    ],<br>    model=MODEL,<br>)<br>data = json.loads(message.model_dump_json(indent=2))[&quot;content&quot;][0]<br>print(data[&quot;text&quot;])</pre><p><strong>Query: </strong>Send me a recipe for Pizza.</p><p><strong>Response:</strong></p><figure><img alt="" src="https://cdn-images-1.medium.com/max/838/1*fqH4D2F-_EMrsXMk3MSvVw.png" /></figure><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/1*f7E7aEVYYScPmxMKxEhbYQ.png" /></figure><h3>2. Single Image Input</h3><p><strong>Image Used:</strong></p><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/1*lnsWMpIz61oidGEiqgktZg.jpeg" /><figcaption>Image 1</figcaption></figure><pre>import base64<br><br>import httpx<br>from anthropic import AnthropicVertex<br><br>client = AnthropicVertex(region=REGION, project_id=PROJECT_ID)<br><br>image1_url = &quot;https://cache.getarchive.net/Prod/thumb/cdn12/L3Bob3RvLzIwMTYvMTIvMzEvdHJhZmZpYy1qYW0tdHJhZmZpYy1pbmRpYS10cmFuc3BvcnRhdGlvbi10cmFmZmljLTFlNDJiZi0xMDI0LmpwZw%3D%3D/1280/720/jpg&quot;<br>image1_media_type = &quot;image/jpeg&quot;<br>image1_data = base64.b64encode(httpx.get(image1_url).content).decode(&quot;utf-8&quot;)<br><br><br>message = client.messages.create(<br>    max_tokens=1024,<br>    messages=[<br>        {<br>            &quot;role&quot;: &quot;user&quot;,<br>            &quot;content&quot;: [<br>                {<br>                    &quot;type&quot;: &quot;image&quot;,<br>                    &quot;source&quot;: {<br>                        &quot;type&quot;: &quot;base64&quot;,<br>                        &quot;media_type&quot;: image1_media_type,<br>                        &quot;data&quot;: image1_data,<br>                    },<br>                },<br>                {&quot;type&quot;: &quot;text&quot;, &quot;text&quot;: &quot;Describe the image and get the location and weather.&quot;},<br>            ],<br>        }<br>    ],<br>    model=MODEL,<br>)<br>data = json.loads(message.model_dump_json(indent=2))[&quot;content&quot;][0]<br>print(data[&quot;text&quot;])</pre><p><strong>Query: </strong>Describe the image and get the location and weather.</p><p><strong>Response:</strong></p><figure><img alt="" src="https://cdn-images-1.medium.com/max/881/1*TkPjrrUhBYFkrKUlgH2y_Q.png" /></figure><h3>3. Multi Image Input:</h3><p><strong>Images Used:</strong></p><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/0*E2Nc-I6HA6Qyvu1G" /><figcaption>Image 1</figcaption></figure><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/0*YPtg3Jiw3HEx8I88" /><figcaption>Image 2</figcaption></figure><pre>import base64<br><br>import httpx<br>from anthropic import AnthropicVertex<br><br>client = AnthropicVertex(region=REGION, project_id=PROJECT_ID)<br><br>image1_url = &quot;https://parkplus.io/_next/image?url=https%3A%2F%2Fstrapi-file-uploads.s3.ap-south-1.amazonaws.com%2Fopen_top_cars_2da902c4b3.jpg&amp;w=1920&amp;q=75&quot;<br>image2_url = &quot;https://images.pexels.com/photos/3817871/pexels-photo-3817871.jpeg?auto=compress&amp;cs=tinysrgb&amp;w=1260&amp;h=750&amp;dpr=2&quot;<br>image1_media_type = &quot;image/jpeg&quot;<br>image1_data = base64.b64encode(httpx.get(image1_url).content).decode(&quot;utf-8&quot;)<br>image2_data = base64.b64encode(httpx.get(image2_url).content).decode(&quot;utf-8&quot;)<br><br><br>message = client.messages.create(<br>    max_tokens=1024,<br>    messages=[<br>        {<br>            &quot;role&quot;: &quot;user&quot;,<br>            &quot;content&quot;: [<br>                {<br>                    &quot;type&quot;: &quot;image&quot;,<br>                    &quot;source&quot;: {<br>                        &quot;type&quot;: &quot;base64&quot;,<br>                        &quot;media_type&quot;: image1_media_type,<br>                        &quot;data&quot;: image1_data,<br>                    },<br>                },<br>                {<br>                    &quot;type&quot;: &quot;image&quot;,<br>                    &quot;source&quot;: {<br>                        &quot;type&quot;: &quot;base64&quot;,<br>                        &quot;media_type&quot;: image1_media_type,<br>                        &quot;data&quot;: image2_data,<br>                    },<br>                },<br>                {&quot;type&quot;: &quot;text&quot;, &quot;text&quot;: &quot;What are the similarities and differences between these two images&quot;},<br>            ],<br>        }<br>    ],<br>    model=MODEL,<br>)<br>data = json.loads(message.model_dump_json(indent=2))[&quot;content&quot;][0]<br>print(data[&quot;text&quot;])</pre><p><strong>Query: </strong>What are the similarities and differences between these two images</p><p><strong>Response:</strong></p><figure><img alt="" src="https://cdn-images-1.medium.com/max/885/1*ZiFv1QIZDyJcQbCSXyVTaQ.png" /></figure><h3>Conclusion:</h3><p>Claude 3 has Capabilities like:</p><ol><li>Performing complex cognitive tasks.</li><li>Transcribing and analyzing static images.</li><li>Code generation</li><li>Translating between various languages in real-time.</li><li>Offers models with combination of speed and performance depending upon the use case.</li><li>It is Secure, Capable and Reliable.</li></ol><h3>If you liked this post, please Clap for it. Follow me if you want to read more such posts!</h3><h3>Twitter: <a href="https://twitter.com/IVaibhavMalpani">https://twitter.com/IVaibhavMalpani</a><br>LinkedIn: <a href="https://www.linkedin.com/in/ivaibhavmalpani/">https://www.linkedin.com/in/ivaibhavmalpani/</a></h3><img src="https://medium.com/_/stat?event=post.clientViewed&referrerSource=full_rss&postId=20c65b308f01" width="1" height="1" alt=""><hr><p><a href="https://medium.com/google-cloud/claude-3-on-google-cloud-20c65b308f01">Getting Started with Claude 3 on Google Cloud</a> was originally published in <a href="https://medium.com/google-cloud">Google Cloud - Community</a> on Medium, where people are continuing the conversation by highlighting and responding to this story.</p>]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Google Cloud Platform Technology Nuggets — March 16–31, 2024 Edition]]></title>
            <link>https://medium.com/google-cloud/google-cloud-platform-technology-nuggets-march-16-31-2024-edition-beddfd742deb?source=rss----e52cf94d98af---4</link>
            <guid isPermaLink="false">https://medium.com/p/beddfd742deb</guid>
            <category><![CDATA[tech-nuggets]]></category>
            <category><![CDATA[gcp-weekly]]></category>
            <category><![CDATA[google-cloud-platform]]></category>
            <dc:creator><![CDATA[Romin Irani]]></dc:creator>
            <pubDate>Sun, 31 Mar 2024 11:51:20 GMT</pubDate>
            <atom:updated>2024-03-31T11:51:20.433Z</atom:updated>
            <content:encoded><![CDATA[<h3>Google Cloud Platform Technology Nuggets — March 16–31, 2024 Edition</h3><p>Welcome to the March 16–31, 2024 edition of Google Cloud Platform Technology Nuggets.</p><p>Please feel free to give <a href="https://forms.gle/UAsAS7YLxYSBTNBy9">feedback</a> on this issue and share the <a href="https://gcptechnuggets.substack.com/">subscription form</a> with your peers.</p><h3>Google Cloud Next 2024</h3><p>We are less than 10 days away from the biggest Google Cloud Event of the year and the excitement is building up. This year, the event is expected to have a large number of technical sessions, based on the feedback received last year.</p><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/0*QCWF8kgUU95aY0HA.jpg" /></figure><p>Several blog posts have started to highlight key sessions to attend from the respective areas: Networking, Dev Practitioners and more. Even if you are not there at the conference, these posts are good reference points to start building out sessions that you would like to watch once they are posted online.</p><p>Here are some of them:</p><ul><li><strong>Dev Connect at Next ’24</strong>: This is one of the key themes of the conference and the <a href="https://cloud.google.com/blog/topics/google-cloud-next/dev-connect-at-next24">post</a> highlights some specific sessions, areas to hang out with fellow practitioners and this is not just for Google Cloud but how all other services Firebase, Android and more come together.</li><li><strong>Networking Sessions</strong>: 12 must attend networking and network security sessions at Next ’24. Check out the <a href="https://cloud.google.com/blog/products/networking/networking-session-preview-at-next24">post</a>.</li></ul><p>If you are into managing IT, then there is a constant pressure to streamline your infrastructure, manage it seamlessly and keep costs at a minimum. Right, isn’t it? An interesting <a href="https://cloud.google.com/blog/products/compute/breakout-sessions-for-it-pros-at-next24">post</a> highlights top 5 questions IT pros have been asking ranging from reducing costs, evaluating reliability of cloud providers, AI infrastructure, scalability and control requirements and more. The post further highlights the sessions where these questions are likely to get answered. Build out that agenda, I tell you.</p><h3>Infrastructure</h3><p>Forrester Research has recognized Google as a Leader in The Forrester Wave™: AI Infrastructure Solutions, Q1 2024. Google received the highest scores of any vendor evaluated in both Current Offering and Strategy categories in the report. Check out the <a href="https://cloud.google.com/blog/products/infrastructure-modernization/google-named-a-leader-in-the-forrester-wave-ai-infrastructure-solutions-q1-2024">post</a> and download the <a href="https://inthecloud.withgoogle.com/forrester-2024-ai-infra-wave/dl-cd.html?_ga=2.73419927.-428458833.1709094666&amp;_gac=1.195768030.1710843694.CjwKCAjwzN-vBhAkEiwAYiO7oHLj_RGrKSAo4oJDQU2SjU77HFVCySA9Xf8sfel4d3tEe32CenfQghoCEcAQAvD_BwE&amp;_gl=1*1t5omrr*_ga*NDI4NDU4ODMzLjE3MDkwOTQ2NjY.*_ga_WH2QY8WWF5*MTcxMTg3Njc5MS4yLjEuMTcxMTg3OTIwMi4wLjAuMA..">report</a>.</p><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/1*dtl-shtgVZJt9TX7IzHaYw.png" /></figure><p>NVIDIA NeMo is an open-source, end-to-end platform purpose-built for developing custom, enterprise-grade generative AI models. Looking to train models on Google Kubernetes Engine (FGKE) using NVIDIA accelerated computing and NVIDIA NeMo framework? Check out the <a href="https://cloud.google.com/blog/products/compute/gke-and-nvidia-nemo-framework-to-train-generative-ai-models">blog post</a> also discusses a reference architecture that highlights the major components, tools and common services used to train the NeMo large language model using GKE.</p><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/0*zk2fdOnHrZN2_Qj1.png" /></figure><p>Google Cloud VMware Engine is now integrated with Google Cloud NetApp Volumes. This availability enables customers to resize volumes without interruption. Separating out the scaling of compute and storage gives lots of flexiblity and cost control too. Check out the <a href="https://cloud.google.com/blog/products/infrastructure-modernization/google-cloud-netapp-volumes-integrates-with-vmware-engine">post</a> for more details.</p><p>Persistent Disk Asynchronous Replication (PD Async Replication) provides low recovery point objective (RPO) and low recovery time objective (RTO) block storage replication for cross-region active-passive disaster recovery (DR). It is a storage option that provides asynchronous replication of data between two regions. It can be used to manage replication for Compute Engine workloads at the infrastructure-level, instead of the workload-level. Check out the <a href="https://cloud.google.com/blog/products/compute/using-pd-async-replication-for-windows-server-disaster-recovery">blog post</a> with an example of how it works.</p><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/0*iSe8yCNZwpzG6SXr.png" /></figure><h3>Customers</h3><p>VPC service Controls (VPC-SC) is a foundational security control that creates an isolation perimeter around managed cloud resources and networks. Via granular ingress and egress rules, you can selectively approve access across perimeter boundaries and play a key role in preventing data exfiltration. Consider CommerzBank, a leading German bank, that is a trusted partner to approx. 26000 corporate client groups and 11 million private and small business customers. With the shift from IP addresses to API endpoints, a new approach was needed to address data sharing and movement needs. Especially around data sharing, CommerzBank had some clear criteria to evaluate any solution and VPC-SC met all these requirements. Check out the <a href="https://cloud.google.com/blog/topics/customers/how-commerzbank-safeguards-its-data-with-vpc-service-controls">post</a> to learn more.</p><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/0*PsWNx1LNe_XuC3GQ.png" /></figure><p>In another interesting customer case study, consider that of Palo Alto Networks. Their solid growth coupled with mergers and acquisitions had lead to more than 170,000 projects on Google Cloud. They did a large exercise a few years back around labelling that helped that identify the team, owner, cost center and environment for these projects (95% coverage). But the final 5% proved to be a challenge till they achieved that with BigQuery ML, which is the built-in machine learning feature in BigQuery. Check out the <a href="https://cloud.google.com/blog/products/data-analytics/how-palo-alto-networks-uses-bigquery-ml">post</a>.</p><h3>Containers and Kubernetes</h3><p>Managing the growth of your GKE clusters required that you had insights into each specific limits like Nodes per cluster, Noder per node pool, pods per cluster and more. Your task just got easier with the introduction of directly monitoring and setting alerts for crucial scalability limits. Check out the <a href="https://cloud.google.com/blog/products/containers-kubernetes/gke-gets-new-quota-monitoring-feature">post</a> for more details.</p><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/0*8X7HfXAqrPH2RIRz.png" /></figure><p>Ray, an open-source Python framework designed for scaling and distributing AI workloads is gaining widespread acceptance. While you can run Ray deployments on VMs, the traditional challenges that come with running workloads on your own on VMs i.e. resource efficiency and managing infrastructure come up. A suggested alternative is to deploy Ray on GKE with KubeRay, an open-source Kubernetes operator that simplifies Ray deployment and management. Check out this <a href="https://cloud.google.com/blog/products/containers-kubernetes/the-benefits-of-using-gke-for-running-ray-ai-workloads">post</a> that dives into the details on why running Ray on GKE would be the best way for you to go forward.</p><p>Continuing with Ray, are you running Ray on Google Kubernetes Engine (GKE)? Here is an essential blog post to read to run Ray securely on GKE. The post delves into areas that you need to address to harden your Ray installation on GKE and a solid summarization of best practices vis-a-vis Kubernetes and GKE constructs like namespaces, RBAC, NetworkPolicy and more. Safer defaults for running Ray with Kubernetes using KubeRay is a focus area and <a href="https://github.com/GoogleCloudPlatform/ai-on-gke/blob/main/ray-on-gke/README.md">Terraform templates</a> are available to spin up a multi-team environment with sample security configurations.</p><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/0*WY1oRpGnazhikqte.jpg" /></figure><p>The final piece on Ray is that of Kueue, a cloud-native queueing system that provides advanced scheduling for Ray applications on GKE. Check out this <a href="https://cloud.google.com/blog/products/containers-kubernetes/using-kuberay-and-kueue-to-orchestrate-ray-applications-in-gke">blog post</a> that shows how KubeRay and Kueue work together to achieve the same.</p><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/0*q1spCntYfLdXRIC5.png" /></figure><p>Speak of training AI models and the need for NVIDIA GPUs comes up regularly. GKE is probably one of the best choices available to deploy, scale and manage custom ML platforms. In an added boost, GKE can now automatically install NVIDIA GPU drivers. This process was manually done before and the automatic installation now even allows for the drivers to be precompiled for the GKE node, which can reduce the time it takes for GPU nodes to startup. Check out the <a href="https://cloud.google.com/blog/products/containers-kubernetes/gke-can-now-automatically-install-nvidia-gpu-drivers">post</a> for more details.</p><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/0*-IfpWIT5x9drgypU.png" /></figure><p>Stanford’s Brain Inferencing Laboratory explore motor systems neuroscience and neuroengineering applications. The relevant data for their research is obtained from experiments on preclininal models and human clinical studies. This data is handled via a complex platform that they have setup for standardized analyses and adhoc analyses. The components of the architecture include Containers, Git, CI/CD and compute clusters, specifically GKE running in Autopilot mode. Check out the <a href="https://cloud.google.com/blog/products/containers-kubernetes/stanford-team-uses-devops-tools-to-manage-research-data">blog post</a> for more details.</p><figure><img alt="" src="https://cdn-images-1.medium.com/max/512/0*-ez2Hh1aqKPxtFWz.png" /></figure><h3>Identity and Security</h3><p>This edition is heavy with security updates and let’s begin with zero-day vulnerabilities but what does that mean? A zero-day vulnerability is a security flaw in an application or operating system that has not been discovered, and there is no defense or patch for it. Did you know Google’s Threat Analysis Group (TAG) and Mandiant showed 97 zero-day vulnerabilities were exploited in 2023. Is that an improvement over 2022 or 2021. Find about this and more in this <a href="https://cloud.google.com/blog/topics/threat-intelligence/2023-zero-day-trends">post</a>.</p><p>You must have heard about Assured Workloads, which allows companies to run regulated workloads in several Google Cloud’s global regions. Consider the requirement then for your organization to adhere to compliance requirements in more than one geographic region, how do you then use Assured Workloads to create regulatory boundaries using a folder structure? Check out this <a href="https://cloud.google.com/blog/products/identity-security/how-to-set-compliance-controls-for-your-google-cloud-organization">post</a>.</p><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/1*YXPQRu5G853XXc3MRAue6Q.png" /></figure><p>In Google Cloud, we have the Organization resource right at the top in hierarchy. With the creation of this resource, you get access to Organization Policy Service. As part of a new release, a set of organization policies have been released that enforce the need to fix potentially insecure postures. These policies scan across IAM, Storage and Essential Contacts. For e.g. a few of the policies at the IAM level include disabling service account key creation, disabling service account key upload and more. Check out the <a href="https://cloud.google.com/blog/products/identity-security/introducing-stronger-default-org-policies-for-our-customers">post</a> to learn more of these policies that are available to all customers who are creating organization resources and for existing customers, who already have done that, these policies are available with no change required.</p><p>Cloud Armor plays an important role in enabling organizations to create a comprehensive DDOS mitigation strategy for their applications. One of the capabilities that plays a key role is that of rate-limiting via which you can curtail traffic to backend resources based on request volume. Check out this <a href="https://cloud.google.com/blog/products/identity-security/how-to-improve-resilience-to-ddos-attacks-with-cloud-armor-advanced-rate-limiting-capabilities">post</a> that highlights the rate-limiting features of Cloud Armor, the two types of actions available for rate-based rules (Throttle, Rate-based ban), planning your rate limiting deployment and more.</p><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/0*gUDRcmgcFoTaX_s0.png" /></figure><p>Handling sensitive data vis-a-vis security, privacy and compliance is an essential requirement for any application handling customer data. Discovery Service, that is part of Google Cloud’s Sensitive Data Protection helps to identify where Sensitive Data resides, which is the first step. Cloud SQL is now supported by the Discovery Service. Earlier it supported BigQuery and BigLake. Check out the <a href="https://cloud.google.com/blog/products/identity-security/expanding-sensitive-data-protection-to-make-it-easier-to-protect-data-in-cloud-sql">post</a> for more details.</p><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/0*ujrb4T08v6Ekjnth.png" /></figure><p>Software Supply Chain attacks are common and organizations need to bring in strict controls, especially when they modern applications have heavy dependency on open source software. Check out this joint <a href="https://cloud.google.com/blog/products/identity-security/how-to-choose-a-known-trusted-supplier-for-open-source-software">blog post</a> from Citi and Google, on common open source attack vectors and 3 main criteria to evaluate an OSS vendor.</p><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/0*s38cJUiBW3x3vtTq.png" /></figure><p>Security will continue to be a big topic at Cloud Next ’24. The 2nd CISO bulletin for March 2024 drops a hint on key security topics and discussion to expect at the conference. In an earlier edition, we had covered the intersection of Gen AI and Security and the <a href="https://cloud.google.com/blog/products/identity-security/cloud-ciso-perspectives-get-ready-for-next-24-what-you-need-to-know">post</a> seems to point towards that and of course, multiple other security areas that will receive attention during the event. The <a href="https://cloud.google.com/blog/products/identity-security/cloud-ciso-perspectives-easing-the-psychological-burden-of-leadership">first CISO bulletin for March</a> this month, focused on psychological resilience in cybersecurity leadership.</p><p>To end the security updates, a slightly different area this time but nevertheless an important one. Data shows that Knowledge workers spend an average of 63% of their productive time in the browser and nearly half (48%) of all business-critical applications are now browser-based and more. Given this, organizations would be served well to consider an enterprise ready browser like Chrome Enterprise. Check out a recent report by Enterprise Strategy Group, titled “ <a href="https://chromeenterprise.google/esg-security-report-2023/">Assessing Enterprise Browser Market Dynamics: Why Organizations Are Turning to Enterprise Browsers to More Effectively Secure Modern Work Styles,</a>” and the <a href="https://cloud.google.com/blog/products/chrome-enterprise/optimize-security-and-productivity-starting-with-the-browser-insights-from-new-report">blog post</a> for more details.</p><h3>Machine Learning</h3><p>The popular Anthropic’s Claude 3 family of models has started to be available on Vertex AI Model Garden. <a href="https://console.cloud.google.com/vertex-ai/publishers/anthropic/model-garden/claude-3-sonnet">Claude 3 Sonnet</a> and <a href="https://console.cloud.google.com/vertex-ai/publishers/anthropic/model-garden/claude-3-haiku">Claude 3 Haiku</a> are generally available to all customers on Vertex AI. Check out the <a href="https://cloud.google.com/blog/products/ai-machine-learning/anthropics-claude-3-models-go-ga-on-vertex-ai">post</a> on the details and steps to getting started.</p><h3>Storage, Databases and Data Analytics</h3><p>BigQuery’s data processing has been extended to Apache Spark. Now announced is the general availability (GA) of Apache Spark stored procedures in BigQuery. It brings Spark together with BigQuery under a single experience, including management, security and billing. Spark procedures are supported using PySpark, Scala and Java code. Check out the <a href="https://cloud.google.com/blog/products/data-analytics/apache-spark-stored-procedures-in-bigquery-are-ga">post</a> for more details.</p><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/0*Vm0Qlq0bQYYvSr4d.png" /></figure><p>Two new SQL features (windowing and gap filling) are now available in preview in BigQuery that simplify time series analysis. The RANGE data type and supporting functions are also available now to complement the analysis. Check out the <a href="https://cloud.google.com/blog/products/data-analytics/bigquery-sql-gets-time-windowing-and-gap-filling">post</a> for more details.</p><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/1*lNTSQwG_8v4vkUH8KxwS4g.png" /></figure><p>What are Dataflow streaming modes? Do exactly-once and at-least-once-processing mode ring a bell? Both of these modes are supported now and understanding them is key to addressing scenarios that need low latency , overall cost and more. Check out the <a href="https://cloud.google.com/blog/products/data-analytics/dataflow-at-least-once-vs-exactly-once-streaming-modes">post</a> for more details.</p><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/0*7_Uu02LGD0BNaUue.jpg" /></figure><p>High-volume data feeds coming in which need data enrichment to be actionable? A Bigtable and Dataflow combination as illustrated in this blog post can address this requirement. Check out the <a href="https://cloud.google.com/blog/products/data-analytics/enrich-streaming-data-in-bigtable-with-dataflow">post</a>.</p><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/1*kJws2k2KqcFwACgmWuUXwQ.png" /></figure><p>If you’d like to read reports, TechTarget’s Enterprise Strategy Group (ESG) did an extensive study to compare the quantitative and qualitative benefits that organizations can realize with Google Cloud BigQuery when compared with alternative solutions. Download the full report <a href="https://cloud.google.com/resources/esg-ultimate-ai-ready-data-platform?utm_source=cgc-blog&amp;utm_medium=blog&amp;utm_campaign=FY24-Q1-global-ENDM297-website-dl-ultimate-AI-ready-platform-price-performance&amp;utm_content=-&amp;utm_term=-">here</a> and read the post <a href="https://cloud.google.com/blog/products/data-analytics/enterprise-strategy-group-evaluates-bigquery-tco">here</a>.</p><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/0*waJlOLNhrBi4y6hm.png" /></figure><p>Datastream, the change data capture (CDC) service now supports SQL Server data sources. The addition of this support now provides a way to replicate data from a range of relational sources to several Google Cloud services, such as BigQuery, Cloud Storage, AlloyDB, and Spanner. Check out the <a href="https://cloud.google.com/blog/products/databases/datastream-supports-sql-server-sources">post</a> for more details and various possibilities with the new feature.</p><figure><img alt="" src="https://cdn-images-1.medium.com/max/1000/0*-u2LiYhim0jvzlGY.png" /></figure><p>Finally, cross-cloud functionality of BigQuery Omni and data sharing capabilities of Analytics Hub has made possible access to data stored in Salesforce Data Cloud and combine it with data in Google Cloud in a secure and zero ETL fashion. Check out the <a href="https://cloud.google.com/blog/products/data-analytics/salesforce-data-cloud-bidirectional-data-sharing-with-bigquery">post</a> for more details.</p><h3>Developers and Practitioners</h3><p>Cloud Run keeps getting better and better. Now available in preview is volume mounts, which enables access to shared data stored in a local file system, across applications. Check out the <a href="https://cloud.google.com/blog/products/serverless/introducing-cloud-run-volume-mounts">blog post</a> that highlights how to mount volumes using gcloud commands and scenarios (load vector database, serve static website, etc) where this feature is very useful.</p><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/0*LcxXg8osEDKPp06B.png" /></figure><p>If you are using the popular NoSQL database Couchbase, here is an update that you can now integrate the database to the wider range of Google Cloud services via the Couchbase connector inside of Google’s Integration-Platform-as-a-Service (iPass) solution. Check out this post that highlights how you can use this connector include key features, using other Google Cloud services to analyse Couchbase data and more.</p><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/0*W-cOtKp9eiZany07.png" /></figure><h3>Learn Google Cloud</h3><p>If you are taking your first steps with Data on Google Cloud or even otherwise and if PostgreSQL is your database of your choice, you have to choose between Spanner, AlloyDB and Cloud SQL. How do you chose one of these services. Check out this <a href="https://cloud.google.com/blog/products/databases/alloydb-and-spanner-databases-for-startups">post</a>, that focuses on AlloyDB and Spanner and determine if you’d like to chose a specific one or in combination too!</p><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/1*KUgiMJoDPLxLPIoFSJj4IA.png" /></figure><h3>Stay in Touch</h3><p>Have questions, comments, or other feedback on this newsletter? Please send <a href="https://forms.gle/UAsAS7YLxYSBTNBy9">Feedback</a>.</p><p>If any of your peers are interested in receiving this newsletter, send them the <a href="https://gcptechnuggets.substack.com/">Subscribe</a> link.</p><img src="https://medium.com/_/stat?event=post.clientViewed&referrerSource=full_rss&postId=beddfd742deb" width="1" height="1" alt=""><hr><p><a href="https://medium.com/google-cloud/google-cloud-platform-technology-nuggets-march-16-31-2024-edition-beddfd742deb">Google Cloud Platform Technology Nuggets — March 16–31, 2024 Edition</a> was originally published in <a href="https://medium.com/google-cloud">Google Cloud - Community</a> on Medium, where people are continuing the conversation by highlighting and responding to this story.</p>]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[A Visual Remix : Swap Objects with Ease]]></title>
            <link>https://medium.com/google-cloud/a-visual-remix-swap-objects-with-ease-8718b040723c?source=rss----e52cf94d98af---4</link>
            <guid isPermaLink="false">https://medium.com/p/8718b040723c</guid>
            <category><![CDATA[imagen]]></category>
            <category><![CDATA[machine-learning]]></category>
            <category><![CDATA[vertex-ai]]></category>
            <category><![CDATA[generative-ai]]></category>
            <category><![CDATA[google-cloud-platform]]></category>
            <dc:creator><![CDATA[Bhushan Garware]]></dc:creator>
            <pubDate>Sun, 31 Mar 2024 02:52:00 GMT</pubDate>
            <atom:updated>2024-03-31T02:52:00.014Z</atom:updated>
            <content:encoded><![CDATA[<h3>A Visual Remix : Swap Objects with Ease</h3><p>Artificial intelligence (AI) has revolutionized the way we create marketing images. With a simple text prompt, we can generate stunning visuals tailored to our campaigns. Following image, generated using <a href="https://cloud.google.com/vertex-ai/generative-ai/docs/image/quickstart-image-generate-console">ImageGen on Veretx AI</a>, illustrates a sample of marketing image for a targeted campaign.</p><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/1*WJ0fbhfKcffRBx0ptsjA9A.png" /><figcaption>AI Generated Image with Google’s Imagegeneration@005 model from Vertex AI Studio</figcaption></figure><p><strong>The Missing Piece: Real Products</strong></p><p>AI image generators are amazing at producing synthetic images from prompts like “A young woman standing in a gym and holding a ‘Specific Brand ’ sneaker in her hand”. The problem? Even if the brand logo appears correctly, that sneaker may not be an actual, purchasable brand product. These images, while visually appealing, lack the crucial link to real merchandise, making them less useful for personalized marketing campaigns. Techniques like subject tuning are promising but not yet refined enough to consistently produce marketing-grade quality content.</p><p><strong>The Solution: Product Replacement</strong></p><p>What if we could easily replace generic products in AI-generated images with the specific products we want to promote? Imagine you have a stock image of a shoe from a particular brand as shown below-</p><figure><img alt="" src="https://cdn-images-1.medium.com/max/1004/1*ZxaVsfEvp5AtT8RAhz8Pxw.jpeg" /><figcaption>Sample AI generated imaginary product [Replace with your branded product stock image]</figcaption></figure><p><em>We can achieve easy object replacement with out manually drawing any bounding boxes or marking segmentation mask with the help of following steps -</em></p><p>(1) <a href="https://ai.google.dev/?gad_source=1&amp;gclid=CjwKCAjw7-SvBhB6EiwAwYdCAZ_hrzfyMCDhNj_y3_EXPb2nwTbkGBDHvfzvqIA6_Bu2KI0QyIoU9RoCFnQQAvD_BwE">Gemini Model</a>: LLM for understanding the name (subject) of the product to be replaced.</p><p>(2) <a href="https://cloud.google.com/vision?hl=en">Google Cloud Vision API</a>: Object detection to find the subject in the source images</p><p>(3) <a href="https://segment-anything.com/">Segment Anything (SAM) Model</a>: for Image Segmentation</p><p>(4) <a href="https://github.com/huggingface/diffusers">Diffuser Model</a>: for Image Impainting</p><p>Let’s understand each step with some derails below -</p><h4><strong>(1) Gemini for Text processing</strong> :</h4><p>Imaging the end user of your tool with use a simple english command like — replace ‘object name’ in the given image with target. As a first step you need to find which object is to be replaced.</p><h4><strong>(2) Google Cloud Vision API:</strong></h4><p>Use Google Cloud Visio API to detect the desired object in the given image</p><figure><img alt="" src="https://cdn-images-1.medium.com/max/980/1*Pral-XFsh2m95co2Z9gXHA.png" /><figcaption>Object detection using Google Cloud Vision API and segmentation with SAM model</figcaption></figure><h4><strong>(3) Segment Anything (SAM) Model:</strong></h4><p>Once the object is detected from Google Vision API, we use SAM model to segment the object. Perform similar operations on the target images as shown below -</p><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/1*Eas2gVkGfSwZnXui9zOPDA.png" /><figcaption>Auto segmentation using SAM model</figcaption></figure><h4><strong>(4) Diffuser Model:</strong></h4><p>In most of the cases, the object in the AI generated image or in the given input image will be of different shape and size. Hence, if we just resize the target image and superimpose with the given image, it would look like below image</p><figure><img alt="" src="https://cdn-images-1.medium.com/max/990/1*W9QBKCE_1wwmMzRjap5rFQ.png" /><figcaption>Superimposed masked images of the object and the target product</figcaption></figure><p>The black portion in the above image represents the part of the original object where the target image has no appearance. This region need to be filled intelligently. We use image impainting technique using diffusers model to perform the task. Following image shows the final output -</p><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/1*dz9bs5ygWOkOBQ6iDLMpGA.png" /><figcaption>A Visual Remix output</figcaption></figure><p>We can use methods like ‘Haugh Transform’ to calculate the angle of rotation as well. However this method can work only if the desired objects are inclined in the 2D plain. As a future step, we need to incorporate 3D roations.</p><img src="https://medium.com/_/stat?event=post.clientViewed&referrerSource=full_rss&postId=8718b040723c" width="1" height="1" alt=""><hr><p><a href="https://medium.com/google-cloud/a-visual-remix-swap-objects-with-ease-8718b040723c">A Visual Remix : Swap Objects with Ease</a> was originally published in <a href="https://medium.com/google-cloud">Google Cloud - Community</a> on Medium, where people are continuing the conversation by highlighting and responding to this story.</p>]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Analyzing Trends of Google Apps Script from Questions on Stackoverflow using Gemini 1.5 API]]></title>
            <link>https://medium.com/google-cloud/analyzing-trends-of-google-apps-script-from-questions-on-stackoverflow-using-gemini-1-5-api-c6b448e36461?source=rss----e52cf94d98af---4</link>
            <guid isPermaLink="false">https://medium.com/p/c6b448e36461</guid>
            <category><![CDATA[google-cloud-platform]]></category>
            <category><![CDATA[generative-ai]]></category>
            <category><![CDATA[machine-learning]]></category>
            <category><![CDATA[google-apps-script]]></category>
            <category><![CDATA[gemini]]></category>
            <dc:creator><![CDATA[Kanshi Tanaike]]></dc:creator>
            <pubDate>Sun, 31 Mar 2024 02:51:15 GMT</pubDate>
            <atom:updated>2024-03-31T02:51:15.186Z</atom:updated>
            <content:encoded><![CDATA[<figure><img alt="" src="https://cdn-images-1.medium.com/max/1000/0*2828W-RsKQh10X2F.png" /></figure><h3>Abstract</h3><p>A new large language model (LLM) called Gemini with an API is now available, allowing developers to analyze vast amounts of data. This report explores trends in Google Apps Script by using the Gemini 1.5 API to analyze questions on Stack Overflow.</p><h3>Introduction</h3><p>The release of the LLM model Gemini as an API on Vertex AI and Google AI Studio has opened a world of possibilities. <a href="https://deepmind.google/technologies/gemini/#introduction">Ref</a> The Gemini API significantly expands the potential of various scripting languages, paving the way for diverse applications. Additionally, Gemini 1.5 has recently been released in AI Studio. <a href="https://blog.google/technology/ai/google-gemini-next-generation-model-february-2024/#sundar-note">Ref</a> We can expect the Gemini 1.5 API to follow suit soon.</p><p>The difference between Gemini 1.0 and Gemini 1.5 is as following table created by Gemini.</p><iframe src="" width="0" height="0" frameborder="0" scrolling="no"><a href="https://medium.com/media/9bfb36b70efe743ac9169ae744e6fe3e/href">https://medium.com/media/9bfb36b70efe743ac9169ae744e6fe3e/href</a></iframe><p>Given Gemini 1.5’s ability to analyze large data, this report leverages the Gemini 1.5 API to analyze trends in Google Apps Script from the data of questions on Stackoverflow. We achieve this by examining all questions tagged google-apps-script from 2008 to 2024 (only 2024, from January to March 28) on Stack Overflow.</p><h3>Step</h3><p>The steps of this analysis are as follows.</p><h3>1. Retrieve questions from Stackoverflow</h3><figure><img alt="" src="https://cdn-images-1.medium.com/max/889/0*PENJvQbml73daj2L.png" /></figure><p>As the base data of Stackoverflow, I used the data retrieved at “<a href="https://medium.com/google-cloud/trend-of-google-apps-script-tag-on-stackoverflow-2024-584e20fb892c">Trend of google-apps-script Tag on Stackoverflow 2024</a>”. In that report, all questions including a tag google-apps-script from 2008 to 2024 have already been retrieved. The data from January 1, 2024, to March 28, 2024, was retrieved in this report. All data is retrieved by StackExchange API. <a href="https://api.stackexchange.com/docs">Ref</a> This flow can be seen in the above image. As a result, 17 CSV files including the data from Stackoverflow were created. The total number of questions including google-apps-script tag from 2008 to March 28, 2024, on Stackoverflow was 54,135.</p><h3>2. Generate texts for each year</h3><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/0*ldN8YDuXzi6_uqmS.png" /></figure><p>As the next step, each summary is created from the retrieved 17 CSV files using Gemini 1.5 API. Because in the current stage, all 17 CSV data cannot be directly used by one API call. So, I separated them. This flow can be seen in the above image. By this flow, a text file including the summaries of each year was created.</p><h3>3. Generate text from all year</h3><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/0*ZSv82VONRiP7AFS8.png" /></figure><p>As the next step, a summary is created from a text file including summaries from 2008 to 2024. This flow can be seen in the above image. By this flow, the summary of all data from 2008 to 2024 is created.</p><h3>Usage</h3><p>In order to test this script, please do the following steps.</p><h3>1. Create an API key</h3><p>Please access <a href="https://makersuite.google.com/app/apikey">https://makersuite.google.com/app/apikey</a> and create your API key. At that time, please enable Generative Language API at the API console. This API key is used for this sample script.</p><p>This official document can be also seen. <a href="https://ai.google.dev/">Ref</a>.</p><h3>2. Create a Google Apps Script project</h3><p>In this report, Google Apps Script is used. Of course, the method introducing this report can be also used in other languages.</p><p>Please create a standalone Google Apps Script project. Of course, this script can be also used with the container-bound script.</p><p>And, please open the script editor of the Google Apps Script project.</p><h3>3. Base data</h3><p>Here, prepare the data as described in the section “1. Retrieve questions from Stack Overflow.” In this report, we focus on the values of “creation_date,” “title,” “score,” and “tags.” While I initially wanted to include the body of the question, it significantly increased the number of tokens for processing. Therefore, the body was excluded. However, I believe the trend can still be obtained from the remaining values: “creation_date,” “title,” “score,” and “tags.”</p><h3>4. Base script</h3><p>The base script for processing this analysis is as follows. Please copy and paste the following script to the script editor of Google Apps Script and save the script.</p><p>In this script, the model models/gemini-1.5-pro-latest was used for generating texts.</p><pre>/**<br> * Sample script for this report.<br> */<br>class DoGemini {<br>  /**<br>   * @param {Object} object Object using this library.<br>   */<br>  constructor(object = {}) {<br>    const model = &quot;models/gemini-1.5-pro-latest&quot;;<br><br>    this.baseUrl = `https://generativelanguage.googleapis.com/v1beta/${model}`;<br>    this.apiKey = object.apiKey || null;<br>    this.headers = object.apiKey<br>      ? null<br>      : {<br>          authorization: `Bearer ${object.token || ScriptApp.getOAuthToken()}`,<br>        };<br>    this.retry = 5;<br>    this.folderId = object.folderId || &quot;root&quot;;<br><br>    this.object = object;<br>  }<br><br>  /**<br>   * ### Description<br>   * Create summaries for each year of the data.<br>   *<br>   * @returns {String} A file ID of the file including the created summaries.<br>   */<br>  createSummariesOfEachYear() {<br>    const headerText = [&quot;creation_date&quot;, &quot;title&quot;, &quot;score&quot;, &quot;tags&quot;].join(&quot;,&quot;);<br>    const files = DriveApp.getFolderById(this.folderId).getFilesByType(<br>      MimeType.CSV<br>    );<br>    const fileList = [];<br>    while (files.hasNext()) {<br>      const file = files.next();<br>      const csv = file.getBlob().getDataAsString().trim() || &quot;No data.&quot;;<br>      const filename = file.getName();<br>      fileList.push({ filename, csv });<br>    }<br>    if (fileList.length == 0) {<br>      throw new Error(&quot;No CSV files.&quot;);<br>    }<br>    fileList.sort((a, b) =&gt; (a.filename &gt; b.filename ? 1 : -1));<br>    console.log(<br>      `--- File list\n${JSON.stringify(<br>        fileList.map(({ filename }) =&gt; filename),<br>        null,<br>        2<br>      )}`<br>    );<br><br>    const res = fileList.map(({ filename, csv }) =&gt; {<br>      console.log(`Now processing: ${filename}`);<br>      const q = [<br>        `Summary the trend from the following CSV data. The CSV data is questions related to Google Apps Script in Stackoverflow. Namely, summarize the trend of questions on Stackoverflow from CSV data.`,<br>        `Consider the creation date of the first column.`,<br>        `Consider the affection of the advent of AI.`,<br>        `Consider the history of Google Apps Script.`,<br>        `Include a value, that you evaluated the activity level of Google Apps Script between 1 and 100, in the response without overestimating.`,<br>        ``,<br>        `${filename}`,<br>        `The format of CSV data is as follows.`,<br>        ``,<br>        `[Format of CSV data]`,<br>        `Created date of the question, Title of the question, Score of the question, Tags related to the question`,<br>        ``,<br>        `[CSV data]`,<br>        `${headerText}`,<br>        `${csv}`,<br>      ].join(&quot;\n&quot;);<br>      const summary = this.generateContent_(q);<br>      return { filename, ...summary };<br>    });<br>    return DriveApp.getFolderById(this.folderId)<br>      .createFile(&quot;summariesOfEachYear.txt&quot;, JSON.stringify(res))<br>      .getId();<br>  }<br><br>  /**<br>   * ### Description<br>   * Create a summary of all years.<br>   *<br>   * @param {String} fileId File ID including summaries of each year.<br>   * @returns {String} A file ID of the file including the created summary.<br>   */<br>  createSummaryOfAllYears(fileId) {<br>    if (!fileId) {<br>      throw new Error(<br>        &quot;Please set the file ID of the file including summaries of each year.&quot;<br>      );<br>    }<br>    const headerText = [&quot;year&quot;, &quot;summary&quot;].join(&quot;,&quot;);<br>    const data = JSON.parse(<br>      DriveApp.getFileById(fileId).getBlob().getDataAsString()<br>    );<br>    const csv = data.map((e) =&gt; `${e.filename},${e.response}`).join(&quot;\n&quot;);<br><br>    // const csv = data.map(e =&gt; `${e.filename},&#39;${JSON.stringify(e.response).replace(/&#39;/, &quot;\&#39;&quot;)}&#39;`).join(&quot;\n&quot;);<br>    const q = [<br>      `Summary the trend from the following CSV data. The CSV data is the summary of trend of questions related to Google Apps Script in Stackoverflow every year. The summaries were created by Gemini API.`,<br>      `Consider the each year of the first column.`,<br>      `Consider the affection of the advent of AI.`,<br>      `Consider the history of Google Apps Script.`,<br>      `At the last of summary, add all values, that you evaluated the activity level of Google Apps Script between 1 and 100, in the response without overestimating. Output the values as an array. The array format is [[&quot;year&quot;, &quot;activity value&quot;],[&quot;year&quot;, &quot;activity value&quot;],,,].`,<br>      ``,<br>      `The format of CSV data is as follows.`,<br>      ``,<br>      `[Format of CSV data]`,<br>      `year, Summary of trend of questions`,<br>      ``,<br>      `[CSV data]`,<br>      `${headerText}`,<br>      `${csv}`,<br>    ].join(&quot;\n&quot;);<br>    const { response } = this.generateContent_(q);<br>    return DriveApp.getFolderById(this.folderId)<br>      .createFile(&quot;summaryOfAllYears.txt&quot;, response)<br>      .getId();<br>  }<br><br>  /**<br>   * ### Description<br>   * Count tokens of inputted values with Gemini API.<br>   *<br>   * @param {Object} options Object for UrlFetchApp.<br>   * @returns {Object} totalTokens<br>   */<br>  countToken_(options) {<br>    const url =<br>      `${this.baseUrl}:countTokens` +<br>      (this.apiKey ? `?key=${this.apiKey}` : &quot;&quot;);<br>    const res = this.fetch_({ url, ...options });<br>    return JSON.parse(res.getContentText());<br>  }<br><br>  /**<br>   * ### Description<br>   * Generate content with Gemini API.<br>   *<br>   * @param {String} q Text for prompt.<br>   * @returns {UrlFetchApp.HTTPResponse|String[]} Response from API. When pageToken is used, String[] is returned.<br>   */<br>  generateContent_(q) {<br>    const payload = { contents: [{ parts: [{ text: q }], role: &quot;user&quot; }] };<br>    const options = {<br>      payload: JSON.stringify(payload),<br>      contentType: &quot;application/json&quot;,<br>      muteHttpExceptions: true,<br>    };<br>    if (this.headers) {<br>      options.headers = headers;<br>    }<br>    const totalTokens = this.countToken_(options);<br><br>    console.log(totalTokens); // Confirm the total tokens in the log.<br><br>    const url =<br>      `${this.baseUrl}:generateContent` +<br>      (this.apiKey ? `?key=${this.apiKey}` : &quot;&quot;);<br>    const res = this.fetch_({ url, ...options });<br>    const obj = JSON.parse(res.getContentText());<br>    if (<br>      obj.candidates &amp;&amp;<br>      obj.candidates.length &gt; 0 &amp;&amp;<br>      obj.candidates[0].content.parts.length &gt; 0<br>    ) {<br>      return { totalTokens, response: obj.candidates[0].content.parts[0].text };<br>    } else {<br>      this.retry--;<br>      console.warn(&quot;No response. Retry again.&quot;);<br>      if (this.retry &gt; 0) {<br>        this.generateContent_(q);<br>      } else {<br>        console.error(&quot;No response.&quot;);<br>      }<br>    }<br>  }<br><br>  /**<br>   * ### Description<br>   * Request Gemini API.<br>   *<br>   * @param {Object} obj Object for using UrlFetchApp.fetchAll.<br>   * @returns {UrlFetchApp.HTTPResponse} Response from API.<br>   */<br>  fetch_(obj) {<br>    obj.muteHttpExceptions = true;<br>    const res = UrlFetchApp.fetchAll([obj])[0];<br>    if (res.getResponseCode() != 200) {<br>      throw new Error(res.getContentText());<br>    }<br>    return res;<br>  }<br>}</pre><h3>5. Script for “Generate texts for each year”</h3><p>This script creates a text file including summaries from 2008 to 2024. The file is created in the same folder as the CSV files. Of course, you can also see each summary from the file.</p><pre>function process1() {<br>  const apiKey = &quot;###&quot;; // Please set your API key.<br><br>  const object = {<br>    apiKey,<br>    folderId: &quot;###&quot;, // Please set the folder ID of the folder including 17 CSV files including data from Stackoverflow.<br>  };<br>  const dg = new DoGemini(object);<br>  const res = dg.createSummariesOfEachYear();<br>  console.log(res);<br>}</pre><p>When this script is run, the number of tokens for each year can be seen at the following chart.</p><figure><img alt="" src="https://cdn-images-1.medium.com/max/981/0*bSWLQd16SvydbZbD.png" /></figure><p>This chart reveals that the number of tokens exceeds 32,000 in most years. In this context, the Gemini 1.5 API has proven to be a valuable tool.</p><h3>6. Script for “Generate text from all year”</h3><p>This script creates a text file of a summary of the trend of all questions including a tag google-apps-script posted from 2008 to 2024. In this case, the result file is created in the root folder.</p><pre>function process2() {<br>  const apiKey = &quot;###&quot;; // Please set your API key.<br>  const fileId = &quot;###&quot;; // Please set the file ID of a text file including summaries of each year.<br><br>  const object = { apiKey };<br>  const dg = new DoGemini(object);<br>  const res = dg.createSummaryOfAllYears(fileId);<br>  console.log(res);<br>}</pre><h3>Result</h3><p>When the above scripts are run, the following result is obtained.</p><pre>## Summary of Google Apps Script Activity on Stack Overflow:<br><br>Based on the provided summaries of Google Apps Script questions on Stack Overflow from 2008 to 2024, we can observe the following trends:<br><br>**Early Stage (2008-2009):**<br><br>* Minimal activity as the platform was in its early stages of development and adoption.<br><br>**Growth and Adoption (2010 onwards):**<br><br>* Gradual increase in questions, indicating growing interest and adoption.<br>* Focus on basic functionalities initially, followed by more complex and diverse topics as the platform matured.<br>* Active community participation and knowledge sharing.<br><br>**Impact of AI:**<br><br>* While not explicitly evident in the earlier data, the potential for AI integration with Google Apps Script is recognized and may influence future trends.<br><br>**Activity Level:**<br><br>* Estimated activity level between **60 and 70 out of 100**, indicating a healthy and active community with room for further growth.<br><br>**Specific Observations:**<br><br>* Common topics include:<br>    * Basic syntax and functionality<br>    * Integration with Google Sheets, Forms, and other Google products<br>    * Email automation<br>    * Data manipulation<br>    * Triggering scripts<br>    * Web app development<br>* Recurring challenges faced by users:<br>    * Authorization and permission errors<br>    * Understanding specific methods and syntax<br>    * Debugging scripts<br>    * Optimizing script performance<br><br>**Overall, the data suggests a steady and ongoing interest in Google Apps Script, with a growing user base and increasingly complex use cases. While AI integration is not yet a dominant theme, it has the potential to influence future trends and applications.**<br><br>**Estimated Activity Levels:**<br><br>Based on the analysis of each year&#39;s data, here&#39;s an array summarizing the estimated activity levels of Google Apps Script on Stack Overflow:<br><br>```<br>[<br>  [&quot;2008-2009&quot;, 10], // Estimated low activity due to early stage<br>  [&quot;2010-2011&quot;, 30], // Moderate activity during early growth<br>  [&quot;2011-2012&quot;, 60], // Increasing activity and diversification of topics<br>  [&quot;2012-2013&quot;, 60], // Steady growth and expanding capabilities<br>  [&quot;2013-2014&quot;, 60], // Moderately active and engaged community<br>  [&quot;2014-2015&quot;, 65], // Consistent activity with focus on both basic and advanced functionalities<br>  [&quot;2015-2016&quot;, 75], // Healthy and active community, diverse topics covered<br>  [&quot;2016-2017&quot;, 70], // Consistent activity, focus on integrations and web app development<br>  [&quot;2017-2018&quot;, 70], // Steady interest, diverse use cases, and demand for advanced functionalities<br>  [&quot;2018-2019&quot;, 65], // Consistent activity, potential for future AI integration<br>  [&quot;2019-2020&quot;, 65], // Sustained interest, potential influence of AI in automation<br>  [&quot;2020-2021&quot;, 65], // Consistent activity, continued relevance and adoption<br>  [&quot;2021-2022&quot;, 75], // Vibrant and active community, growing adoption and complex use cases<br>  [&quot;2022-2023&quot;, 75], // Consistent activity, potential for AI integration in specific areas<br>  [&quot;2023-2024&quot;, 65], // Steady interest, focus on basic functionalities and integrations<br>]<br>```<br><br>**Note:** These activity levels are estimations based on the provided data and general knowledge of Google Apps Script&#39;s adoption and development. A more precise assessment would require access to a larger dataset and more detailed information about question topics and user engagement.</pre><p>When the activity level is evaluated by Gemini 1.5 API for each year is exported as a chart, it becomes as follows.</p><figure><img alt="" src="https://cdn-images-1.medium.com/max/981/0*Y_vIz1H0Xoz6yVBb.png" /></figure><p>The above results confirm various insights about the trend of Google Apps Script on Stack Overflow. Additionally, the Gemini 1.5 API emerged as a valuable tool for data analysis.</p><h3>Note</h3><ul><li>The top illustration was created by <a href="https://gemini.google.com/">Gemini</a> with giving the abstract.</li></ul><img src="https://medium.com/_/stat?event=post.clientViewed&referrerSource=full_rss&postId=c6b448e36461" width="1" height="1" alt=""><hr><p><a href="https://medium.com/google-cloud/analyzing-trends-of-google-apps-script-from-questions-on-stackoverflow-using-gemini-1-5-api-c6b448e36461">Analyzing Trends of Google Apps Script from Questions on Stackoverflow using Gemini 1.5 API</a> was originally published in <a href="https://medium.com/google-cloud">Google Cloud - Community</a> on Medium, where people are continuing the conversation by highlighting and responding to this story.</p>]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Generating Texts using Files Uploaded by Gemini 1.5 API]]></title>
            <link>https://medium.com/google-cloud/generating-texts-using-files-uploaded-by-gemini-1-5-api-5777f1c902ab?source=rss----e52cf94d98af---4</link>
            <guid isPermaLink="false">https://medium.com/p/5777f1c902ab</guid>
            <category><![CDATA[gemini]]></category>
            <category><![CDATA[google-apps-script]]></category>
            <category><![CDATA[generative-ai]]></category>
            <category><![CDATA[google-cloud-platform]]></category>
            <category><![CDATA[machine-learning]]></category>
            <dc:creator><![CDATA[Kanshi Tanaike]]></dc:creator>
            <pubDate>Sun, 31 Mar 2024 02:50:43 GMT</pubDate>
            <atom:updated>2024-03-31T02:50:43.081Z</atom:updated>
            <content:encoded><![CDATA[<figure><img alt="" src="https://cdn-images-1.medium.com/max/1000/0*4xCKDkXmAXkIXMbs.png" /></figure><h3>Abstract</h3><p>The Gemini API allows the generating of text from uploaded files using Google Apps Script. It expands the potential of various scripting languages for diverse applications.</p><h3>Introduction</h3><p>With the release of the LLM model Gemini as an API on Vertex AI and Google AI Studio, a world of possibilities has opened up. <a href="https://deepmind.google/technologies/gemini/#introduction">Ref</a> The Gemini API significantly expands the potential of various scripting languages and paves the way for diverse applications. Also, recently, Gemini 1.5 in AI Studio has been released. <a href="https://blog.google/technology/ai/google-gemini-next-generation-model-february-2024/#sundar-note">Ref</a> In the near future, Gemini 1.5 API will be also released soon.</p><p>Recently, the files got to be able to be uploaded with Gemini API. <a href="https://ai.google.dev/api/rest/v1beta/files">Ref1</a> and <a href="https://ai.google.dev/api/rest/v1beta/media">Ref2</a> When this is used, the text is generated using the uploaded files. This report introduces the sample scripts for uploading the files and generating the texts using Google Apps Script.</p><h3>Usage</h3><p>In order to test this script, please do the following steps.</p><h3>1. Create an API key</h3><p>Please access <a href="https://makersuite.google.com/app/apikey">https://makersuite.google.com/app/apikey</a> and create your API key. At that time, please enable Generative Language API at the API console. This API key is used for this sample script.</p><p>This official document can be also seen. <a href="https://ai.google.dev/">Ref</a>.</p><h3>2. Create a Google Apps Script project</h3><p>In this report, Google Apps Script is used. Of course, the method introducing this report can be also used in other languages.</p><p>Please create a standalone Google Apps Script project. Of course, this script can be also used with the container-bound script.</p><p>And, please open the script editor of the Google Apps Script project.</p><h3>3. Steps of script</h3><p>Here, it introduces the following 4 sample scripts.</p><ol><li>Upload a file with <a href="https://ai.google.dev/api/rest/v1beta/media">“Method: files.list”</a>.</li><li>Confirm the uploaded file with <a href="https://ai.google.dev/api/rest/v1beta/files">“Method: media.upload”</a>.</li><li>Generate content using the uploaded file with <a href="https://ai.google.dev/api/rest/v1beta/models/generateContent">“Method: models.generateContent”</a>.</li><li>Delete the uploaded file with <a href="https://ai.google.dev/api/rest/v1beta/files/delete">“Method: files.delete”</a>.</li></ol><p>Limitation of the uploaded file <a href="https://github.com/google-gemini/gemini-api-cookbook/blob/main/preview/file-api/File_API.ipynb">Ref</a></p><blockquote><em>Can only be used with model.generateContent or model.streamGenerateContent Automatic file deletion after 2 days Maximum 2GB per file, 20GB limit per project No downloads allowed</em></blockquote><h3>4. Script</h3><h3>Upload a file</h3><p>You can see the official document at <a href="https://ai.google.dev/api/rest/v1beta/media/upload">Method: media.upload</a>. The sample script of Google Apps Script is as follows.</p><p>Please set your API key and the file ID of the image file. Here, PNG image is used.</p><pre>function sample1() {<br>  const apiKey = &quot;###&quot;; // Please set your API key.<br>  const fileId = &quot;###&quot;; // Please set the file ID of the image file. Here, PNG image is used.<br><br>  const url = `https://generativelanguage.googleapis.com/upload/v1beta/files?uploadType=multipart&amp;key=${apiKey}`;<br>  const metadata = {<br>    file: { displayName: DriveApp.getFileById(fileId).getName() },<br>  };<br>  const payload = {<br>    metadata: Utilities.newBlob(JSON.stringify(metadata), &quot;application/json&quot;),<br>    file: UrlFetchApp.fetch(<br>      `https://drive.google.com/thumbnail?sz=w1000&amp;id=${fileId}`,<br>      { headers: { authorization: &quot;Bearer &quot; + ScriptApp.getOAuthToken() } }<br>    ).getBlob(),<br>  };<br>  const options = {<br>    method: &quot;post&quot;,<br>    payload: payload,<br>    muteHttpExceptions: true,<br>  };<br>  const res = UrlFetchApp.fetch(url, options).getContentText();<br>  console.log(res);<br>}</pre><p>When this script is run, the following value is returned.</p><pre>{<br>  &quot;file&quot;: {<br>    &quot;name&quot;: &quot;files/###&quot;,<br>    &quot;displayName&quot;: &quot;###&quot;,<br>    &quot;mimeType&quot;: &quot;image/jpeg&quot;,<br>    &quot;sizeBytes&quot;: &quot;123456&quot;,<br>    &quot;createTime&quot;: &quot;2024-03-30T01:23:00.000000Z&quot;,<br>    &quot;updateTime&quot;: &quot;2024-03-30T01:23:00.000000Z&quot;,<br>    &quot;expirationTime&quot;: &quot;2024-04-01T01:23:00.000000Z&quot;,<br>    &quot;sha256Hash&quot;: &quot;###&quot;,<br>    &quot;uri&quot;: &quot;https://generativelanguage.googleapis.com/v1beta/files/###&quot;<br>  }<br>}</pre><p>The values of mimeType and uri are used with generateContent.</p><p>In this sample, I used uploadType=multipart because of the small size of the image file. If you want to upload a large file, I think that resumable upload can be also used.</p><h3>Get the file list</h3><p>You can see the official document at <a href="https://ai.google.dev/api/rest/v1beta/files/list">Method: files.list</a>. The sample script of Google Apps Script is as follows.</p><p>Please set your API key.</p><pre>function sample2() {<br>  const apiKey = &quot;###&quot;; // Please set your API key.<br><br>  const url = `https://generativelanguage.googleapis.com/v1beta/files?pageSize=100&amp;key=${apiKey}`;<br>  const res = UrlFetchApp.fetch(url);<br>  console.log(res.getContentText());<br>}</pre><p>When this script is run, the following value is returned.</p><pre>{<br>  &quot;files&quot;: [<br>    {<br>      &quot;name&quot;: &quot;files/###&quot;,<br>      &quot;displayName&quot;: &quot;###&quot;,<br>      &quot;mimeType&quot;: &quot;image/jpeg&quot;,<br>      &quot;sizeBytes&quot;: &quot;123456&quot;,<br>      &quot;createTime&quot;: &quot;2024-03-30T01:23:00.000000Z&quot;,<br>      &quot;updateTime&quot;: &quot;2024-03-30T01:23:00.000000Z&quot;,<br>      &quot;expirationTime&quot;: &quot;2024-04-01T01:23:00.000000Z&quot;,<br>      &quot;sha256Hash&quot;: &quot;###&quot;,<br>      &quot;uri&quot;: &quot;https://generativelanguage.googleapis.com/v1beta/files/###&quot;<br>    },<br>    ,<br>    ,<br>    ,<br>  ]<br>}</pre><p>When the number of files is more than 100, please retrieve all files using pageToken.</p><h3>Generate content from the uploaded file</h3><p>You can see the official document at <a href="https://ai.google.dev/api/rest/v1beta/models/generateContent">Method: models.generateContent</a>. The sample script of Google Apps Script is as follows.</p><p>Please set your API key, the URI of the uploaded file, and the mimeType of the file.</p><pre>function sample3() {<br>  const apiKey = &quot;###&quot;; // Please set your API key.<br>  const fileUri = &quot;https://generativelanguage.googleapis.com/v1beta/files/###&quot;; // Please set your file uri of the uploaded file.<br>  const mimeType = &quot;image/jpeg&quot;; // Please set the mimeType of the uploaded file.<br><br>  const q = &quot;Describe the image and count apples in the image.&quot;;<br>  const model = &quot;models/gemini-1.5-pro-gf-fc&quot;;<br>  const baseUrl = `https://generativelanguage.googleapis.com/v1beta/${model}`;<br>  const payload = {<br>    contents: [{ parts: [{ text: q }, { fileData: { fileUri, mimeType } }] }],<br>  };<br>  const options = {<br>    payload: JSON.stringify(payload),<br>    contentType: &quot;application/json&quot;,<br>    muteHttpExceptions: true,<br>  };<br>  const res = UrlFetchApp.fetch(<br>    `${baseUrl}:generateContent?key=${apiKey}`,<br>    options<br>  );<br>  console.log(res.getContentText());<br>}</pre><p>In this sample, the following image created by Gemini was uploaded as a sample file and was used.</p><figure><img alt="" src="https://cdn-images-1.medium.com/max/800/0*2K3xjxp7uwYgCx7-.png" /></figure><p>There are 12 apples including 7 red apples, 4 green apples, and 1 yellow apple are shown in the image. This image was generated by Gemini.</p><p>When this script is run, the following generated contents are returned.</p><ul><li>At the model models/gemini-1.0-pro-latest, Image input modality is not enabled for models/gemini-1.0-pro-latest was returned.</li><li>At the model models/gemini-1.0-pro-vision-latest, There are 10 apples in the image. Four red, five green, and one yellow. was returned.</li><li>At the model models/gemini-1.5-pro-latest, The image shows a group of apples on a wooden table. There are red, green, and yellow apples. There are 14 apples in total. was returned.</li><li>At the model models/gemini-1.5-pro-gf-fc, The image shows a group of apples on a wooden table. There are 13 apples in total. The apples are of different colors, including red, green, and yellow. The apples are arranged in a random pattern on the table. The light is coming from the left side of the image, and it is casting shadows on the apples and the table. was returned.</li></ul><h3>Delete the uploaded file</h3><p>You can see the official document at <a href="https://ai.google.dev/api/rest/v1beta/files/delete">Method: files.delete</a>. The sample script of Google Apps Script is as follows.</p><p>Please set your API key and the name of the uploaded file.</p><pre>function sample4() {<br>  const apiKey = &quot;###&quot;; // Please set your API key.<br>  const name = &quot;files/###&quot;; // Please set the name of the uploaded file.<br><br>  const url = `https://generativelanguage.googleapis.com/v1beta/${name}?key=${apiKey}`;<br>  const res = UrlFetchApp.fetch(url, { method: &quot;delete&quot; });<br>  console.log(res.getContentText()); // {}<br>}</pre><p>In this case, an empty object like {} is returned.</p><p>In the current stage, the expiration time of the uploaded file is 2 days. So, the uploaded file is automatically deleted 2 days later.</p><h3>Summary</h3><p>In this report, we present sample scripts for using the Gemini API’s generateContent function with uploaded files. Our findings are as follows:</p><ul><li>Uploading files, retrieving file lists, and deleting files all functioned smoothly using an API key. Also, I heard that at Google APIs, both “snake_case” and “camelCase” within the request body. This was confirmed through testing.</li><li>For generating content from uploaded image files, Gemini 1.5 API models models/gemini-1.5-pro-latest and models/gemini-1.5-pro-gf-fc can be used for image analysis. However, accurately counting objects within the image might still be challenging.</li><li>Currently, uploading text, CSV, and PDF files results in an error message like “Request contains an invalid argument.” It appears that only image and movie files are supported at this stage. We anticipate this limitation to be addressed in a future update.</li></ul><h3>Note</h3><ul><li>The top illustration was created by <a href="https://gemini.google.com/">Gemini</a> with giving the abstract.</li></ul><img src="https://medium.com/_/stat?event=post.clientViewed&referrerSource=full_rss&postId=5777f1c902ab" width="1" height="1" alt=""><hr><p><a href="https://medium.com/google-cloud/generating-texts-using-files-uploaded-by-gemini-1-5-api-5777f1c902ab">Generating Texts using Files Uploaded by Gemini 1.5 API</a> was originally published in <a href="https://medium.com/google-cloud">Google Cloud - Community</a> on Medium, where people are continuing the conversation by highlighting and responding to this story.</p>]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Demystifying Google Cloud Networking for Cloud SQL Setup with IAC — Part II]]></title>
            <link>https://medium.com/google-cloud/demystifying-google-cloud-networking-for-cloud-sql-setup-with-iac-part-ii-ae36432d313b?source=rss----e52cf94d98af---4</link>
            <guid isPermaLink="false">https://medium.com/p/ae36432d313b</guid>
            <category><![CDATA[private-service-connect]]></category>
            <category><![CDATA[infrastructure]]></category>
            <category><![CDATA[google-cloud-platform]]></category>
            <category><![CDATA[terraform]]></category>
            <category><![CDATA[cloud-networking]]></category>
            <dc:creator><![CDATA[paras mamgain]]></dc:creator>
            <pubDate>Sun, 31 Mar 2024 02:50:19 GMT</pubDate>
            <atom:updated>2024-03-31T02:50:19.343Z</atom:updated>
            <content:encoded><![CDATA[<h3><strong>Demystifying Google Cloud Networking for Cloud SQL Setup with IAC — Part II</strong></h3><figure><img alt="" src="https://cdn-images-1.medium.com/proxy/1*O2A2IBNzegsOF79melvcjA.png" /><figcaption>Simplifying Cloud Networking (Private Service Connect) for Cloud SQL</figcaption></figure><p>In our <a href="https://medium.com/google-cloud/demystifying-google-cloud-networking-for-cloud-sql-setup-with-infrastructure-as-code-iac-2873d4068ed8">previous write up</a> we described and shared the IaC code that uses the <a href="https://cloud.google.com/sql/docs/mysql/configure-private-services-access"><strong>Private Service Access (PSA)</strong></a> and its unique ability in google cloud to enable the accessiblity with the managed service using the private IP address of the managed service. <br>This means a client can connect to the managed service wiithout there instance being ever exposed to outside world via public IP address thus providing better and a more granular approach to finetune security.</p><p>In short, private service access enables the client to reach the internal IP address of the google managed service and third part service by using secure and private connections. This becomes very useful when we want to use the private IP address instead of external IP address.</p><p>This article dives into Google Cloud’s Private Service Connect (PSC). We’ll explore the challenges it solves and how terraform can automate infrastructure management for Cloud SQL instance using PSC mode of connectivity.</p><h3>The Problem: Simplify Private Service Connect in Cloud Networking for Cloud SQL instance</h3><p>Configuring Google Cloud networking for Cloud SQL instances can be challenging especially for users who are not familiar with the intricacies of VPCs, subnets, private service connect and firewall rules. To simplify this process, we’ve bundled Terraform modules into a single repository to handle the networking configuration seamlessly.</p><p><strong>e.g.</strong> A VM instance present in our google cloud network can use the internal IP address of the google cloud sql instance instead of its public IP address to establish a private connection using private service connect.</p><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/1*5GI9oZ_Pw_d5gxsIfY6O8w.png" /></figure><p>Private service connect aims to incrementally address secure private connections providing greater flexibility and a centralized way to manage private connections compared to setting up individial VPC peering within cloud environments.</p><p>While PSA (Private Service Access) and PSC (Private Service Connect) are both the functionality that enables safe, secure and private connection to services they differ slightly in there approach.</p><h3>Simplify Private Service Connect (PSC)</h3><p><a href="https://cloud.google.com/vpc/docs/private-service-connect"><strong>Private Service Connect</strong></a> facilitates the private connection between your google cloud VPC and services running in another VPC network by means of creating a dedicated connection which is referred as service attachment. Service attachment then routes the traffic between your VPC and the target service’s VPC.</p><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/1*uxOmjYS1IYT3X8W6dbHZ6A.png" /></figure><h4><strong>Utilizing Private Service Connect (PSC)</strong></h4><p>As an end user, following are the high level overview and essential steps required in the configuration of the private service connect (PSC) :</p><ol><li><strong>Create a Private Connection : </strong>When creating a google cloud service instance supporting private service connect (PSC) like Cloud SQL instance we need to enable/configure the instance to use the PSC. When enabled, the Cloud SQL instance creates a service attachment for the instance automatically. <br>The <strong>service attachment</strong> acts as a point that VPC networks use to access the instance.</li><li><strong>Allowed Private Service Connect projects : </strong>Allowed projects are associated with VPC networks &amp; are associated to each Cloud SQL instance. If an instance isn’t contained in any allowed projects, then you can’t enable Private Service Connect for the instance.</li><li><strong>Configure DNS : </strong>While this is an<strong> optional but still a recommended step</strong> to set up a DNS name like <em>myCloudSQLInstance.myProject</em> which resolves to internal IP address assigned by the PSC endpoint.</li><li><strong>Manage Networking: </strong>The way you set up your network for Cloud SQL depends on where your clients are located.</li></ol><ul><li><strong>Clients on-premises or in another cloud:</strong> If your clients are not within Google Cloud, you’ll need a secure connection like Cloud VPN (HA VPN) or Cloud Interconnect to establish a secure connection between your external network and google cloud network.</li><li><strong>Clients within Google Cloud:</strong> If your clients are in the same Google Cloud project or a different project within the same google cloud organization, a simpler approach using VPC peering between your VPCs can be used for communication.</li></ul><p><strong>5</strong>. <strong>Security and IAM Permissions :</strong> Make sure the necessary the firewalls rules are configured appropriately to allow the client to connect to the instance via its whitelisted ip address &amp; ports along with the necessary IAM permissions to the client so that the user account, service account at the client side is able to establish a client connection.</p><p><strong>e.g.</strong> <em>roles/cloudsql.client</em> permission would be required for the compute service account expecting to establish a connection to cloud sql instance.</p><h3><strong>The Solution: Terraform Modules for Simplifying the configuration and usage of Google Cloud SQL with private service connect</strong></h3><p>The pre-built modules bundle everything you need to connect securely to a private Cloud SQL instance using Private Service Connect. No need to be a cloud networking expert — the modules handle the complexity of setting up Private Service Connect endpoints, service attachments etc. <br>Database administrators and application engineers can easily configure Cloud SQL with the required network components.</p><h3>Supported Usage Scenarios</h3><p>To further assist you in using our simplified networking cloud sql modules, we’ve included multiple examples in the <a href="https://github.com/GoogleCloudPlatform/terraform-google-cloudsqlnetworking/tree/main/examples">examples</a> folder of the github code repository.</p><p>These examples cover different scenarios, complete with implementation guides and architecture designs. Here is a short description about them that you can explore:</p><ol><li><a href="https://github.com/GoogleCloudPlatform/terraform-google-cloudsqlnetworking/blob/main/examples/3.PSC"><strong>PSC Scenario</strong></a><strong> (within same google cloud org) :</strong> This solution guides a user to create a PSC enabled Cloud SQL instance with a consumer and producer project setup having a compute VM instance created in the consumer project connecting to the Cloud SQL instance through PSC service endpoint.</li><li><a href="https://github.com/GoogleCloudPlatform/terraform-google-cloudsqlnetworking/blob/main/examples/4.PSC-Across-VPN"><strong>PSC across VPN Scenario</strong></a><strong> : </strong>This solution helps user with the IaC code to create a HA VPN connection between user and consumer project to connect to a PSC enabled Cloud SQL instance in a producer project from a compute VM instance through PSC service endpoint.</li></ol><p>If you’re ready to supercharge your Google Cloud SQL configuration with private service connect, explore our repository and discover how Terraform modules and the simplified samples can make your life easier. Say goodbye to complex networking configurations and hello to simplified Cloud SQL deployment.</p><p><a href="https://github.com/GoogleCloudPlatform/terraform-google-cloudsqlnetworking/tree/main">Explore the Simplified Cloud Sql Networking Terraform Module Repository</a></p><p>You can also refer to previous write up <a href="https://medium.com/google-cloud/demystifying-google-cloud-networking-for-cloud-sql-setup-with-infrastructure-as-code-iac-2873d4068ed8">Demystifying Google Cloud Networking for Cloud SQL Setup with IAC — Part I</a></p><p>If you have any specific suggestions, scenarios or ideas that you would like to cover then feel free to reach out to us.</p><img src="https://medium.com/_/stat?event=post.clientViewed&referrerSource=full_rss&postId=ae36432d313b" width="1" height="1" alt=""><hr><p><a href="https://medium.com/google-cloud/demystifying-google-cloud-networking-for-cloud-sql-setup-with-iac-part-ii-ae36432d313b">Demystifying Google Cloud Networking for Cloud SQL Setup with IAC — Part II</a> was originally published in <a href="https://medium.com/google-cloud">Google Cloud - Community</a> on Medium, where people are continuing the conversation by highlighting and responding to this story.</p>]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[GKE + Gemma + Ollama: The Power Trio for Flexible LLM Deployment ]]></title>
            <link>https://medium.com/google-cloud/gke-gemma-ollama-the-power-trio-for-flexible-llm-deployment-5f1fa9223477?source=rss----e52cf94d98af---4</link>
            <guid isPermaLink="false">https://medium.com/p/5f1fa9223477</guid>
            <category><![CDATA[llm]]></category>
            <category><![CDATA[google-cloud-platform]]></category>
            <category><![CDATA[kubernetes]]></category>
            <category><![CDATA[gemma]]></category>
            <category><![CDATA[ollama]]></category>
            <dc:creator><![CDATA[Federico Iezzi]]></dc:creator>
            <pubDate>Fri, 29 Mar 2024 03:27:33 GMT</pubDate>
            <atom:updated>2024-03-29T08:13:48.579Z</atom:updated>
            <cc:license>http://creativecommons.org/licenses/by/4.0/</cc:license>
            <content:encoded><![CDATA[<p>In today’s exploration, we delve into the intricacies of deploying a variety of LLMs, focusing particularly on <a href="https://ai.google.dev/gemma/docs">Google</a> <a href="https://huggingface.co/google/gemma-7b">Gemma</a>. The platform of choice will be GKE with invaluable assistance from the <a href="https://github.com/ollama/ollama">Ollama</a> framework. Our journey to achieving this milestone will be facilitated by the <a href="https://github.com/open-webui/open-webui">Open WebUI</a>, which bears a remarkable resemblance to the original OpenAI ChatGPT prompt interface, ensuring a seamless and intuitive user experience.</p><p>Before going into the nitty and gritty details, let’s address the elephant in the room: why pursue this route in the first place? To me, the rationale is crystal clear and can be distilled into several compelling factors:</p><ol><li><strong>Cost-Effectiveness</strong>: Operating LLMs on public cloud infrastructures could potentially offer a more economical solution, especially for smaller organizations or research entities constrained by budgetary limitations. It’s essential, however, to underscore the conditional nature of this benefit, as platforms like Vertex AI Studio and the OpenAI Developer Platform already provide cost-effective, fully flashed, managed services. Vertex AI will also manage life-cycle and observability of your models. Bear that in mind.</li><li><strong>Customization and Flexibility</strong>: Ollama is crafted with customization, flexibility, and open-source principles at its core. Despite the comprehensive model offerings available through cloud providers’ model registries — Google’s one being the <a href="https://cloud.google.com/vertex-ai/generative-ai/docs/model-garden/explore-models">Model Garden that features a more than comprehensive offering</a> — there may be scenarios where a specific model you’re interested in isn’t readily available. This is where Ollama steps in, offering a solution.</li><li><strong>Portability across environments</strong>: Ollama’s design is cloud and platform-agnostic, granting the freedom to deploy it on any private or public platform that accommodates Docker, even on your own laptop. This stands in contrast to other powerful solutions like Vertex AI and SageMaker, which are inherently tied to their respective cloud environments. There is a reason why Docker and Kubernetes took over the entire market. And the very same thing is also valid for x86.</li><li><strong>Privacy and Data Control</strong>: For those inclined towards harnessing fully open-source models, such as 🌋 <a href="https://github.com/haotian-liu/LLaVA">LLaVA</a> and Gemma, within a wholly private framework, this approach offers an optimal path to ensuring data privacy and full control over the deployment environment.</li></ol><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/1*5M-E3pGI5YYeRTXG4rauRQ.png" /></figure><p>∘ <a href="#1234">The GKE Platform</a><br> ∘ <a href="#a10a">Deploying Ollama and Open WebUI (Formerly Ollama WebUI)</a><br> ∘ <a href="#cf41">GPU vs. CPU — a matter of speed</a><br> ∘ <a href="#6f00">Ollama’s Current Limitations: A Deeper Dive</a><br> ∘ <a href="#b26c">Key Takeaways</a></p><h4>The GKE Platform</h4><p>For this experiment, my GKE platform setup prioritized efficiency and performance:</p><ul><li><strong>GKE 1.27 (Regular channel)</strong>: Ensures compatibility and access to recent Google Kubernetes Engine features.</li><li><strong>Container-Optimized OS</strong>: Reduces node startup time for faster workload deployment (<a href="https://medium.com/google-cloud/cut-container-startup-time-for-better-performance-and-costs-part1-02ff48178aff">you can read more on my former article</a>).</li><li>g2-standard-4 <strong>Node Pool (NVIDIA L4 GPU)</strong>: Powerful combination of GPU and CPU resources, ideal for ML tasks. <em>Benchmark results will illustrate the advantages</em>.</li><li><strong>Managed NVIDIA GPU drivers</strong>: Streamlined setup process by integrating drivers directly into GKE, ensuring seamless experience just a flag away gpu-driver-version. <a href="https://cloud.google.com/kubernetes-engine/docs/how-to/gpus#:~:text=DRIVER_VERSION%3A%20the%20NVIDIA%20driver%20version%20to%20install.%20Can%20be%20one%20of%20the%20following%3A">Once the cluster is up it’s also ready to go</a>.</li></ul><p>The <a href="https://www.nvidia.com/en-us/data-center/l4/">NVIDIA L4 GPU</a> pack a punch when it comes to raw specs and results in robust processing capabilities for compute-intensive ML workloads:</p><ul><li>7680 Shader Processors, 240 TMUs, 80 ROPs, 60 RT cores, 240 Tensor Cores.</li><li>24GB GDDR6 memory at 300GB/s bandwidth.</li><li>485 teraFLOPs (FP8 throughput).</li></ul><p><a href="https://cloud.google.com/compute/docs/accelerator-optimized-machines#g2-vms">The G2 Machine Series</a> is the underline platform, based on Intel Cascade Lake and it provides excellent all-around processing to complement the GPU and keep it fed.</p><p>G2 supports <a href="https://cloud.google.com/compute/docs/instances/spot">Spot VM</a>: Offers substantial cost savings (approximately 67% discount) for suitable ML workloads that can tolerate interruptions.</p><h4>Deploying Ollama and Open WebUI (Formerly Ollama WebUI)</h4><p>The K8s ecosystem’s maturity has simplified the deployment process, now essentially a matter of executing helm install and kubectl apply commands. For Ollama, the deployment leverages a community-driven <a href="https://github.com/otwld/ollama-helm">Helm Chart available on GitHub</a>, outlining a canonical values.yaml file to guide the configuration:</p><pre>ollama:<br>  gpu:<br>    enabled: true<br>    type: &#39;nvidia&#39;<br>    number: 1<br>  models:<br>    - gemma:7b<br>    - llava:13b<br>    - llama2:7b<br>persistentVolume:<br>  enabled: true<br>  size: 100Gi<br>  storageClass: &quot;premium-rwo&quot;</pre><p>Conversely, for deploying Open WebUI, the choice veered towards an official Chart and Kustomize template from the community, offering a more fitting approach for this implementation:</p><p><a href="https://github.com/open-webui/open-webui/tree/main/kubernetes/manifest">open-webui/kubernetes/manifest at main · open-webui/open-webui</a></p><p>While Open WebUI offers manifests for Ollama deployment, I preferred the feature richness of the Helm Chart. After deployment, you should be able to access the Open WebUI login screen by navigating to the GCP Load Balancer’s IP address on port 8080.</p><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/1*3NgC2Pj4BjXnbY2hzLCMaA.png" /></figure><p>Simple checks in the ollama namespace should show all systems operational.</p><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/1*RsYpDtZ--YH9DC1pP0N5tg.png" /></figure><p>Let’s tackle a classic science question: Why is the sky blue?</p><figure><img alt="" src="https://cdn-images-1.medium.com/max/694/1*0CM7W3rKWJbuMEGsAGkC5Q.gif" /></figure><p>This is real-time footage — Gemma 7B on the NVIDIA L4 delivers results at lightning speed! Want to try it yourself? Deploying models on Ollama couldn’t be easier: just use ollama run gemma:7b.</p><h4>GPU vs. CPU — a matter of speed</h4><p>Now that the platform is ready to rock, you know I can’t resist a good benchmark session 😉. I ran two types of benchmarks across different models:</p><ul><li>The classic Why is the sky blue? question: Put to Gemma 2B and 7B, as well as LLaMA v1.6 7B and 13B. Gotta test those multimodal and unimodal LLMs!</li><li><a href="https://ollama.com/library/llava#:~:text=of%20the%20picture.-,API%20Usage,-curl%20http%3A//localhost">What’s in this picture?</a> for LLaMA v1.6 7B and 13B: Focusing on image analysis here.</li></ul><p>Don’t worry, I’m not about to start a full-blown LLM showdown — that’s a whole different rabbit hole and way above my understanding. My goal was to track how different machine types impact speed and responsiveness.</p><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/1*Huo2-5vD6eTN6N6uT9qFCQ.png" /><figcaption>Prices comparison for europe-west4 region</figcaption></figure><p>Without GPU acceleration, inference performance depended entirely on raw CPU power and memory bandwidth. Naturally, I deployed Ollama without CPU or memory limits and verified full CPU utilization. However, inference tasks often become bottlenecked by memory bandwidth availability and memory architecture.</p><p>This first graph illustrates several key metrics:</p><ul><li>total duration: How long the model takes to process the input and generate a response.</li><li>response_token/s: A measure of how quickly the model produces output.</li><li>monthly cost: The financial impact of running the chosen configuration for an entire month.</li></ul><figure><img alt="" src="https://cdn-images-1.medium.com/max/778/1*sWBP22YhgTooiCwY1oephw.png" /></figure><p>A lot needs to be unpacked here but I want to start with a warning: the performance numbers you are about to witness are representative just of this specific scenarios. The world of LLM is so vast and fast, that this current picture could be completely irrelevant in a matter of days and even with slightly different scenarios.</p><p><strong>GPU Dominance:</strong></p><ul><li>GPUs deliver drastically lower latency (higher tokens per second) than CPUs. Even 180 dedicated CPU cores at $12k/month can’t compete.</li><li>The NVIDIA L4 offers a 15% speed advantage over the older T4, with a 78% cost increase. Sustained Use Discounts were factored in.</li><li>While the A100 is lightning-fast, about three times faster than L4, its high price and focus on training make it overkill for most inference tasks. Yet it managed to answer in just shy of 3.6 seconds 🤯.</li></ul><p><strong>CPU Struggles:</strong></p><ul><li>Smaller CPUs are undeniably slow and surprisingly expensive.</li><li>Even cost-comparable CPUs (c3-highcpu-22 / c3d-highcpu-16) lag behind the L4 and T4 in throughput.</li><li>The largest CPUs (c3-standard-176 / c3d-standard-360) offer poor performance for their exorbitant cost.</li><li>C3 scale badly, this could be a potential issues with ollama/llama.cpp, my setup, or C3 instance and their lack of vNUMA topology. Regardless, the price makes it pointless.</li></ul><p>Now, looking at an image recognition prompt, this time the model of choice was LLaVA v1.6 with 13B parameters.</p><figure><img alt="" src="https://cdn-images-1.medium.com/max/778/1*QUTVen_J89VgeLOuUKWaEA.png" /></figure><p>The GPU’s performance advantage holds true here as well, demonstrating that CPUs simply can’t compete in this domain. Interestingly, the c3-standard-176 finally outperformed the c3-highcpu-22, which dispels any suspicions of bugs in C3 or my setup.</p><p>As per tradition, all results are publicly available at the following Google Sheet:</p><p><a href="https://docs.google.com/spreadsheets/d/1WUBMBfEtK6TXbo0yTZbjwk-72vvM_S8gsiCNXHf6VUY/edit?usp=sharing">[ollama][medium] - GPU vs. CPU - Mar 28th 2024</a></p><p>Before discussing a few points about Ollama, I’d like to share the exact SHA and tags used in this environment. The AI world is moving so fast that anybody attempting at reproducing my work could discover a different landscape just a few weeks down the road:</p><ul><li>ollama <a href="https://github.com/ollama/ollama/releases/tag/v0.1.29">v0.1.29</a>;</li><li>Gemma 2B SHA b50d6c999e59</li><li>Gemma 7B SHA 430ed3535049</li><li>LLaVA v1.6 7B SHA 8dd30f6b0cb1</li><li>LLaVA v1.6 13B SHA 0d0eb4d7f485</li></ul><p>And on the how the benchmark were executed:</p><pre>curl http://localhost:8080/api/generate -d \<br>&#39;{<br>  &quot;model&quot;: &quot;gemma:7b&quot;,<br>  &quot;prompt&quot;: &quot;Why is the sky blue?&quot;,<br>  &quot;stream&quot;: false,<br>  &quot;options&quot;: {&quot;seed&quot;: 100}<br>}&#39;</pre><pre>curl http://localhost:8080/api/generate -d \<br>&#39;{<br>  &quot;model&quot;: &quot;llava:13b&quot;,<br>  &quot;prompt&quot;:&quot;What is in this picture?&quot;,<br>  &quot;images&quot;: [&quot;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&quot;],<br>  &quot;stream&quot;: false,<br>  &quot;options&quot;: {&quot;seed&quot;: 100}<br>}&#39;</pre><p>As you can see, while recording the results:</p><ul><li>Direct Ollama API communication.</li><li>Streaming disabled.</li><li>Same seed across all prompts.</li></ul><h4>Ollama’s Current Limitations: A Deeper Dive</h4><p>While it’s important to remember that Ollama is a rapidly evolving project, it’s useful to examine some key constraints that power users should be aware of:</p><ul><li><strong>The Repository Bottleneck</strong>: Being locked into <a href="https://github.com/ollama/ollama/blob/v0.1.29/server/modelpath.go#L22">registry.ollama.ai</a> stifles innovation and experimentation. Imagine if Docker had never expanded beyond Quay.io! While a workaround might be possible, a native solution for diverse model sources would be a huge step forward and <a href="https://github.com/ollama/ollama/issues/962">the community has already made a proposal</a>.</li><li><strong>Missed Opportunities with Parallelism</strong>: Ollama’s sequential request handling limits its real-world throughput. Imagine a high-traffic scenario where users experience frustrating delays. The good news is that parallel decoding <a href="https://github.com/ollama/ollama/pull/3348">was merged in </a><a href="https://github.com/ollama/ollama/pull/3348">llama.cpp and pulled in during the v0.1.30</a> cycle — something to keep a close eye on <a href="https://github.com/ollama/ollama/issues/358">is issue #358 open upstream</a>.</li><li><strong>The AVX512 Letdown and an Emerging Option</strong>: It’s disappointing that AVX512 optimizations don’t deliver the expected performance boost in Ollama. <a href="https://github.com/ollama/ollama/issues/2205#issuecomment-2013087742">I even made an attempt at making it better</a> before facing reality: AVX512 sucks, it’s slower than AVX2 😭 (of course the core clock is more than halve), and “<a href="https://www.extremetech.com/computing/312673-linus-torvalds-i-hope-avx512-dies-a-painful-death">I Hope AVX512 Dies a Painful Death</a>”. Intel AMX paints a brighter picture. Its competitive pricing, <a href="https://github.com/ggerganov/llama.cpp/issues/2555">early benchmark results</a>, and the potential to outpace GPUs in certain workloads make it an exciting alternative. On this topic, I strongly encourage a deep look at The Next Platform take on why AI Inference will remain largely on CPUs.</li></ul><p><a href="https://www.nextplatform.com/2023/04/05/why-ai-inference-will-remain-largely-on-the-cpu/">Why AI Inference Will Remain Largely On The CPU</a></p><h4>Key Takeaways</h4><p>Deploying LLMs on GKE with Ollama offers a compelling option for users prioritizing customization, flexibility, potential cost savings, and privacy within their LLM solutions. This approach unlocks the ability to use models unavailable on commercial platforms and provides complete control over the deployment environment. Crucially, GPU acceleration is indispensable for optimal LLM performance, drastically outpacing even powerful CPU-based instances. However, it’s essential to stay mindful of Ollama’s current limitations, such as the registry dependency and sequential request handling, which may impact real-world scenarios. As Ollama continues to evolve, these limitations are likely to be addressed, further enhancing its potential.</p><p><em>I hope you had fun, this was a new journey also for me. If you have any questions, do not hesitate and leave a comment.</em></p><img src="https://medium.com/_/stat?event=post.clientViewed&referrerSource=full_rss&postId=5f1fa9223477" width="1" height="1" alt=""><hr><p><a href="https://medium.com/google-cloud/gke-gemma-ollama-the-power-trio-for-flexible-llm-deployment-5f1fa9223477">GKE + Gemma + Ollama: The Power Trio for Flexible LLM Deployment 🚀</a> was originally published in <a href="https://medium.com/google-cloud">Google Cloud - Community</a> on Medium, where people are continuing the conversation by highlighting and responding to this story.</p>]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Gemini codelab for Java developers using LangChain4j]]></title>
            <link>https://medium.com/google-cloud/gemini-codelab-for-java-developers-using-langchain4j-769fbd419756?source=rss----e52cf94d98af---4</link>
            <guid isPermaLink="false">https://medium.com/p/769fbd419756</guid>
            <category><![CDATA[langchain4j]]></category>
            <category><![CDATA[gemini]]></category>
            <category><![CDATA[google-cloud-platform]]></category>
            <category><![CDATA[gcp-app-dev]]></category>
            <category><![CDATA[java]]></category>
            <dc:creator><![CDATA[Guillaume Laforge]]></dc:creator>
            <pubDate>Fri, 29 Mar 2024 03:27:13 GMT</pubDate>
            <atom:updated>2024-03-29T03:27:13.378Z</atom:updated>
            <content:encoded><![CDATA[<figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/0*f6qD8NYosB2mVZD2.jpg" /></figure><p>No need to be a Python developer to do Generative AI! If you’re a Java developer, you can take advantage of <a href="https://docs.langchain4j.dev/">LangChain4j</a> to implement some advanced LLM integrations in your Java applications. And if you’re interested in using <a href="https://blog.google/technology/ai/google-gemini-next-generation-model-february-2024/">Gemini</a>, one of the best models available, I invite you to have a look at the following “codelab” that I worked on:</p><p><a href="https://codelabs.developers.google.com/codelabs/gemini-java-developers">Codelab — Gemini for Java Developers using LangChain4j</a></p><p>In this workshop, you’ll find various examples covering the following use cases, in <em>crescendo</em> approach:</p><ul><li>Making your fist call to Gemini (streaming &amp; non-streaming)</li><li>Maintaining a conversation</li><li>Taking advantage of multimodality by analysing images with your prompts</li><li>Extracting structured information from unstructured text</li><li>Using prompt templates</li><li>Doing text classification with few-shot prompting</li><li>Implementing Retrieval Augmented Generation to chat with your documentation</li><li>How to do Function Calling to expand the LLM to interact with external APIs and services</li></ul><p>You’ll find all the <a href="https://github.com/glaforge/gemini-workshop-for-java-developers">code samples on Github</a>.</p><p>If you’re attending Devoxx France, be sure to attend the <a href="https://www.devoxx.fr/en/schedule/talk/?id=40285">Hands-on-Lab workshop</a> with my colleagues <a href="https://twitter.com/meteatamel">Mete Atamel</a> and <a href="https://twitter.com/val_deleplace">Valentin Deleplace</a> who will guide you through this codelab.</p><p><em>Originally published at </em><a href="https://glaforge.dev/posts/2024/03/27/gemini-codelab-for-java-developers/"><em>https://glaforge.dev</em></a><em> on March 27, 2024.</em></p><img src="https://medium.com/_/stat?event=post.clientViewed&referrerSource=full_rss&postId=769fbd419756" width="1" height="1" alt=""><hr><p><a href="https://medium.com/google-cloud/gemini-codelab-for-java-developers-using-langchain4j-769fbd419756">Gemini codelab for Java developers using LangChain4j</a> was originally published in <a href="https://medium.com/google-cloud">Google Cloud - Community</a> on Medium, where people are continuing the conversation by highlighting and responding to this story.</p>]]></content:encoded>
        </item>
    </channel>
</rss>