<?xml version="1.0" encoding="UTF-8"?><rss xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" version="2.0" xmlns:cc="http://cyber.law.harvard.edu/rss/creativeCommonsRssModule.html">
    <channel>
        <title><![CDATA[Google Cloud - Community - Medium]]></title>
        <description><![CDATA[A collection of technical articles and blogs published or curated by Google Cloud Developer Advocates. The views expressed are those of the authors and don&#39;t necessarily reflect those of Google. - Medium]]></description>
        <link>https://medium.com/google-cloud?source=rss----e52cf94d98af---4</link>
        <image>
            <url>https://cdn-images-1.medium.com/proxy/1*TGH72Nnw24QL3iV9IOm4VA.png</url>
            <title>Google Cloud - Community - Medium</title>
            <link>https://medium.com/google-cloud?source=rss----e52cf94d98af---4</link>
        </image>
        <generator>Medium</generator>
        <lastBuildDate>Sun, 07 Apr 2024 08:12:04 GMT</lastBuildDate>
        <atom:link href="https://medium.com/feed/google-cloud" rel="self" type="application/rss+xml"/>
        <webMaster><![CDATA[yourfriends@medium.com]]></webMaster>
        <atom:link href="http://medium.superfeedr.com" rel="hub"/>
        <item>
            <title><![CDATA[Recipe Mixer‚Äç]]></title>
            <link>https://medium.com/google-cloud/recipe-mixer-88fe60836e43?source=rss----e52cf94d98af---4</link>
            <guid isPermaLink="false">https://medium.com/p/88fe60836e43</guid>
            <category><![CDATA[generative-ai]]></category>
            <category><![CDATA[google-cloud-platform]]></category>
            <category><![CDATA[llm]]></category>
            <category><![CDATA[genai]]></category>
            <category><![CDATA[geminipro]]></category>
            <dc:creator><![CDATA[Gitesh Mahadik]]></dc:creator>
            <pubDate>Fri, 05 Apr 2024 04:51:23 GMT</pubDate>
            <atom:updated>2024-04-05T04:51:23.558Z</atom:updated>
            <content:encoded><![CDATA[<blockquote>Recipe Mixer is an AI-powered web application that encourages culinary exploration through recipe remixing. Users can input a recipe or list ingredients they have on hand, and the application utilizes the Gemini Pro model to suggest alternative ingredients based on flavor profiles and user preferences, including dietary restrictions.</blockquote><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/1*WztpIzEwXLtIAPHgrdAntA.gif" /></figure><h4>Why use Recipe¬†Mixer?</h4><p>Recipe Mixer is a user-friendly web application that helps you find delicious recipes based on the ingredients you have on hand. Whether you‚Äôre a busy parent, a cooking enthusiast, or someone with dietary restrictions, Recipe Mixer makes meal planning easy and enjoyable.</p><p>All you need to do is input the ingredients you have in your kitchen and specify any dietary preferences you may have, such as vegetarian or gluten-free. Recipe Mixer then suggests personalized recipe options that match your input. It even offers alternative ingredient suggestions and can adapt recipes to different cultural cuisines, so you can explore new flavors and cooking¬†styles.</p><p>With Recipe Mixer, you no longer have to worry about what to cook for dinner or how to use up leftover ingredients. It‚Äôs like having a personal chef at your fingertips, ready to inspire you with creative and delicious meal¬†ideas.</p><h4>Features</h4><ul><li><strong>Ingredient Matching:</strong> Users can input a list of ingredients they have on hand, and the application suggests recipes based on those ingredients.</li><li><strong>Dietary Preferences:</strong> Users can specify dietary preferences such as vegetarian, vegan, or gluten-free, and the suggested recipes take these preferences into¬†account.</li><li><strong>Alternative Ingredient Suggestions:</strong> The application suggests alternative ingredients based on flavor profiles and dietary preferences, allowing users to experiment with different ingredients.</li><li><strong>Cultural Adaptation:</strong> The suggested recipes can be adapted to different cultural cuisines, promoting culinary exploration and diversity.</li></ul><h4>Dependencies</h4><ul><li><strong>Gemini Pro LLM:</strong> Natural language processing model for text classification.</li><li><strong>Streamlit:</strong> Web application framework for building interactive web applications.</li><li><strong>Google Generative AI:</strong> Integrates advanced AI capabilities into the application.</li><li><strong>python-dotenv:</strong> python-dotenv is a Python library that allows you to read environment variables from¬†.env¬†files.</li><li><strong>langchain.llms:</strong> langchain.llms is a library used to interact with language models, particularly for text generation tasks.</li></ul><h4>How it¬†works?</h4><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/1*BcrtnKnVez7YEpYpSjp84g.gif" /></figure><h3>Building Recipe Mixerüßëüèª‚Äçüç≥</h3><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/1*DCwRD0yFB7ylxDsl36BKUQ.gif" /></figure><h4>Requirements:</h4><ul><li>Python 3.10</li><li><a href="https://ai.google.dev/">Gemini Pro API key</a> (Note: Ensure you have the necessary credentials and permissions to access the Gemini Pro¬†API)</li></ul><h4>Steps:</h4><ol><li>Clone the repository</li></ol><pre>git clone https://github.com/Gitesh08/recipe-mixer.git</pre><p>or create <strong>app.py</strong> file and paste below¬†code.</p><pre>import streamlit as st<br>import google.generativeai as genai<br>from dotenv import load_dotenv<br>import os<br><br># Load environment variables from a .env file<br>load_dotenv()<br><br># Configure the generative AI model with the Google API key<br>genai.configure(api_key=os.getenv(&quot;GOOGLE_API_KEY&quot;))<br><br># Set up the model configuration for text generation<br>generation_config = {<br>    &quot;temperature&quot;: 0.4,<br>    &quot;top_p&quot;: 1,<br>    &quot;top_k&quot;: 32,<br>    &quot;max_output_tokens&quot;: 4096,<br>}<br><br>     # Create a GenerativeModel instance with &#39;gemini-pro&#39; as the model type<br>llm = genai.GenerativeModel(<br>    model_name=&quot;gemini-pro&quot;,<br>    generation_config=generation_config,<br>    )<br>    <br>def match_ingredients(user_ingredients, dietary_preferences=None):<br>    &quot;&quot;&quot;<br>    Matches ingredients with recipes using Gemini Pro (if available).<br><br>    Args:<br>        user_ingredients (list): List of user-provided ingredients (lowercase and stripped).<br>        dietary_preferences (str, optional): User&#39;s dietary preferences (e.g., vegetarian, vegan).<br><br>    Returns:<br>        tuple: A tuple containing the recipe name and instructions (if found), otherwise None.<br>    &quot;&quot;&quot;<br>    <br>    prompt_template = &quot;&quot;&quot;Find a delicious recipe using these ingredients: {ingredients}. <br>    {dietary_preferences_prompt}<br>    I want the response in a single structured format.&quot;&quot;&quot;<br><br>    dietary_preferences_prompt = f&quot;Considering dietary restrictions: {dietary_preferences}&quot; if dietary_preferences else &quot;&quot;<br><br>    prompt = prompt_template.format(ingredients=&quot;, &quot;.join(user_ingredients), dietary_preferences_prompt=dietary_preferences_prompt)<br><br>    response = llm.generate_content(prompt)<br><br>  # Parse the response from Gemini Pro to extract the matching recipe name and instructions (implementation depends on API response format)<br>    recipe = response.text<br>  # ... (code to parse response and extract recipe information)<br>    return recipe<br><br>st.set_page_config(page_title=&quot;Recipe Mixer&quot;)<br><br>st.title(&quot;Recipe Mixer&quot; + &quot;:sunglasses:&quot;)<br>st.markdown(&#39;&lt;style&gt;h1{color: orange; text-align: center; font-family:POPPINS}&lt;/style&gt;&#39;, unsafe_allow_html=True)<br><br>st.text(&quot; \n&quot;)<br>st.text(&quot; \n&quot;)<br>st.text(&quot; \n&quot;)<br><br>user_ingred = st.text_input(&quot;Enter your ingredients (comma-separated):&quot;)<br><br># Add dietary preference dropdown<br>dietary_options = st.selectbox(&quot;Dietary Preferences (Optional):&quot;, [None, &quot;Vegetarian&quot;, &quot;Vegan&quot;, &quot;Gluten-Free&quot;])<br><br>submit_button = st.button(&quot;Suggest me recipe&quot;)<br>user_ingredients = user_ingred.split(&quot;, &quot;)<br><br><br>if submit_button:<br>    if user_ingred is not None:<br>    # Preprocess user ingredients<br>        user_ingredients_str = [ingredient.strip().lower() for ingredient in user_ingred.split(&quot;, &quot;)]<br>        <br>        # Call match_ingredients once and assign results<br>        recipe =  match_ingredients(user_ingredients_str, dietary_preferences=dietary_options)<br><br>        if recipe:<br>            complete_recipe = f&quot;\n{recipe}\n&quot;<br>            st.write(complete_recipe.replace(&#39;\\n&#39;, &#39;\n&#39;))<br>        else:<br>            st.write(&quot;No Recipe&quot;)<br>    <br>st.text(&quot; \n&quot;)<br>st.text(&quot; \n&quot;)<br>st.text(&quot; \n&quot;)<br>st.text(&quot; \n&quot;)<br>st.text(&quot; \n&quot;)<br>st.text(&quot; \n&quot;)<br>st.text(&quot; \n&quot;)<br>st.text(&quot; \n&quot;)<br>st.text(&quot; \n&quot;)<br>st.text(&quot; \n&quot;)<br>st.text(&quot; \n&quot;)<br>st.text(&quot; \n&quot;)<br>st.text(&quot; \n&quot;)<br>st.text(&quot; \n&quot;)<br><br>footer=&quot;&quot;&quot;&lt;style&gt;<br>a:link , a:visited{<br>color: yellow;<br>background-color: transparent;<br>text-decoration: underline;<br>}<br><br>a:hover,  a:active {<br>color: red;<br>background-color: transparent;<br>text-decoration: underline;<br>}<br><br>.footer {<br>position: Bottom;<br>left: 0;<br>bottom: 0;<br>width: 100%;<br>background-color: transparent;<br>color: white;<br>text-align: center;<br>}<br>&lt;/style&gt;<br>&lt;div class=&quot;footer&quot;&gt;<br>&lt;p&gt;Developed with ‚ù§ by&lt;a style=&#39;display: block; text-align: center;&#39; href=&quot;https://github.com/Gitesh08&quot; target=&quot;_blank&quot;&gt;Gitesh Mahadik&lt;/a&gt;&lt;/p&gt;<br>&lt;/div&gt;<br>&quot;&quot;&quot;<br>st.markdown(footer,unsafe_allow_html=True)</pre><p>Create file <strong>requirements.txt</strong> and paste below¬†code.</p><pre>streamlit<br>google-generativeai<br>python-dotenv<br>langchain</pre><p>2. Create a Python virtual environment. Open a new terminal of your editor and paste below¬†command.</p><pre>python -m virtualenv .</pre><p>3. Activate virtual environment. Paste below command in terminal.</p><pre>.\scripts\activate</pre><p>4. Install the required dependencies.</p><pre>pip install -r requirements.txt</pre><p>5. Generate Gemini Pro API¬†Key:</p><p><a href="https://ai.google.dev/">Build with the Gemini API | Google AI for Developers</a></p><p>6. Create¬†<strong>.env</strong> file and define your API¬†Key.</p><pre>GOOGLE_API_KEY = &quot;Replace with your API Key&quot;</pre><p>7. Run the application.</p><pre>streamlit run app.py</pre><p>Access the application through your web browser using the provided local¬†address.</p><p><strong>Great! You have successfully built Recipe Mixer using the Gemini Pro LLM¬†model.</strong></p><p><strong>Please give a star to this¬†repo!</strong></p><p><a href="https://github.com/Gitesh08/Recipe-Mixer">GitHub - Gitesh08/Recipe-Mixer</a></p><h4>Usage</h4><ul><li><strong>Input your ingredients:</strong> Enter a list of ingredients you have on hand, separated by¬†commas.</li><li><strong>Specify dietary preferences (optional):</strong> Select your dietary preferences from the dropdown¬†menu.</li><li>Click the <strong>‚ÄúSuggest me recipe‚Äù</strong> button to receive recipe suggestions.</li><li>Explore alternative ingredient suggestions and recipe¬†options.</li><li>Enjoy experimenting with different recipes and ingredients!</li></ul><p><strong>Contributions are welcome! If you have any suggestions, enhancements, or bug fixes, feel free to open an issue or submit a pull¬†request.</strong></p><p>Thank you for reading! I hope you enjoyed this article. If you did, please consider subscribing to my Medium publication. You can also follow me on <a href="https://www.linkedin.com/in/gitesh-mahadik%E2%98%81%EF%B8%8F-7487961a0/">LinkedIn</a> for more¬†updates.</p><p>If you have any questions or feedback, please feel free to leave a comment below. I would love to hear from¬†you!</p><img src="https://medium.com/_/stat?event=post.clientViewed&referrerSource=full_rss&postId=88fe60836e43" width="1" height="1" alt=""><hr><p><a href="https://medium.com/google-cloud/recipe-mixer-88fe60836e43">Recipe Mixerüßëüèª‚Äçüç≥</a> was originally published in <a href="https://medium.com/google-cloud">Google Cloud - Community</a> on Medium, where people are continuing the conversation by highlighting and responding to this story.</p>]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Calling Gemma with Ollama, TestContainers, and LangChain4j]]></title>
            <link>https://medium.com/google-cloud/calling-gemma-with-ollama-testcontainers-and-langchain4j-fbfe220ca715?source=rss----e52cf94d98af---4</link>
            <guid isPermaLink="false">https://medium.com/p/fbfe220ca715</guid>
            <category><![CDATA[gcp-app-dev]]></category>
            <category><![CDATA[ollama]]></category>
            <category><![CDATA[google-cloud-platform]]></category>
            <category><![CDATA[testcontainer]]></category>
            <category><![CDATA[langchain4j]]></category>
            <dc:creator><![CDATA[Guillaume Laforge]]></dc:creator>
            <pubDate>Fri, 05 Apr 2024 04:50:25 GMT</pubDate>
            <atom:updated>2024-04-05T04:50:25.157Z</atom:updated>
            <content:encoded><![CDATA[<figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/0*MaT34TRoitiU1RMM.jpg" /></figure><p>Lately, for my Generative AI powered Java apps, I‚Äôve used the <a href="https://deepmind.google/technologies/gemini/#introduction">Gemini</a> multimodal large language model from Google. But there‚Äôs also <a href="https://blog.google/technology/developers/gemma-open-models/">Gemma</a>, its little sister¬†model.</p><p>Gemma is a family of lightweight, state-of-the-art open models built from the same research and technology used to create the Gemini models. Gemma is available in two sizes: 2B and 7B. Its weights are freely available, and its small size means you can run it on your own, even on your laptop. So I was curious to give it a run with <a href="https://docs.langchain4j.dev/">LangChain4j</a>.</p><h3>How to run¬†Gemma</h3><p>There are many ways to run Gemma: in the cloud, via <a href="https://console.cloud.google.com/vertex-ai/publishers/google/model-garden/335">Vertex AI</a> with a click of a button, or <a href="https://cloud.google.com/kubernetes-engine/docs/tutorials/serve-gemma-gpu-vllm">GKE</a> with some GPUs, but you can also run it locally with <a href="https://github.com/tjake/Jlama">Jlama</a> or <a href="https://github.com/google/gemma.cpp">Gemma.cpp</a>.</p><p>Another good option is to run Gemma with <a href="https://ollama.com/">Ollama</a>, a tool that you install on your machine, and which lets you run small models, like Llama 2, Mistral, and <a href="https://ollama.com/library">many others</a>. They quickly added support for <a href="https://ollama.com/library/gemma">Gemma</a> as¬†well.</p><p>Once installed locally, you can¬†run:</p><pre>ollama run gemma:2b<br>ollama run gemma:7b</pre><p>Cherry on the cake, the <a href="https://glaforge.dev/posts/2024/04/04/calling-gemma-with-ollama-and-testcontainers/">LangChain4j</a> library provides an <a href="https://docs.langchain4j.dev/integrations/language-models/ollama">Ollama module</a>, so you can plug Ollama supported models in your Java applications easily.</p><h3>Containerization</h3><p>After a great discussion with my colleague <a href="https://twitter.com/ddobrin">Dan Dobrin</a> who had worked with Ollama and TestContainers (<a href="https://github.com/GoogleCloudPlatform/serverless-production-readiness-java-gcp/blob/main/sessions/next24/books-genai-vertex-langchain4j/src/test/java/services/OllamaContainerTest.java">#1</a> and<a href="https://github.com/GoogleCloudPlatform/serverless-production-readiness-java-gcp/blob/main/sessions/next24/books-genai-vertex-langchain4j/src/test/java/services/OllamaChatModelTest.java#L37">#2</a>) in his <a href="https://github.com/GoogleCloudPlatform/serverless-production-readiness-java-gcp/tree/main">serverless production readiness workshop</a>, I decided to try the approach¬†below.</p><p>Which brings us to the last piece of the puzzle: Instead of having to install and run Ollama on my computer, I decided to use Ollama within a container, handled by <a href="https://testcontainers.com/">TestContainers</a>.</p><p>TestContainers is not only useful for testing, but you can also use it for driving containers. There‚Äôs even a specific <a href="https://java.testcontainers.org/modules/ollama/">OllamaContainer</a> you can take advantage of!</p><p>So here‚Äôs the whole¬†picture:</p><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/0*lHxJaKf0ALEEnoJS.png" /></figure><h3>Time to implement this approach!</h3><p>You‚Äôll find the code in the Github <a href="https://github.com/glaforge/gemini-workshop-for-java-developers/blob/main/app/src/main/java/gemini/workshop/CallGemma.java">repository</a> accompanying my recent <a href="https://codelabs.developers.google.com/codelabs/gemini-java-developers">Gemini¬†workshop</a></p><p>Let‚Äôs start with the easy part, interacting with an Ollama supported model with LangChain4j:</p><pre>OllamaContainer ollama = createGemmaOllamaContainer();<br>ollama.start();<br><br>ChatLanguageModel model = OllamaChatModel.builder()<br>    .baseUrl(String.format(&quot;http://%s:%d&quot;, ollama.getHost(), ollama.getFirstMappedPort()))<br>    .modelName(&quot;gemma:2b&quot;)<br>    .build();<br><br>String response = model.generate(&quot;Why is the sky blue?&quot;);<br><br>System.out.println(response);</pre><ul><li>You run an Ollama test container.</li><li>You create an Ollama chat model, by pointing at the address and port of the container.</li><li>You specify the model you want to¬†use.</li><li>Then, you just need to call model.generate(yourPrompt) as¬†usual.</li></ul><p>Easy? Now let‚Äôs have a look at the trickier part, my local method that creates the Ollama container:</p><pre>// check if the custom Gemma Ollama image exists already<br>List&lt;Image&gt; listImagesCmd = DockerClientFactory.lazyClient()<br>    .listImagesCmd()<br>    .withImageNameFilter(TC_OLLAMA_GEMMA_2_B)<br>    .exec();<br><br>if (listImagesCmd.isEmpty()) {<br>    System.out.println(&quot;Creating a new Ollama container with Gemma 2B image...&quot;);<br>    OllamaContainer ollama = new OllamaContainer(&quot;ollama/ollama:0.1.26&quot;);<br>    ollama.start();<br>    ollama.execInContainer(&quot;ollama&quot;, &quot;pull&quot;, &quot;gemma:2b&quot;);<br>    ollama.commitToImage(TC_OLLAMA_GEMMA_2_B);<br>    return ollama;<br>} else {<br>    System.out.println(&quot;Using existing Ollama container with Gemma 2B image...&quot;);<br>    // Substitute the default Ollama image with our Gemma variant<br>    return new OllamaContainer(<br>        DockerImageName.parse(TC_OLLAMA_GEMMA_2_B)<br>            .asCompatibleSubstituteFor(&quot;ollama/ollama&quot;));<br>}</pre><p>You need to create a derived Ollama container that pulls in the Gemma model. Either this image was already created beforehand, or if it doesn‚Äôt exist yet, you create¬†it.</p><p>Use the Docker Java client to check if the custom Gemma image exists. If it doesn‚Äôt exist, notice how TestContainers let you create an image derived from the base Ollama image, pull the Gemma model, and then commit that image to your local Docker registry.</p><p>Otherwise, if the image already exists (ie. you created it in a previous run of the application), you‚Äôre just going to tell TestContainers that you want to substitute the default Ollama image with your Gemma-powered variant.</p><h3>And voila!</h3><p>You can <strong>call Gemma locally on your laptop, in your Java apps, using LangChain4j</strong>, without having to install and run Ollama locally (but of course, you need to have a Docker daemon running).</p><p>Big thanks to <a href="https://twitter.com/ddobrin">Dan Dobrin</a> for the approach, and to <a href="https://twitter.com/bsideup">Sergei</a>, <a href="https://twitter.com/EdduMelendez">Edd√∫</a> and <a href="https://twitter.com/shelajev">Oleg</a> from TestContainers for the help and useful pointers.</p><p><em>Originally published at </em><a href="https://glaforge.dev/posts/2024/04/04/calling-gemma-with-ollama-and-testcontainers/"><em>https://glaforge.dev</em></a><em> on April 3,¬†2024.</em></p><img src="https://medium.com/_/stat?event=post.clientViewed&referrerSource=full_rss&postId=fbfe220ca715" width="1" height="1" alt=""><hr><p><a href="https://medium.com/google-cloud/calling-gemma-with-ollama-testcontainers-and-langchain4j-fbfe220ca715">Calling Gemma with Ollama, TestContainers, and LangChain4j</a> was originally published in <a href="https://medium.com/google-cloud">Google Cloud - Community</a> on Medium, where people are continuing the conversation by highlighting and responding to this story.</p>]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Build Infrastructure on Google Cloud with Terraform‚Ää‚Äî‚ÄäGoogle Challenge Lab Walkthrough]]></title>
            <link>https://medium.com/google-cloud/build-infrastructure-on-google-cloud-with-terraform-google-challenge-lab-walkthrough-30a592373d3e?source=rss----e52cf94d98af---4</link>
            <guid isPermaLink="false">https://medium.com/p/30a592373d3e</guid>
            <category><![CDATA[challenge-lab]]></category>
            <category><![CDATA[google-cloud-platform]]></category>
            <category><![CDATA[terraform]]></category>
            <category><![CDATA[infrastructure]]></category>
            <category><![CDATA[terraform-import]]></category>
            <dc:creator><![CDATA[Dazbo (Darren Lester)]]></dc:creator>
            <pubDate>Fri, 05 Apr 2024 04:49:54 GMT</pubDate>
            <atom:updated>2024-04-05T04:49:54.155Z</atom:updated>
            <content:encoded><![CDATA[<h3>Build Infrastructure on Google Cloud with Terraform‚Ää‚Äî‚ÄäGoogle Challenge Lab Walkthrough</h3><p>This is a walkthrough of the <a href="https://partner.cloudskillsboost.google/focuses/16515?parent=catalog">challenge lab</a> from the course <a href="https://www.cloudskillsboost.google/course_templates/636">Build Infrastructure with Terraform on Google¬†Cloud</a>.</p><p>This lab tests your ability¬†to:</p><ul><li>Import existing infrastructure into your Terraform configuration.</li><li>Build and reference your own Terraform modules.</li><li>Add a remote backend to your configuration.</li><li>Use and implement a module from the Terraform Registry.</li><li>Re-provision, destroy, and update infrastructure.</li><li>Test connectivity between the resources you‚Äôve¬†created.</li></ul><h3>Intro to Challenge Labs</h3><p>Google provides an online learning platform called Google <a href="https://www.cloudskillsboost.google/">Cloud Skills Boost</a>, formerly known as QwikLabs. On this platform, you can follow training courses aligned to learning paths, to particular products, or for particular solutions.</p><p>One type of learning experience on this platform is called a <strong>quest</strong>. This is where you complete a number of guided hands-on labs, and then finally complete a <strong>Challenge Lab</strong>. The <strong>challenge lab</strong> differs from the other labs in that goals are specified, but very little guidance on <em>how</em> to achieve the goals is¬†given.</p><p>I occasionally create walkthroughs of these challenge labs. The goal is not to help you cheat your way through the challenge labs! But¬†rather:</p><ul><li>To show you what I believe to be an ideal route through the¬†lab.</li><li>To help you with particular gotchas or blockers that are preventing you from completing the lab on your¬†own.</li></ul><p>If you‚Äôre looking for help with challenge lab, then you‚Äôve come to the right place. But I strongly urge you to work your way through the quest first, and to try the lab on your own, before reading¬†further!</p><p>With all these labs, there are always many ways to go about solving the problem. I generally like to solve them using the Cloud Shell, since I can then document a more repeatable and programmatic approach. But of course, you can use the Cloud Console¬†too.</p><h3>Overview of this¬†Lab</h3><p>In this lab we‚Äôre expected to use Terraform to create, deploy and manage infrastructure on Google Cloud. We also need to import some mismanaged instances into our configuration and fix¬†them.</p><h3>My Solution</h3><p>Let‚Äôs start by defining some variables we can use throughout this challenge. The actual variables will be provided to you when you start the¬†lab.</p><pre>gcloud auth list<br><br>region=&lt;ENTER REGION&gt;<br>zone=&lt;ENTER ZONE&gt;<br>prj=&lt;ENTER PRJ ID&gt;</pre><h4>Task 1‚Ää‚Äî‚ÄäCreate the Configuration Files</h4><p>We‚Äôre told to create this folder structure:</p><pre>main.tf<br>variables.tf<br>modules/<br>‚îî‚îÄ‚îÄ instances<br>|   ‚îú‚îÄ‚îÄ instances.tf<br>|   ‚îú‚îÄ‚îÄ outputs.tf<br>|   ‚îî‚îÄ‚îÄ variables.tf<br>‚îî‚îÄ‚îÄ storage<br>    ‚îú‚îÄ‚îÄ storage.tf<br>    ‚îú‚îÄ‚îÄ outputs.tf<br>    ‚îî‚îÄ‚îÄ variables.tf</pre><p>We can do it like¬†this:</p><pre># Create main.tf and variables.tf in the root directory<br>touch main.tf variables.tf<br><br># Create main directory and its files<br>mkdir -p modules/instances<br>mkdir modules/storage<br><br># Create the required files in the &#39;instances&#39; module directory<br>touch modules/instances/instances.tf<br>touch modules/instances/outputs.tf<br>touch modules/instances/variables.tf<br><br># Create the required files in the &#39;storage&#39; module directory<br>touch modules/storage/storage.tf<br>touch modules/storage/outputs.tf<br>touch modules/storage/variables.tf</pre><p>Now we update the variables.tf files to contain these variables:</p><pre>variable &quot;region&quot; {<br>  description = &quot;The Google Cloud region&quot;<br>  type        = string<br>  default     = &quot;Lab-supplied region&quot;<br>}<br><br>variable &quot;zone&quot; {<br>  description = &quot;The Google Cloud zone&quot;<br>  type        = string<br>  default     = &quot;Lab-supplied zone&quot;<br>}<br><br>variable &quot;project_id&quot; {<br>  description = &quot;The ID of the project in which to provision resources.&quot;<br>  type        = string<br>  default     = &quot;Your project ID&quot;<br>}</pre><p>Update the root module main.tf to include the Google Cloud Provider, which you can always look up in the <a href="https://registry.terraform.io/providers/hashicorp/google/latest/docs">Terraform Registry</a>. We‚Äôre asked to include all three of our variables in our provider¬†block.</p><pre>terraform {<br>  required_providers {<br>    google = {<br>      source = &quot;hashicorp/google&quot;<br>    }<br>  }<br>}<br><br>provider &quot;google&quot; {<br>  project     = var.project_id<br>  region      = var.region<br>  zone        = var.zone<br>}</pre><p>Now we need to initialise Terraform. So run this¬†command:</p><pre>terraform init</pre><h4>Task 2‚Ää‚Äî‚ÄäImport Infrastructure</h4><p>Here, the goal is to bring infrastructure under Terraform control, that has thus far been provisioned outside of Terraform.</p><p>We‚Äôre going to use the Terraform import workflow:</p><figure><img alt="" src="https://cdn-images-1.medium.com/max/737/0*cLTWjcD7L2rsBcRO.png" /><figcaption>Terraform import¬†workflow</figcaption></figure><p>These are the import¬†steps:</p><ol><li>Identify the existing infrastructure to be imported.</li><li>Import the infrastructure into your <strong>Terraform state</strong>.</li><li>Write a <strong>Terraform configuration</strong> that matches that infrastructure.</li><li><strong>Review the Terraform plan</strong> to ensure that the configuration matches the expected state and infrastructure.</li><li><strong>Apply </strong>the configuration to update your Terraform state.</li></ol><h4>Identify the existing infrastructure to be¬†imported</h4><p>Two GCE instances have already been created. Examine one of the existing instances, tf-instance-1 in the Cloud Console. We want to retrieve:</p><ul><li>Network</li><li>Machine type</li><li>Disk</li></ul><p>Next we need to include two calls to our instances module in our main.tf. They will contain empty definitions, so that we can¬†import.</p><pre>module &quot;tf_instance_1&quot; {<br>  source        = &quot;./modules/instances&quot;<br>  instance_name = &quot;tf-instance-1&quot;<br>  zone          = var.zone<br>  region        = var.region<br>}<br><br>module &quot;tf_instance_2&quot; {<br>  source        = &quot;./modules/instances&quot;<br>  instance_name = &quot;tf-instance-2&quot;<br>  zone          = var.zone<br>  region        = var.region<br>}</pre><p>Remember that each module definition must have a unique¬†label.</p><p>Now initialise:</p><pre>terraform init</pre><p>Now we write the <a href="https://registry.terraform.io/providers/hashicorp/google/latest/docs/resources/compute_instance">module configurations</a> in instances.tf. We‚Äôre told the arguments that need to be included in our minimal configuration:</p><pre>resource &quot;google_compute_instance&quot; &quot;instance&quot; {<br>  name         = var.instance_name<br>  machine_type = &quot;hard code from existing instance&quot;<br>  zone         = var.zone<br><br>  boot_disk {<br>    initialize_params {<br>      # image = &quot;debian-cloud/debian-11&quot;<br>      image = &quot;hard code from existing instance&quot;<br>    }<br>  }<br><br>  network_interface {<br>    # network = &quot;default&quot;<br>    network = &quot;hard code from existing instance&quot;<br>    access_config {<br>      // Ephemeral public IP<br>    }<br>  }<br><br>  metadata_startup_script = &lt;&lt;-EOT<br>          #!/bin/bash<br>      EOT<br>  allow_stopping_for_update = true<br>}</pre><p>Update variables.tf in the instance module, so we can pass in the instance_name:</p><pre>variable &quot;instance_name&quot; {<br>  description = &quot;The name of the instance.&quot;<br>  type        = string<br>}</pre><h4>Import the Existing Infrastructure into Terraform State</h4><pre>terraform import module.tf_instance_1.google_compute_instance.instance \<br>  projects/$prj/zones/$zone/instances/tf-instance-1<br><br>terraform import module.tf_instance_2.google_compute_instance.instance \<br>  projects/$prj/zones/$zone/instances/tf-instance-2<br><br># verify the import<br>terraform show</pre><p>The import should look like¬†this:</p><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/0*1YafhrvtKcZG7MrQ.png" /><figcaption>terraform import</figcaption></figure><h4>Plan and¬†Apply</h4><p>Now we update the instances in-place by running the¬†apply:</p><pre>terraform plan<br>terraform apply</pre><h4>Task 3‚Ää‚Äî‚ÄäConfigure a Remote¬†Backend</h4><p>This is pretty easy. These are standard steps that you would run whenever we want to store Terraform state in a remote GCS¬†backend:</p><ol><li>Provision a GCS bucket with Terraform.</li><li>Add a backend block that points to the new GCS¬†bucket.</li><li>Reinitialise Terraform and migrate the state from the local state file to the remote¬†backend.</li></ol><h4>Provision the GCS¬†Bucket</h4><p>Add this resource definition to¬†main.tf:</p><pre>resource &quot;google_storage_bucket&quot; &quot;test-bucket-for-state&quot; {<br>  name        = &quot;Bucket Name You Are Given&quot;<br>  location    = &quot;US&quot;<br>  uniform_bucket_level_access = true<br><br>  force_destroy = true<br>}</pre><p>And apply:</p><pre>terraform apply</pre><h4>Add the GCS¬†Backend</h4><p>Modify main.tf and include the backend in the terraform block:</p><pre>terraform {<br>  backend &quot;gcs&quot; {<br>    bucket  = var.project_id<br>    prefix  = &quot;terraform/state&quot;<br>  }<br>}</pre><h4>Migrate the¬†State</h4><p>This is where we migrate the Terraform state from the local state file into the GCS¬†backend:</p><pre>terraform init -migrate-state</pre><p>It will ask you to confirm you want to migrate the¬†state:</p><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/0*qJ3EoohrCM8M5h7V.png" /><figcaption>Migrating Terraform state</figcaption></figure><h4>Task 4‚Ää‚Äî‚ÄäModify and Update the Infrastructure</h4><p>We need to update variables.tf to include a machine_type:</p><pre>variable &quot;machine_type&quot; {<br>  description = &quot;The machine type of an instance&quot;<br>  type        = string<br>  default     = &quot;e2-standard-2&quot;<br>}</pre><p>Then we need to modify instance.tf so that it can accept a machine_type parameter:</p><pre>resource &quot;google_compute_instance&quot; &quot;instance&quot; {<br>  name         = var.instance_name<br>  machine_type = var.machine_type<br>  zone         = var.zone<br><br>  ...</pre><p>Lastly, we need to modify main.tf such that we add the specified third instance to our main.tf, by calling the module for a third time. We don‚Äôt need to pass in the machine_type, as we‚Äôve already set it to have a¬†default.</p><p>Now initialise (because we‚Äôve added another module instance) and¬†apply.</p><pre>terraform init<br>terraform apply</pre><h4>Task 5‚Ää‚Äî‚ÄäDestroy Resources</h4><p>Now we remove the instance we previously added. Remove the call to this module from main.tf, then¬†reapply:</p><pre>terraform init<br>terraform apply</pre><h4>Task 6‚Ää‚Äî‚ÄäUse a Module from the¬†Registry</h4><p>We‚Äôre going to use the <a href="https://registry.terraform.io/modules/terraform-google-modules/network/google/6.0.0">Google Network¬†Module</a>.</p><pre>module &quot;network&quot; {<br>  source  = &quot;terraform-google-modules/network/google&quot;<br>  version = &quot;6.0.0&quot;<br><br>  project_id   = var.project_id<br>  network_name = &quot;Use Supplied VPC Name&quot;<br>  routing_mode = &quot;GLOBAL&quot;<br><br>  subnets = [<br>    {<br>      subnet_name           = &quot;subnet-01&quot;<br>      subnet_ip             = &quot;10.10.10.0/24&quot;<br>      subnet_region         = var.region<br>    },<br>    {<br>      subnet_name           = &quot;subnet-02&quot;<br>      subnet_ip             = &quot;10.10.20.0/24&quot;<br>      subnet_region         = var.region<br>    }<br>  ]<br>}</pre><p>Initialise and¬†apply:</p><pre>terraform init<br>terraform apply</pre><p>Update instances module to take a network parameter and a subnet parameter.</p><p>In variables.tf:</p><pre>variable &quot;network&quot; {<br>  description = &quot;The network&quot;<br>  type        = string<br>}<br><br>variable &quot;subnet&quot; {<br>  description = &quot;The subnet&quot;<br>  type        = string<br>}</pre><p>In instance.tf:</p><pre>network_interface {<br>  network = var.network<br>  subnetwork = var.subnet<br><br>  access_config {<br>    // Ephemeral public IP<br>  }<br>}</pre><p>Then update main.tf to create the instances like¬†this:</p><pre>module &quot;tf_instance_1&quot; {<br>  source        = &quot;./modules/instances&quot;<br>  instance_name = &quot;tf-instance-1&quot;<br>  zone          = var.zone<br>  region        = var.region<br><br>  network       = module.network.network_name<br>  subnet        = &quot;subnet-01&quot;<br>}<br><br>module &quot;tf_instance_2&quot; {<br>  source        = &quot;./modules/instances&quot;<br>  instance_name = &quot;tf-instance-2&quot;<br>  zone          = var.zone<br>  region        = var.region<br>  network       = module.network.network_name<br>  subnet        = &quot;subnet-02&quot;<br>}</pre><pre>terraform init<br>terraform apply</pre><h4>Task 7‚Ää‚Äî‚ÄäAdd a¬†Firewall</h4><p>Update main.tf:</p><pre>resource &quot;google_compute_firewall&quot; &quot;default&quot; {<br>  name          = &quot;tf-firewall&quot;<br>  network       = module.network.network_name<br>  direction     = &quot;INGRESS&quot;<br>  source_ranges = [&quot;0.0.0.0/0&quot;]<br><br>  allow {<br>    protocol = &quot;tcp&quot;<br>    ports    = [&quot;80&quot;]<br>  }<br>}</pre><p>And one last¬†apply‚Ä¶</p><pre>terraform apply</pre><p>And we‚Äôre¬†done!</p><img src="https://medium.com/_/stat?event=post.clientViewed&referrerSource=full_rss&postId=30a592373d3e" width="1" height="1" alt=""><hr><p><a href="https://medium.com/google-cloud/build-infrastructure-on-google-cloud-with-terraform-google-challenge-lab-walkthrough-30a592373d3e">Build Infrastructure on Google Cloud with Terraform‚Ää‚Äî‚ÄäGoogle Challenge Lab Walkthrough</a> was originally published in <a href="https://medium.com/google-cloud">Google Cloud - Community</a> on Medium, where people are continuing the conversation by highlighting and responding to this story.</p>]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Using AlloyDB Go connector for automatic IAM authentication (service account)]]></title>
            <link>https://medium.com/google-cloud/using-alloydb-connector-for-automatic-iam-authentication-service-account-ec29c4ee5d2b?source=rss----e52cf94d98af---4</link>
            <guid isPermaLink="false">https://medium.com/p/ec29c4ee5d2b</guid>
            <category><![CDATA[go]]></category>
            <category><![CDATA[google-cloud-platform]]></category>
            <category><![CDATA[data]]></category>
            <category><![CDATA[postgres]]></category>
            <category><![CDATA[alloydb]]></category>
            <dc:creator><![CDATA[Harinderjit Singh]]></dc:creator>
            <pubDate>Fri, 05 Apr 2024 04:49:36 GMT</pubDate>
            <atom:updated>2024-04-05T04:49:35.915Z</atom:updated>
            <content:encoded><![CDATA[<h3><strong>Introduction</strong></h3><p><a href="https://cloud.google.com/alloydb#documentation">AlloyDB</a> is a fully managed PostgreSQL compatible database service for your most demanding enterprise workloads. AlloyDB combines the best of Google with PostgreSQL, for superior performance, scale, and availability.</p><p>Since AlloyDB is PostgreSQL compatible, you can use <a href="https://github.com/jackc/pgx/">pgxpool</a> and <a href="https://github.com/brettwooldridge/HikariCP/blob/dev/README.md">HikariCP</a> for connection pooling in ‚ÄúGo‚Äù and ‚ÄúJava‚Äù applications respectively.</p><p>There are two prominent ways to <strong>connect securely to¬†AlloyDB:</strong></p><ul><li>AlloyDB Auth¬†Proxy</li><li>AlloyDB Language connectors</li></ul><h4>AlloyDB Auth¬†Proxy</h4><ul><li><strong>IAM-based connection authorization (AuthZ):</strong> The Auth Proxy uses the credentials and permissions of an IAM principal to authorize connections to AlloyDB instances.</li><li><strong>Secure, encrypted communication:</strong> The Auth Proxy automatically creates, uses, and maintains a TLS 1.3 connection using a 256-bit AES cipher between your client and an AlloyDB instance.</li></ul><h4>AlloyDB Language connectors</h4><p>AlloyDB connectors are the language specific libraries for connecting securely to your AlloyDB instances. Using an AlloyDB connector provides the following additional benefits (besides the ones provided by AlloyDB Auth Proxy)¬†:</p><ul><li><strong>Convenience</strong>: removes the requirement to use and distribute SSL certificates, as well as manage firewalls or source/destination IP addresses. <strong>You also don‚Äôt need to manage a separate Auth proxy container or¬†process.</strong></li><li>(optionally) <strong>IAM DB Authentication</strong>: provides support for <a href="https://github.com/GoogleCloudPlatform/alloydb-go-connector?tab=readme-ov-file#automatic-iam-database-authentication">AlloyDB‚Äôs automatic IAM DB AuthN</a> feature. That means <strong>you can configure service accounts to connect to database</strong>. For applications deployed on GKE you can use workload identity to authenticate to the backend AlloyDB database.</li></ul><p>AlloyDB Language connectors are available for Go, Java and Python at this¬†time.</p><h3>Purpose</h3><p>If you‚Äôre deploying a Go application on GCE/GKE and want to streamline secure connections to your AlloyDB database, the AlloyDB Go connector with IAM authentication is the way to¬†go.</p><p>In this post I will walk you through the process of configuring your application and AlloyDB Instance for using AlloyDB Go connector such that your application can use a service account to connect to AlloyDB database. You don‚Äôt need to configure any vault to store the DB user password, no need to store any keyfile for the service¬†account.</p><p>We are considering a hypothetical Go application (<a href="https://github.com/bijeshos/go-postgresql-pgx-example/blob/main/main.go">example</a>) which will be deployed on GCE for this¬†article.</p><h3>Assumptions</h3><ol><li>GCP Project is already¬†created</li><li>VPC network exists for this project and has a subnet defined for¬†GCE/GKE</li><li>AlloyDB, Service Networking, Compute APIs are¬†enabled</li></ol><h3>Steps</h3><h4>Create a service¬†account</h4><p>This is the service account which will be configured as AlloyDB user and will be used by application to connect to database.</p><pre>read -p &quot;project_id: &quot; PROJECT_ID<br>read -p &quot;region: &quot; REGION<br>read -p &quot;serviceaccount: &quot; SERVICEACCOUNT<br>gcloud iam service-accounts create ${SERVICEACCOUNT} --display-name=&quot;alloydb service-account&quot; --project ${PROJECT_ID}</pre><h4>Add roles to the service¬†account</h4><p>As per <a href="https://cloud.google.com/alloydb/docs/manage-iam-authn#role,">https://cloud.google.com/alloydb/docs/manage-iam-authn#role,</a> we need to assign roles alloydb.client, alloydb.databaseUser and serviceusage.serviceUsageConsumer to the service¬†account.</p><pre>gcloud projects add-iam-policy-binding ${PROJECT_ID} --member=&#39;serviceAccount:${SERVICEACCOUNT}@${PROJECT_ID}.iam.gserviceaccount.com&#39; --role=&#39;roles/alloydb.client&#39;<br>gcloud projects add-iam-policy-binding ${PROJECT_ID} --member=&#39;serviceAccount:${SERVICEACCOUNT}@${PROJECT_ID}.iam.gserviceaccount.com&#39; --role=&#39;roles/alloydb.databaseUser&#39;<br>gcloud projects add-iam-policy-binding ${PROJECT_ID} --member=&#39;serviceAccount:${SERVICEACCOUNT}@${PROJECT_ID}.iam.gserviceaccount.com&#39; --role=&#39;roles/serviceusage.serviceUsageConsumer&#39;</pre><h4>Create private service¬†access</h4><p>Use Private Services Access to connect to AlloyDB¬†service.</p><p>Private services access requires you to first allocate an internal IPv4 address range and then create a private connection</p><pre>read -p &quot;region : &quot; REGION<br>read -p &quot;projectid : &quot; PROJECT_ID<br>read -p &quot;postgres_password: &quot; PASSWORD<br>read -p &quot;vpc network: &quot; VPC_NETWORK<br><br>gcloud compute addresses create alloydbpsa \<br>    --global \<br>    --purpose=VPC_PEERING \<br>    --prefix-length=16 \<br>    --description=&quot;Private service access&quot; \<br>    --network=$VPC_NETWORK \<br> --project ${PROJECT_ID}</pre><h4>Create VPC private connection to alloydb¬†service</h4><p>Private connection enables private access for AlloyDB Instances</p><pre>gcloud services vpc-peerings connect \<br>     --service=servicenetworking.googleapis.com \<br>     --ranges=alloydbpsa \<br>     --network=$VPC_NETWORK  \<br>--project ${PROJECT_ID}</pre><h4>Create AlloyDB Cluster and Primary¬†Instance</h4><p>Below commands will create an AlloyDB Cluster and Instance. Please update the cluster and Instance names as per requirements.</p><pre>read -p &quot;region : &quot; REGION<br>read -p &quot;projectid : &quot; PROJECT_ID<br>read -p &quot;postgres_password: &quot; PASSWORD<br>read -p &quot;vpc network: &quot; VPC_NETWORK<br>gcloud alloydb clusters create alloydb-cls-$(date +%d%m%Y) \<br>--region=${REGION} --password=$PASSWORD --network=${VPC_NETWORK} \<br>--project=${PROJECT_ID}<br><br>gcloud beta alloydb instances create alloydb-ins-primary-$(date +%d%m%Y) \<br>--cluster=alloydb-cls-$(date +%d%m%Y)  --region=${REGION} \<br>--instance-type=PRIMARY --cpu-count=2 \<br>--database-flags=alloydb.iam_authentication=on,alloydb.enable_auto_explain=on \<br>--availability-type=ZONAL --project=${PROJECT_ID}</pre><p>Notice that AlloyDB Instance has flag <strong>alloydb.iam_authentication</strong> set to on. This flag enables IAM authentication on an AlloyDB instance. If you already have an AlloyDB Instance, you can use below command to enable this¬†flag.</p><pre>gcloud alloydb instances update $INSTANCE --cluster=$CLUSTER \<br> --region=$REGION --database-flags=alloydb.iam_authentication=on</pre><h4>Create a AlloyDB user with name same as the service¬†account</h4><p>Username must be a same as the service account leaving the suffix ‚Äú.gserviceaccount.com‚Äù and authentication type must be ‚ÄúIAM_BASED‚Äù.</p><pre>read -p &quot;serviceaccount: &quot; SERVICEACCOUNT<br>gcloud alloydb users create ${SERVICEACCOUNT}@${PROJECT_ID}.iam \<br>--cluster=alloydb-cls-$(date +%d%m%Y) --type=IAM_BASED \<br>--region=${REGION} --project=${PROJECT_ID}</pre><h4>Create Application schema and grant appropriate roles</h4><p>Connect to AlloyDB database postgres using a BUILTIN user (postgres) to create ‚Äúapplication‚Äù database and grant appropriate roles to AlloyDB IAM user on ‚Äúapplication‚Äù database.</p><p>To connect you may use AlloyDB SQL studio or¬†psql.</p><pre>create database application;<br>---replace the ${SERVICEACCOUNT}@${PROJECT_ID}.iam with actual SA<br>grant all privileges on database application to &quot;${SERVICEACCOUNT}@${PROJECT_ID}.iam&quot;;</pre><h4>Create GCE¬†Instance</h4><p>Create GCE spot Instance (experimentation purposes only) where our application will be deployed.</p><pre>read -p &quot;GCE subnet:&quot; GCE_SUBNET<br>gcloud compute instances create instance-$(date +%d%m%Y) \<br>--project=${PROJECT_ID} --zone=${REGION}-a --machine-type=e2-medium \<br>--network-interface=network-tier=PREMIUM,stack-type=IPV4_ONLY,subnet=$GCE_SUBNET \<br>--provisioning-model=SPOT --service-account=${SERVICEACCOUNT}@${PROJECT_ID}.iam.gserviceaccount.com \<br>--scopes=https://www.googleapis.com/auth/cloud-platform \<br>--create-disk=auto-delete=yes,boot=yes,device-name=instance-$(date +%d%m%Y)-230433,image=projects/debian-cloud/global/images/debian-12-bookworm-v20240213,mode=rw,size=10,type=projects/${PROJECT_ID}/zones/${REGION}-a/diskTypes/pd-balanced \<br>--no-shielded-secure-boot --shielded-vtpm --shielded-integrity-monitoring \<br>--labels=goog-ec-src=vm_add-gcloud --reservation-affinity=any \<br>--preemptible --metadata=startup-script=&#39;#! /bin/bash<br>  apt update -y<br>  apt -y install golang unzip git&#39;</pre><p>Notice that we bind the service account (DB User Service Account) that we created earlier to the GCE¬†VM.</p><p>Now any process running on GCE VM can use that service account to authenticate to allowed APIs using assigned¬†roles.</p><h4>Connecting to postgres using pgx pool (no connector)</h4><p>To make a connection to your database you would typically be using a function such as below. This uses <a href="https://pkg.go.dev/github.com/jackc/pgx/v5/pgxpool#pkg-overview">pgxpool package</a> to create a connection pool.</p><pre>func connectPostgres() (*pgxpool.Pool, error) {<br> ctx := context.Background()<br> var (<br>  dsn      string<br>  dbname   = os.Getenv(&quot;DBNAME&quot;)<br>  user     = os.Getenv(&quot;DBUSER&quot;)<br>  host     = os.Getenv(&quot;PGHOSTNAME&quot;)<br>  password = os.Getenv(&quot;PGPASSWORD&quot;)<br>  err      error<br> )<br><br> dsn = fmt.Sprintf(<br>  //user=jack password=secret host=pg.example.com port=5432 dbname=mydb sslmode=verify-ca pool_max_conns=10<br>  // connection instead.<br>  &quot;user=%s password=%s dbname=%s sslmode=disable host=%s&quot;,<br>  user, password, dbname, host,<br> )<br> config, err := pgxpool.ParseConfig(dsn)<br> if err != nil {<br>  return nil, fmt.Errorf(&quot;failed to parse pgx config: %v&quot;, err)<br> }<br> // Establish the connection.<br> pool, connErr := pgxpool.NewWithConfig(ctx, config)<br> if connErr != nil {<br>  return nil, fmt.Errorf(&quot;failed to connect: %s&quot;, connErr)<br> }<br> return pool, nil<br><br>}</pre><p>This requires you to define environment variables DBNAME, DBUSER, PGHOSTNAME and PGPASSWORD.</p><p>If you want to encrypt the data in transit, you have to configure sslmode and configure TLS certificates to encrypt the data in transit. You will need to manage the certificates on the application host.</p><h4>Connecting to postgres using pgx pool and Go Connector</h4><p>Update the definition of connectPostgres() in your application to the¬†below.</p><pre>func connectPostgres() (*pgxpool.Pool, error) {<br> ctx := context.Background()<br>// export DBNAME=application<br>// export DBUSER=${SERVICEACCOUNT}@${PROJECT_ID}.iam<br>// export INSTURI=projects/${PROJECT_ID}/locations/${REGION}/clusters/alloydb-cls--$(date +%d%m%Y)/instances/alloydb-ins-primary--$(date +%d%m%Y)<br> var (<br>  dsn     string<br>  dbname  = os.Getenv(&quot;DBNAME&quot;)<br>  user    = os.Getenv(&quot;DBUSER&quot;)<br>  instURI = os.Getenv(&quot;INSTURI&quot;)<br> )<br>// A Dialer can be configured to connect to an AlloyDB instance <br>// using automatic IAM database authentication with the WithIAMAuthN Option.<br> d, err := alloydbconn.NewDialer(ctx, alloydbconn.WithIAMAuthN())<br>if err != nil {<br>  return nil, fmt.Errorf(&quot;failed to init Dialer: %v&quot;, err)<br> }<br> dsn = fmt.Sprintf(<br>  // sslmode is disabled, because the Dialer will handle the SSL<br>  // connection instead.<br>  &quot;user=%s  dbname=%s sslmode=disable&quot;,<br>  user, dbname,<br> )<br> config, err := pgxpool.ParseConfig(dsn)<br> if err != nil {<br>  return nil, fmt.Errorf(&quot;failed to parse pgx config: %v&quot;, err)<br> }<br> // Tell pgx to use alloydbconn.Dialer to connect to the instance.<br> config.ConnConfig.DialFunc = func(ctx context.Context, _ string, _ string) (net.Conn, error) {<br>  return d.Dial(ctx, instURI)<br> }<br> // Establish the connection.<br> pool, connErr := pgxpool.NewWithConfig(ctx, config)<br> if connErr != nil {<br>  return nil, fmt.Errorf(&quot;failed to connect: %s&quot;, connErr)<br> }<br> return pool, nil<br>}</pre><p>This code excerpt is where the AlloyDB Go Connector is configured for pgxpool connection pool. <strong>alloydbconn.WithIAMAuthN()</strong> allows us to use IAM authentication when creating a connection.</p><p>We pass DBNAME, DBUSER and INSTURI as environment variables. ‚Äússlmode‚Äù is disabled, because the Dialer handles the SSL. You don‚Äôt need to manage any certificates and yet the data in transit is encrypted.</p><p>You would notice that we did not pass DB user password (PGPASSWORD) as parameter. Also we didn‚Äôt have to pass the IP for AlloyDB Instance as host, instead we used the Instance¬†URI.</p><p>Below call to function connectPostgres() creates a connection pool.</p><pre> db, err := connectPostgres()<br> if err != nil {<br>  return err<br> }<br>// just an example<br> data, err = getEmployeesPG(db)<br> if err != nil {<br>  log.Printf(&quot;func getEmployeesPG: failed to get data: %v&quot;, err)<br>  return err<br> }</pre><p>Then we can use that connection to query the database in our application.</p><h4>Grant access to IAM user on application database</h4><p>Assuming there is a table called employees in this database ‚Äúapplication‚Äù. We need to connect to the application databases as BUILTIN User and need to grant appropriate privileges to the IAM DB¬†user.</p><pre><br>grant all privileges on table employees to &quot;${SERVICEACCOUNT}@${PROJECT_ID}.iam&quot;;</pre><p>You will need to manage the permissions on the relations as per your application requirements.</p><h4>Deploy and Execute the code on GCE¬†VM</h4><p>This is just an example for demonstration.</p><pre>###Suppose you are in application directory<br>read -p &quot;region : &quot; REGION<br>read -p &quot;projectid : &quot; PROJECT_ID<br>read -p &quot;serviceaccount: &quot; SERVICEACCOUNT<br>export DBNAME=application<br>export DBUSER=${SERVICEACCOUNT}@${PROJECT_ID}.iam<br>export INSTURI=projects/${PROJECT_ID}/locations/${REGION}/clusters/alloydb-cls-$(date +%d%m%Y)/instances/alloydb-ins-primary-$(date +%d%m%Y)<br>go get cloud.google.com/go/alloydbconn<br>go get github.com/jackc/pgx/v5/pgxpool<br>go run ./main.go</pre><p>Application can successfully connect to database to read/write data.</p><h3>For applications deployed on¬†GKE</h3><ul><li>You should have a valid docker container image of your application.</li><li>Workload identity must be enabled at the GKE cluster¬†level.</li><li>Main difference is how the GKE uses Kubernetes service account to authenticate to AlloyDB Database on behalf of Google Service account which is also a Database user in this case. This is done using <a href="https://cloud.google.com/sql/docs/mysql/connect-kubernetes-engine#workload-identity">workload identity</a>.</li><li>We assign iam.workloadIdentityUser role to workload identity service account on your google service¬†account.</li><li>This enables your Kubernetes service account (example alloydb-ksa) to retrieve the authentication token as your google service account (example alloydb-sa) which then can be used to authenticate to AlloyDB as IAM_BASED Database¬†user.</li><li>This Kubernetes service account is then used by the application ‚Äúdeployment‚Äù kubernetes resource.</li><li>The environment variables such as DBNAME, DBUSER and INSTURI can be defined in a config map and then that config map can be used by the application ‚Äúdeployment‚Äù kubernetes resource.</li></ul><h3>Other Takeaways</h3><ul><li>If you application is written in Java, except the connection pool + Java connector code all steps are same. For connection pool using AlloyDB Java connector, you can¬†use</li></ul><p><a href="https://github.com/GoogleCloudPlatform/alloydb-java-connector/blob/HEAD/alloydb-jdbc-connector/src/test/java/com/google/cloud/alloydb/AlloyDbJdbcConnectorDataSourceFactory.java">alloydb-java-connector/alloydb-jdbc-connector/src/test/java/com/google/cloud/alloydb/AlloyDbJdbcConnectorDataSourceFactory.java at 80864f2b1e3548f3dbfa87f87c95f42f79d363d5 ¬∑ GoogleCloudPlatform/alloydb-java-connector</a></p><p>and set config.addDataSourceProperty(&quot;alloydbEnableIAMAuth&quot;, &quot;true&quot;);for Automatic IAM Authentication.</p><ul><li>If you desire to use Go connector to connect to your AlloyDB Instance but don‚Äôt want to use IAM Authentication, you can use <a href="https://github.com/GoogleCloudPlatform/alloydb-go-connector/blob/HEAD/pgxpool_test.go">https://github.com/GoogleCloudPlatform/alloydb-go-connector/blob/HEAD/pgxpool_test.go</a></li><li>You can configure AlloyDB to accept the connections only through connectors i.e <a href="https://cloud.google.com/alloydb/docs/enforce-connectors">connector enforcement</a>.</li></ul><img src="https://medium.com/_/stat?event=post.clientViewed&referrerSource=full_rss&postId=ec29c4ee5d2b" width="1" height="1" alt=""><hr><p><a href="https://medium.com/google-cloud/using-alloydb-connector-for-automatic-iam-authentication-service-account-ec29c4ee5d2b">Using AlloyDB Go connector for automatic IAM authentication (service account)</a> was originally published in <a href="https://medium.com/google-cloud">Google Cloud - Community</a> on Medium, where people are continuing the conversation by highlighting and responding to this story.</p>]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Convert Soft Breaks to Hard Breaks on Google Documents using Google Apps Script]]></title>
            <link>https://medium.com/google-cloud/convert-soft-breaks-to-hard-breaks-on-google-documents-using-google-apps-script-4edfd7fef0c5?source=rss----e52cf94d98af---4</link>
            <guid isPermaLink="false">https://medium.com/p/4edfd7fef0c5</guid>
            <category><![CDATA[google-document]]></category>
            <category><![CDATA[google-apps-script]]></category>
            <category><![CDATA[google-docs]]></category>
            <category><![CDATA[gcp-app-dev]]></category>
            <category><![CDATA[google-cloud-platform]]></category>
            <dc:creator><![CDATA[Kanshi Tanaike]]></dc:creator>
            <pubDate>Wed, 03 Apr 2024 04:49:27 GMT</pubDate>
            <atom:updated>2024-04-03T04:49:27.459Z</atom:updated>
            <content:encoded><![CDATA[<h3>Description</h3><p>This script converts soft breaks to hard breaks in a Google Document using Google Apps¬†Script.</p><h3>Usage</h3><p>Follow these¬†steps:</p><h3>1. Create a New Google¬†Document</h3><p>Create a new Google Document and open it. Go to ‚ÄúView‚Äù -&gt; ‚ÄúShow non-printing characters‚Äù in the top menu to see line breaks in the document body (as shown in the image¬†below).</p><h3>2. Sample¬†Script</h3><p>Copy and paste the following script into the script editor of your Google Document.</p><p>Important: Before using this script, enable the Google Docs API in Advanced Google services. <a href="https://developers.google.com/apps-script/guides/services/advanced#enable_advanced_services">Ref</a></p><pre>function myFunction() {<br>  const doc = DocumentApp.getActiveDocument();<br>  const requests = [<br>    { replaceAllText: { replaceText: &quot;\n&quot;, containsText: { text: &quot;\u000b&quot; } } },<br>  ];<br>  Docs.Documents.batchUpdate({ requests }, doc.getId());<br>}</pre><ul><li>The script searches for soft breaks using¬†\u000b.</li><li>It replaces them with \n, which creates hard¬†breaks.</li></ul><h3>Testing</h3><p>Running the script on a sample document with soft breaks will convert them to hard breaks as¬†follows.</p><figure><img alt="" src="https://cdn-images-1.medium.com/max/969/0*e-8Yqw118TRcG9yo.png" /></figure><h3>Note</h3><ul><li>The soft breaks can be searched with findText(&quot;\\v&quot;). But, when replaceText(&quot;\\v&quot;, &#39;\n&#39;) is run, it seems that \n is used as the soft breaks. I‚Äôm not sure whether this is the current specification or a bug. From this situation, I thought that Google Docs API might be able to be used. But, it seems that Google Docs API cannot search the soft breaks with \v. So, I thought that \u000b might be able to be¬†used.</li></ul><h3>References</h3><ul><li><a href="https://developers.google.com/docs/api/reference/rest/v1/documents/batchUpdate">Method: documents.batchUpdate</a></li><li><a href="https://developers.google.com/docs/api/reference/rest/v1/documents/request#replacealltextrequest">ReplaceAllTextRequest</a></li><li>Stack Overflow Thread: <a href="https://stackoverflow.com/q/78258654">https://stackoverflow.com/q/78258654</a> (original script¬†post)</li></ul><img src="https://medium.com/_/stat?event=post.clientViewed&referrerSource=full_rss&postId=4edfd7fef0c5" width="1" height="1" alt=""><hr><p><a href="https://medium.com/google-cloud/convert-soft-breaks-to-hard-breaks-on-google-documents-using-google-apps-script-4edfd7fef0c5">Convert Soft Breaks to Hard Breaks on Google Documents using Google Apps Script</a> was originally published in <a href="https://medium.com/google-cloud">Google Cloud - Community</a> on Medium, where people are continuing the conversation by highlighting and responding to this story.</p>]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Making sense of Vector Search and Embeddings across GCP products]]></title>
            <link>https://medium.com/google-cloud/making-sense-of-vector-search-and-embeddings-across-gcp-products-46cedad68934?source=rss----e52cf94d98af---4</link>
            <guid isPermaLink="false">https://medium.com/p/46cedad68934</guid>
            <category><![CDATA[vector-search]]></category>
            <category><![CDATA[google-cloud-platform]]></category>
            <category><![CDATA[embedding]]></category>
            <category><![CDATA[generative-ai]]></category>
            <category><![CDATA[machine-learning]]></category>
            <dc:creator><![CDATA[Steve Loh]]></dc:creator>
            <pubDate>Wed, 03 Apr 2024 04:49:10 GMT</pubDate>
            <atom:updated>2024-04-03T09:32:37.490Z</atom:updated>
            <content:encoded><![CDATA[<h3>Intro</h3><p>Many of you have already used the <strong>Large Language Model (LLM)</strong> from Generative AI. These models are great in performing certain creative tasks like content generation, text summarization, entity extraction and etc, but that‚Äôs not sufficient for enterprises that need¬†to:</p><ul><li>provide accurate and up-to-date information (reducing hallucination)</li><li>offer contextual user experiences</li><li>offer secure and governed access to the¬†data</li></ul><p>Hence comes the <strong>Retrieval-Augmented Generation technique (RAG)</strong> to fulfill those requirements. It combines the power of LLMs with the ability to reference external knowledge sources, by incorporating the following 2¬†systems:</p><ul><li><strong>Retrieval</strong>: When a user asks a question, RAG first searches through a database of documents or text to find relevant passages.</li><li><strong>Generation</strong>: the user then sends the retrieved information along as the context in the LLM prompt, effectively grounding LLM‚Äôs language understanding with specific knowledge in order to generate a more informed and accurate¬†answer.</li></ul><p>So how does the RAG retrieval system find the relevant knowledge? Welcome to the world of embeddings and vector¬†search.</p><ul><li><strong>Vector embeddings</strong> are numerical representations of text that capture the semantic meaning and relationships between words and concepts. You would use a pre-trained model to help generate embeddings. For example the Google Vertex <a href="https://cloud.google.com/vertex-ai/generative-ai/docs/model-reference/text-embeddings">textembedding-gecko model</a> generates a 768-dimensional embedding, while a <a href="https://cloud.google.com/vertex-ai/generative-ai/docs/model-reference/multimodal-embeddings">multimodal embedding model</a> would generate a 128, 256, 512, or 1408 dimensional embedding.</li><li><strong>Vector search</strong> comes into play by comparing the user‚Äôs query embedding to the vectors representing documents or passages in the knowledge base. This comparison uses similarity metrics to find the most relevant pieces of information based on their semantic closeness to the¬†query.</li></ul><p>Now with these concepts explained, you can implement RAG with the following steps:</p><figure><img alt="" src="https://cdn-images-1.medium.com/max/794/1*F0Yz_slYGzqsOaqf6ipHTQ.png" /></figure><ul><li>Break down large documents or text corpus using a suitable <a href="https://medium.com/@anuragmishra_27746/five-levels-of-chunking-strategies-in-rag-notes-from-gregs-video-7b735895694d">chunking¬†strategy</a></li><li>Generate embeddings for each chunk using a selected embedding model</li><li>Store the chunked data and vector embeddings together in a vector¬†database</li><li>User posts a prompt¬†query</li><li>Use the same pre-trained embedding model to generate a vector embedding for the user¬†query</li><li>Use the query embedding to search for most similar embeddings in vector database, then retrieve the corresponding data¬†chunk</li><li>Create a new prompt for the LLM by incorporating the retrieved chunked text alongside the original user¬†query</li></ul><p>Vector embeddings need to be stored in a vector database before you can search for embeddings. But adding a vector database to your software stack increases complexity, cost and learning curve. The great news is that most of the GCP data products already support vector out of the box, which means users will no longer need to choose between vector query and other critical database functionality. For example, all GCP transactional databases aims to fully support Vector features in near¬†future:</p><ul><li>AlloyDB (GA)</li><li>Cloud SQL for PostgreSQL (GA)</li><li>Cloud SQL for MySQL (Preview)</li><li>Spanner (Preview)</li><li>Memorystore for Redis (Preview)</li><li>Firestore (Preview)</li><li>Bigtable (Preview)</li></ul><p>Here I will showcase vector implementation across 3 main data product families on¬†GCP:</p><ul><li><strong>AlloyDB</strong>‚Ää‚Äî‚ÄäTransactional database</li><li><strong>BigQuery</strong>‚Ää‚Äî‚ÄäEnterprise data warehouse</li><li><strong>Vertex AI Vector Search</strong>‚Ää‚Äî‚ÄäMachine learning¬†platform</li></ul><blockquote>Disclaimer</blockquote><blockquote>I work as a Data Analytics practice lead in Google Cloud, This article is my own opinion and does not reflect the views of my employer.</blockquote><blockquote>Please take note that by the time you read this article, the information may already be obsolete as GenAI is a fast developing domain and Google Cloud is actively releasing new product features in this¬†space.</blockquote><h3>AlloyDB</h3><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/1*HAe09_TeYj5Dhbg6EWs7Bg.png" /></figure><p>AlloyDB is a fully Managed, PostgreSQL-compatible cloud native database service built to deliver superior performance, scalability, and high availability for most demanding enterprise workloads. It now comes with AlloyDB AI feature suite that provides the semantic and predictive power of ML models for your data out-of-the-box.</p><h4>Setup</h4><ul><li>Make sure you already have an <a href="https://cloud.google.com/alloydb/docs/cluster-create">AlloyDB cluster and instance¬†setup</a>.</li><li>Enable <strong>Vertex AI integration</strong> and the <strong>pgvector</strong> extensions in your AlloyDB instance:</li></ul><pre>psql &quot;host=$INSTANCE_IP user=alloydb_user dbname=vector_db&quot; -c &quot;CREATE EXTENSION IF NOT EXISTS google_ml_integration CASCADE&quot;<br><br>psql &quot;host=$INSTANCE_IP user=alloydb_user dbname=vector_db&quot; -c &quot;CREATE EXTENSION IF NOT EXISTS vector&quot;</pre><h4>Embeddings generation</h4><ul><li>Create a new column with the type <strong>vector</strong> to store the embeddings:<br>- The vector dimension should match the model that you use. For example textembedding-gecko model has 768 dimensions.<br>- AlloyDB implements embeddings as arrays of real values, but it can automatically cast from real array to a vector¬†value.</li></ul><pre>ALTER TABLE my_products ADD COLUMN embedding_column VECTOR(768);</pre><ul><li>To generate embedding, use the <strong>embedding() </strong>function:<br>- To use <strong>textembedding-gecko model</strong>, the AlloyDB cluster must reside in <strong>region us-central1</strong> to match the region of the model.<br>- You can <a href="https://cloud.google.com/alloydb/docs/ai/invoke-predictions">invoke predictions</a> to get around the region restriction.<br>- 003 is the latest version of textembedding-gecko model. Note that it‚Äôs always advisable to specify the version tag to avoid mistakes, as a new published model may return different embeddings.</li></ul><pre>SELECT embedding(&#39;textembedding-gecko@003&#39;, &#39;Google Pixel 8 Pro redefines smartphone photography with its advanced AI-powered camera system&#39;);</pre><ul><li>To generate embedding value based on another¬†column:</li></ul><pre>UPDATE my_products SET embedding_column = embedding(( &#39;textembedding-gecko@003&#39;, product_description);</pre><ul><li>Alternatively, you can also create an embedding column with default value generated from another¬†column:</li></ul><pre>ALTER TABLE my_products ADD COLUMN embedding_column vector GENERATED ALWAYS AS (embedding(&#39;textembedding-gecko@003&#39;, product_description)) STORED;</pre><h4>Vector index</h4><ul><li>By default pgvector performs exact nearest neighbor search which provides perfect recall. It can support approximate nearest-neighbor searching through indexing of HNSW or IVFFlat. AlloyDB provides built-in optimizations for pgvector by adding a scalar quantization feature (SQ8) to IVF index creation that can significantly speed up queries.<br>- SQ8 supports vectors with up to 8000 dimensions. <br>- You can choose among 3 distance functions: vector_l2_ops (L2 distance), vector_ip_ops (Inner product) or vector_cosine_ops (Cosine distance).</li></ul><pre>CREATE INDEX embedding_column_idx ON my_products<br>  USING ivf (embedding_column vector_l2_ops)<br>  WITH (lists = 20, quantizer = &#39;SQ8&#39;);</pre><h4>Vector search</h4><ul><li>Perform vector search using the pgvector nearest-neighbor operator &lt;-&gt; in order to find the database rows with the most semantically similar embeddings:</li></ul><pre>SELECT product_name FROM my_products<br>    ORDER BY embedding_column<br>    &lt;-&gt; embedding((&#39;textembedding-gecko@003&#39;, &#39;I need a phone that provides the best photography quality&#39;)::vector<br>    LIMIT 10;</pre><p>Check the following links for more information:</p><ul><li><a href="https://cloud.google.com/alloydb/docs/ai/work-with-embeddings">Work with vector embeddings on¬†AlloyDB</a></li><li><a href="https://github.com/pgvector/pgvector#indexing">pgvector indexing</a></li></ul><h3>BigQuery</h3><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/1*2XV9VBLwcU7bdryyp-U5DQ.png" /></figure><h4>Setup</h4><ul><li>BigQuery is a serverless service and no resource setup is needed for¬†it.</li><li>Create a remote connection to Vertex AI remote¬†models:</li></ul><pre>bq mk --connection --location=US --project_id={PROJECT_ID}  --connection_type=CLOUD_RESOURCE vertex_embeddings</pre><ul><li>Grant ‚ÄòVertex AI User‚Äô role to the service account of the created connection:</li></ul><pre>gcloud projects add-iam-policy-binding {PROJECT_ID} \<br>  --member=&#39;serviceAccount:{CONNECTION_SERVICE_ACCOUNT}&#39; \<br>  --role=&#39;roles/aiplatform.user&#39;</pre><h4>Embeddings generation</h4><ul><li>Create a remote embedding model to represented the hosted textembedding-gecko model:</li></ul><pre>CREATE OR REPLACE MODEL test_embeddings.llm_embedding_model<br>  REMOTE WITH CONNECTION `us.vertex_embeddings`<br>  OPTIONS(ENDPOINT=&#39;textembedding-gecko@003&#39;);</pre><ul><li>You can now generate text embeddings using the <a href="https://cloud.google.com/bigquery/docs/reference/standard-sql/bigqueryml-syntax-generate-embedding">ML.GENERATE_EMBEDDING</a> function:<br>- We use data from a public dataset table called imdb.reviews in this example.<br>- The text_embedding column is of type ARRAY&lt;FLOAT&gt; with 768-dimensions.</li></ul><pre>CREATE OR REPLACE TABLE test_embeddings.embedded_reviews<br>AS SELECT content as review, text_embedding<br>FROM<br>  ML.GENERATE_TEXT_EMBEDDING(<br>    MODEL `test_embeddings.llm_embedding_model`,<br>    (SELECT review as content<br>      FROM bigquery-public-data.imdb.reviews limit 8000<br>    ),<br>    STRUCT(TRUE AS flatten_json_output)<br>  );</pre><h4>Vector index</h4><ul><li>Create vector index on the embeddings column. Vector index enables Approximate Nearest Neighbor search to help improve vector search performance.<br>- Currently supported distance types are EUCLIDEAN (L2) and COSINE.<br>- Currently only IVF is supported for index type.<br>- The created index is fully managed by BigQuery, the refresh happens automatically as data changes.<br>- The metadata information of the vector index is available via <a href="https://cloud.google.com/bigquery/docs/information-schema-vector-indexes">INFORMATION_SCHEMA.VECTOR_INDEXES</a> view.</li></ul><pre>CREATE VECTOR INDEX embedded_reviews_idx ON test_embeddings.embedded_reviews(text_embedding) OPTIONS(distance_type = &#39;EUCLIDEAN&#39;, index_type=&#39;IVF&#39;);</pre><h4>Vector search</h4><ul><li>Use VECTOR_SEARCH function to perform text similarity search:<br>- It first generates embeddings from the text query, then compares them to the column `embeddings.embedded_reviews.text_embedding`.</li></ul><pre>SELECT<br>  *<br>FROM<br>  VECTOR_SEARCH( TABLE `embeddings.embedded_reviews`, &#39;text_embedding&#39;, (<br>    SELECT<br>      ml_generate_embedding_result,<br>      content AS query<br>    FROM<br>      ML.GENERATE_EMBEDDING( MODEL `embeddings.llm_embedding_model`,<br>        (<br>        SELECT &#39;Our family enjoyed this movie, especially the kids were so fascinated by the magical world&#39; AS content<br>        )) <br>    ),<br>    top_k =&gt; 5);</pre><p>Check the following links for more information:</p><ul><li><a href="https://cloud.google.com/bigquery/docs/vector-search">Search embeddings with vector¬†search</a></li><li>A <a href="https://github.com/steveloh/demo/blob/main/bigquery/notebook/BigQuery%20Embedding%20and%20Vector%20Search.ipynb">notebook</a> that I created to showcase embedding and vector search in BigQuery.</li></ul><h3>Vertex AI Vector¬†Search</h3><p>Vertex AI is a unified machine learning platform that simplifies and accelerates the end-to-end process of building, deploying, and managing ML models at scale. Vector Search (previously known as Matching Engine) provides highly scalable and performant vector similarity search.</p><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/1*6Qe6HxbxDsnrxlpgz5BGIA.png" /></figure><p>Following code snippets are based on¬†Python.</p><h4>Setup</h4><ul><li>Import aiplatform package:</li></ul><pre>from google.cloud import aiplatform<br>aiplatform.init(project=PROJECT_ID, location=LOCATION)</pre><ul><li>Vector Search does not provide services to generate embeddings. You can for example generate embeddings via BigQuery, then export the embeddings to a file in a storage bucket, before importing them into Vector¬†Search.</li></ul><h4>Vector index</h4><ul><li>Create a vector index endpoint, which is a server instance that accepts query requests for your¬†index.</li></ul><pre>my_index_endpoint = aiplatform.MatchingEngineIndexEndpoint.create(<br>    display_name = f&quot;index-endpoint-{PROJECT_ID}&quot;,<br>    public_endpoint_enabled = True<br>)</pre><ul><li>Create a vector search index:<br>- EMBEDDING_BUCKET_URI is where you store the files with embeddings, read here about the required <a href="https://cloud.google.com/vertex-ai/docs/vector-search/setup/format-structure">input data format and structure</a><br>- Approximate_neighbors_count specifies the number of neighbors to find through approximate search before exact reordering is performed.<br>- See here for available <a href="https://cloud.google.com/vertex-ai/docs/vector-search/configuring-indexes#distance-measure-type">distance measure¬†type</a>.</li></ul><pre><br>my_index = aiplatform.MatchingEngineIndex.create_tree_ah_index(<br>    display_name={DISPLAY_NAME},<br>    contents_delta_uri={EMBEDDING_BUCKET_URI},<br>    dimensions=768,<br>    approximate_neighbors_count=10,<br>    distance_measure_type=&quot;DOT_PRODUCT_DISTANCE&quot;,<br>)</pre><ul><li>Deploy the index to the index endpoint:</li></ul><pre>my_index_endpoint = my_index_endpoint.deploy_index(<br>    index=my_index, deployed_index_id = DEPLOYED_INDEX_ID<br>)</pre><h4>Vector search</h4><ul><li>Now you can search the vector index using a query embedding:</li></ul><pre># get the query embedding<br>model = TextEmbeddingModel.from_pretrained(&quot;textembedding-gecko@003&quot;)  <br>query = &quot;Our family enjoyed this movie, especially the kids were so fascinated by the magical world&quot;<br>query_embeddings = model.get_embeddings([query])[0]<br><br># query the index endpoint to find 3 nearest neighbors.<br>response = my_index_endpoint.find_neighbors(<br>    deployed_index_id=my_index_endpoint.deployed_indexes[0].id,<br>    queries=[query_embeddings.values],<br>    num_neighbors=3,<br>)</pre><p>I have created a <a href="https://github.com/steveloh/demo/blob/main/vertex/vector-search/vertex-vector-search-python-call.ipynb">notebook</a> to demonstrate how to do vector search in Vertex¬†AI.</p><h3>Summary</h3><p>2023 was the booming year of GenAI foundation models, while this year organizations will focus on building applications harnessing values from these models. This may include accelerating organization‚Äôs access to insights, improving productivity, streamlining operations and business processes and building innovative product services. Vector storage and vector search are the backbone for storing and organizing the rich semantic information to ground generative AI models. <strong>Their ability to handle various structures of data, power meaningful search, scale efficiently, and support rapid development makes them the ideal engine for the next generation of AI innovation.</strong></p><img src="https://medium.com/_/stat?event=post.clientViewed&referrerSource=full_rss&postId=46cedad68934" width="1" height="1" alt=""><hr><p><a href="https://medium.com/google-cloud/making-sense-of-vector-search-and-embeddings-across-gcp-products-46cedad68934">Making sense of Vector Search and Embeddings across GCP products</a> was originally published in <a href="https://medium.com/google-cloud">Google Cloud - Community</a> on Medium, where people are continuing the conversation by highlighting and responding to this story.</p>]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Deterministic Generative AI with Gemini Function Calling in Java]]></title>
            <link>https://medium.com/google-cloud/using-gemini-function-calling-in-java-for-deterministic-generative-ai-responses-4c86a5ab80a9?source=rss----e52cf94d98af---4</link>
            <guid isPermaLink="false">https://medium.com/p/4c86a5ab80a9</guid>
            <category><![CDATA[calling-function]]></category>
            <category><![CDATA[google-cloud-platform]]></category>
            <category><![CDATA[gcp-app-dev]]></category>
            <category><![CDATA[gemini]]></category>
            <category><![CDATA[generative-ai]]></category>
            <dc:creator><![CDATA[Abirami Sukumaran]]></dc:creator>
            <pubDate>Wed, 03 Apr 2024 04:48:45 GMT</pubDate>
            <atom:updated>2024-04-03T04:48:45.378Z</atom:updated>
            <content:encoded><![CDATA[<figure><img alt="" src="https://cdn-images-1.medium.com/max/738/1*cwsJqTsvzudgNKgCZqg8ow.png" /><figcaption>Navigate better with deterministic Generative AI &amp; Reverse Geocoding API</figcaption></figure><p>Generative AI models are remarkable at understanding and responding to natural language. But what if you need precise, predictable outputs for critical tasks like address standardization? Traditional generative models can sometimes provide different responses at different times for the same prompts, potentially leading to inconsistencies. That‚Äôs where Gemini‚Äôs Function Calling capability shines, allowing you to deterministically control elements of the AI‚Äôs response.</p><p>In this blog, we‚Äôll illustrate this concept with the address completion and standardization use case. For this we will be building a Java Cloud Function¬†that:</p><ol><li><strong>Takes latitude and longitude coordinates</strong></li><li><strong>Calls the Google Maps Geocoding API to get corresponding addresses</strong></li><li><strong>Uses Gemini 1.o Pro Function Calling feature to deterministically standardize and summarize those addresses in a specific format that we¬†need</strong></li></ol><p>Let‚Äôs dive¬†in!</p><h3>Gemini Function¬†Calling</h3><p>Gemini Function Calling stands out in the Generative AI era because it lets you blend the flexibility of generative language models with the precision of traditional programming. Here‚Äôs how it¬†works:</p><p><strong>Defining Functions:</strong> You describe functions as if you were explaining them to a coworker. These descriptions include:</p><ol><li>The function‚Äôs name (e.g., ‚ÄúgetAddress‚Äù)</li><li>The parameters it expects (e.g., ‚Äúlatlng‚Äù as a¬†string)</li><li>The type of data it returns (e.g., a list of address¬†strings)</li></ol><p><strong>‚ÄúTools‚Äù for Gemini:</strong> You package function descriptions in the form of API specification into ‚ÄúTools‚Äù. Think of a tool as a specialized toolbox Gemini can use to understand the functionality of the¬†API.</p><p><strong>Gemini as API Orchestrator:</strong> When you send a prompt to Gemini, it can analyze your request and recognize where it can use the tools you‚Äôve provided. Gemini then acts as a smart orchestrator:</p><ol><li>Generates API Parameters: It produces the necessary parameters to call your defined functions.</li><li>Calls External APIs: Gemini doesn‚Äôt call the API on your behalf. You call the API based on the parameters and signature that Gemini function calling has generated for¬†you.</li><li>Processes Results: Gemini feeds the results from your API calls back into its generation, letting it incorporate structured information into its final response which you can process in any way you desire for your application.</li></ol><h3>High Level Flow¬†Diagram</h3><p>This diagram represents the flow of data and steps involved in the implementation. Please note that the owner for the respective step is mentioned in the text underneath.</p><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/1*2-HYu2sGPsNwe46UdJuVdA.png" /><figcaption>High level flow diagram of the implementation</figcaption></figure><h3>Industry Use cases and why it¬†matters</h3><p>Below are some of the examples and industry specific use cases for function calling with¬†Gemini.</p><ol><li><strong>Geocoding (Our Use Case):</strong> You‚Äôve seen how to define a ‚ÄúgetAddress‚Äù function and use it within the context of address standardization.</li><li><strong>Data Validation:</strong> Imagine a function called ‚ÄúvalidateEmail‚Äù that takes a string and checks it against an email validation service. Gemini can help you formulate the parameters string so you can call the email validation API to ensure the quality of generated responses. Remember, Gemini does not make the API call for¬†you.</li><li><strong>Fact-Checking:</strong> Define a ‚ÄúlookupFact‚Äù function. Gemini could use this to consult a trusted knowledge base, making its responses more reliable within specific¬†domains.</li></ol><p><strong>Why Function Calling¬†Matters</strong></p><p><strong>Bridging Two Worlds:</strong> LLMs can‚Äôt know everything (especially private information, customer details, news that are more recent than its knowledge cut-off date), and by integrating function calling, it‚Äôs able to extend its knowledge and capabilities to bridge the gap between open-ended generative AI and the deterministic execution of traditional code.</p><p><strong>Controlled Creativity:</strong> Function Calling injects structured, predictable elements into Gemini‚Äôs creative process, ideal for critical use cases or maintaining consistency.</p><p><strong>Building Agent:</strong> Chain together multiple function calls and Gemini processing steps, enabling multi-stage generative AI workflows.</p><h3>Create the Java Cloud¬†Function</h3><p>This is the Gen 2 Cloud Function implementation where we will invoke the Gemini model to orchestrate the input for function Calling, invoke the API and then process the response in another Gemini call and deploy it to a REST endpoint.</p><h3>Setup</h3><ol><li>In the <a href="https://console.cloud.google.com/">Google Cloud Console</a>, on the project selector page, select or create a Google Cloud¬†<a href="https://cloud.google.com/resource-manager/docs/creating-managing-projects">project</a>.</li><li>Make sure that billing is enabled for your Cloud project. Learn how to <a href="https://cloud.google.com/billing/docs/how-to/verify-billing-enabled">check if billing is enabled on a¬†project</a>.</li><li>You will use Cloud Shell, a command-line environment running in Google Cloud that comes preloaded with bq. From the Cloud Console, click Activate Cloud Shell on the top right¬†corner.</li><li>Just for support with building and delivering the app, let‚Äôs enable Duet AI. Navigate to <a href="https://console.cloud.google.com/marketplace/product/google/cloudaicompanion.googleapis.com">Duet AI Marketplace</a> to enable the API. You can also run the following command in the Cloud Shell terminal:</li></ol><pre>gcloud services enable cloudaicompanion.googleapis.com ‚Äìproject PROJECT_ID</pre><p>5. Enable necessary APIs for this implementation if you haven‚Äôt¬†already.</p><p>Alternative to the gcloud command is through the console using this¬†<a href="https://console.cloud.google.com/apis/enableflow?apiid=bigquery.googleapis.com,bigqueryconnection.googleapis.com,aiplatform.googleapis.com">link</a>.</p><h3>Java Cloud¬†Function</h3><ol><li>Open Cloud Shell Terminal and navigate to the root directory or your default workspace path.</li><li>Click the Cloud Code Sign In icon from the bottom left corner of the status bar and select the active Google Cloud Project that you want to create the Cloud Functions in.</li><li>Click the same icon again and this time select the option to create a new application.</li><li>In the Create New Application pop-up, select Cloud Functions application:</li></ol><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/0*n53iiiF7ZuyG9J4U" /><figcaption>Create New Application page¬†1</figcaption></figure><p>5. Select Java: Hello World option from the next¬†pop-up:</p><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/0*jRH5u3oXSLqx-a_k" /><figcaption>Create New Application page¬†2</figcaption></figure><p>6. Provide a name for the project in the project path. In this case, ‚ÄúGeminiFunctionCalling‚Äù.</p><p>7. You should see the project structure opened up in a new Cloud Shell Editor¬†view:</p><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/0*z7PMp8qsGOUik2j1" /><figcaption>Cloud Shell Editor showing the project structure with pom.xml¬†open</figcaption></figure><p>8. Now go ahead and add the necessary dependencies within the &lt;dependencies&gt;‚Ä¶ &lt;/dependencies&gt; tag in the pom.xml file. You can access the entire <a href="https://github.com/AbiramiSukumaran/GeminiFunctionCalling/blob/main/pom.xml">pom.xml</a> from this project‚Äôs github <a href="https://github.com/AbiramiSukumaran/GeminiFunctionCalling">repository</a>.</p><pre>&lt;dependency&gt;<br>      &lt;groupId&gt;com.google.cloud&lt;/groupId&gt;<br>      &lt;artifactId&gt;google-cloud-vertexai&lt;/artifactId&gt;<br>&lt;/dependency&gt;<br><br>&lt;dependency&gt;<br>  &lt;groupId&gt;com.google.code.gson&lt;/groupId&gt;<br>  &lt;artifactId&gt;gson&lt;/artifactId&gt;<br>  &lt;version&gt;2.10&lt;/version&gt;<br>&lt;/dependency&gt;</pre><p>9. You can access the entire HelloWorld.java (or whatever you changed it to) class from the github <a href="https://github.com/AbiramiSukumaran/GeminiFunctionCalling/blob/main/src/main/java/cloudcode/helloworld/HelloWorld.java">link</a>. Let‚Äôs understand Function Calling by breaking down this¬†class:</p><p><strong>Prompt Input:<br></strong>In this example, this is what the input prompt looks¬†like:</p><pre>‚ÄúWhat&#39;s the address for the latlong value 40.714224,-73.961452‚Äù</pre><p>You can find the below code snippet relevant to the input prompt in the¬†file:</p><pre>String promptText = &quot;What&#39;s the address for the latlong value &#39;&quot; + latlngString + &quot;&#39;?&quot;; //40.714224,-73.961452</pre><p><strong>API Specification / Signature Definition:<br></strong>We decided to use the <a href="https://developers.google.com/maps/documentation/geocoding/requests-reverse-geocoding">Reverse Geocoding API</a>. In this example, this is what the API spec looks¬†like:</p><pre>/* Declare the function for the API that we want to invoke (Geo coding API) */<br>      FunctionDeclaration functionDeclaration = FunctionDeclaration.newBuilder()<br>          .setName(&quot;getAddress&quot;)<br>          .setDescription(&quot;Get the address for the given latitude and longitude value.&quot;)<br>          .setParameters(<br>              Schema.newBuilder()<br>                  .setType(Type.OBJECT)<br>                  .putProperties(&quot;latlng&quot;, Schema.newBuilder()<br>                      .setType(Type.STRING)<br>                      .setDescription(&quot;This must be a string of latitude and longitude coordinates separated by comma&quot;)<br>                      .build())<br>                  .addRequired(&quot;latlng&quot;)<br>                  .build())<br>          .build();</pre><p><strong>Gemini to orchestrate the prompt with the API specification:<br></strong>This is the part where we send the prompt input and the API spec to¬†Gemini:</p><pre>// Add the function to a &quot;tool&quot;<br> Tool tool = Tool.newBuilder()<br> .addFunctionDeclarations(functionDeclaration)<br> .build();<br><br><br>// Invoke the Gemini model with the use of the  tool to generate the API parameters from the prompt input.<br>GenerativeModel model = GenerativeModel.newBuilder()<br> .setModelName(modelName)<br> .setVertexAi(vertexAI)<br> .setTools(Arrays.asList(tool))<br> .build();<br>GenerateContentResponse response = model.generateContent(promptText);<br>Content responseJSONCnt = response.getCandidates(0).getContent();</pre><p>The response from this is the orchestrated parameters JSON to the API. Output from this step would look like¬†below:</p><pre>role: &quot;model&quot;<br>parts {<br>  function_call {<br>    name: &quot;getAddress&quot;<br>    args {<br>      fields {<br>        key: &quot;latlng&quot;<br>        value {<br>          string_value: &quot;40.714224,-73.961452&quot;<br>        }<br>      }<br>    }<br>  }<br>}</pre><p>The parameter that needs to be passed to the Reverse Geocoding API is¬†this:</p><p>‚Äúlatlng=40.714224,-73.961452‚Äù</p><p>From the Content object, you can get the Part, call the hasFunctionCall() method to know if it has a function call request that‚Äôs returned by the LLM. Call getFunctionCall() to get a FunctionCall object. Use the hasArgs() method to check if there are arguments, and then a getArgs() method to get the actual arguments. It‚Äôs a protobuf Struct object. Match the orchestrated result to the format ‚Äúlatlng=VALUE‚Äù. Refer to the full code¬†<a href="https://github.com/AbiramiSukumaran/GeminiFunctionCalling/blob/main/src/main/java/cloudcode/helloworld/HelloWorld.java">here</a>.</p><p><strong>Invoke the API:<br></strong>At this point you have everything you need to invoke the API. The part of the code that does it is¬†below:</p><pre>// Create a request<br>      String url = API_STRING + &quot;?key=&quot; + API_KEY + params;<br>      java.net.http.HttpRequest request = java.net.http.HttpRequest.newBuilder()<br>          .uri(URI.create(url))<br>          .GET()<br>          .build();<br>      // Send the request and get the response<br>      java.net.http.HttpResponse&lt;String&gt; httpresponse = client.send(request, java.net.http.HttpResponse.BodyHandlers.ofString());<br>      // Save the response<br>      String jsonResult =  httpresponse.body().toString();</pre><p>The string jsonResult holds the stringified response from the reverse Geocoding API. It looks something like this: (This is a formatted version of the output. Please note the result is truncated as¬†well).</p><pre>‚Äú...277 Bedford Ave, Brooklyn, NY 11211, USA; 279 Bedford Ave, Brooklyn, NY 11211, USA; 277 Bedford Ave, Brooklyn, NY 11211, USA;...‚Äù</pre><p><strong>Process the API response and prepare the prompt:<br></strong>The below code processes the response from the API and prepares the prompt with instructions on how to process the response:</p><pre>// Provide an answer to the model so that it knows what the result<br>      // of a &quot;function call&quot; is.<br>      String promptString =<br>      &quot;You are an AI address standardizer for assisting with standardizing addresses accurately. Your job is to give the accurate address in the standard format as a JSON object containing the fields DOOR_NUMBER, STREET_ADDRESS, AREA, CITY, TOWN, COUNTY, STATE, COUNTRY, ZIPCODE, LANDMARK by leveraging the address string that follows in the end. Remember the response cannot be empty or null. &quot;;<br><br><br>Content content =<br>          ContentMaker.fromMultiModalData(<br>              PartMaker.fromFunctionResponse(<br>                  &quot;getAddress&quot;,<br>                  Collections.singletonMap(&quot;address&quot;, formattedAddress)));<br>      String contentString = content.toString();<br>      String address = contentString.substring(contentString.indexOf(&quot;string_value: \&quot;&quot;) + &quot;string_value: \&quot;&quot;.length(), contentString.indexOf(&#39;&quot;&#39;, contentString.indexOf(&quot;string_value: \&quot;&quot;) + &quot;string_value: \&quot;&quot;.length()));<br><br><br>      List&lt;SafetySetting&gt; safetySettings = Arrays.asList(<br>        SafetySetting.newBuilder()<br>            .setCategory(HarmCategory.HARM_CATEGORY_HATE_SPEECH)<br>            .setThreshold(SafetySetting.HarmBlockThreshold.BLOCK_ONLY_HIGH)<br>            .build(),<br>        SafetySetting.newBuilder()<br>            .setCategory(HarmCategory.HARM_CATEGORY_DANGEROUS_CONTENT)<br>            .setThreshold(SafetySetting.HarmBlockThreshold.BLOCK_ONLY_HIGH)<br>            .build()<br>    );</pre><p><strong>Invoke Gemini and return the standardized address¬†:<br></strong>The below code passes the processed output from the above step as prompt to¬†Gemini:</p><pre>GenerativeModel modelForFinalResponse = GenerativeModel.newBuilder()<br>      .setModelName(modelName)<br>      .setVertexAi(vertexAI)<br>      .build();<br>      GenerateContentResponse finalResponse = modelForFinalResponse.generateContent(promptString + &quot;: &quot; + address, safetySettings);<br>       System.out.println(&quot;promptString + content: &quot; + promptString + &quot;: &quot; + address);<br>        // See what the model replies now<br>        System.out.println(&quot;Print response: &quot;);<br>        System.out.println(finalResponse.toString());<br>        String finalAnswer = ResponseHandler.getText(finalResponse);<br>        System.out.println(finalAnswer);</pre><p>The finalAnswer variable has the standardized address in JSON format. Sample output¬†below:</p><pre>{&quot;replies&quot;:[&quot;{ \&quot;DOOR_NUMBER\&quot;: null, \&quot;STREET_ADDRESS\&quot;: \&quot;277 Bedford Ave\&quot;, \&quot;AREA\&quot;: \&quot;Brooklyn\&quot;, \&quot;CITY\&quot;: \&quot;New York\&quot;, \&quot;TOWN\&quot;: null, \&quot;COUNTY\&quot;: null, \&quot;STATE\&quot;: \&quot;NY\&quot;, \&quot;COUNTRY\&quot;: \&quot;USA\&quot;, \&quot;ZIPCODE\&quot;: \&quot;11211\&quot;, \&quot;LANDMARK\&quot;: null} null}&quot;]}</pre><p>Now that you have understood how Gemini Function Calling works with the address standardization use case, go ahead and deploy the Cloud Function.</p><p>10. Now that you have understood how Gemini Function Calling works with the address standardization use case, go ahead and deploy the Cloud Function.</p><pre>gcloud functions deploy gemini-fn-calling --gen2 --region=us-central1 --runtime=java11 --source=. --entry-point=cloudcode.helloworld.HelloWorld --trigger-http</pre><p>The result for this deploy command would be a REST URL in the format as below¬†:</p><p><a href="https://us-central1-YOUR_PROJECT_ID.cloudfunctions.net/gemini-fn-calling"><strong>https://us-central1-YOUR_PROJECT_ID.cloudfunctions.net/gemini-fn-calling</strong></a></p><p>11. Test this Cloud Function by running the following command from the terminal:</p><pre>gcloud functions call gemini-fn-calling --region=us-central1 --gen2 --data &#39;{&quot;calls&quot;:[[&quot;40.714224,-73.961452&quot;]]}&#39;</pre><p>Response for a random sample¬†prompt:</p><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/0*L2ME8WPaWun8XBIX" /><figcaption>Cloud Shell Terminal response for the Cloud Function¬†call</figcaption></figure><pre>  &#39;{&quot;replies&quot;:[&quot;{ \&quot;DOOR_NUMBER\&quot;: \&quot;277\&quot;, \&quot;STREET_ADDRESS\&quot;: \&quot;Bedford Ave\&quot;, \&quot;AREA\&quot;:<br>  null, \&quot;CITY\&quot;: \&quot;Brooklyn\&quot;, \&quot;TOWN\&quot;: null, \&quot;COUNTY\&quot;: \&quot;Kings County\&quot;, \&quot;STATE\&quot;:<br>  \&quot;NY\&quot;, \&quot;COUNTRY\&quot;: \&quot;USA\&quot;, \&quot;ZIPCODE\&quot;: \&quot;11211\&quot;, \&quot;LANDMARK\&quot;: null}}```&quot;]}&#39;</pre><p>The request and response parameters of this Cloud Function are implemented in a way that is compatible with BigQuery‚Äôs remote function invocation. It can be directly consumed from BigQuery data in-place. It means that if your data input (lat and long data) lives in BigQuery then you can call the remote function on the data and get the function response which can be stored or processed within BigQuery directly. To learn how to leverage this Cloud Function in performing in-place LLM insights on your database, refer to this¬†<a href="https://medium.com/google-cloud/in-place-llm-insights-bigquery-gemini-for-structured-unstructured-data-analytics-fdfac0421626">blog</a>.</p><h3>Conclusion</h3><p>This project has demonstrated the power of Gemini Function Calling, transforming a generative AI task into a deterministic, reliable process. If you work with generative AI, don‚Äôt let its sometimes-unpredictable nature hold you back. Use the power of Gemini 1.0 Pro Function Calling feature and create applications that are as innovative as they are dependable. Start exploring how you can incorporate this feature into your own work! Are there datasets you could validate, information gaps you could fill, or tasks that could be automated with structured calls embedded within your generative AI responses? Here is the link to the <a href="https://github.com/AbiramiSukumaran/GeminiFunctionCalling">repo</a> and for further reading, refer to the documentation for <a href="https://cloud.google.com/vertex-ai">Vertex AI</a>, <a href="https://cloud.google.com/bigquery/docs/remote-functions">BigQuery Remote Functions</a>, and <a href="https://cloud.google.com/functions">Cloud Functions</a> for more in-depth guidance in these¬†areas.</p><img src="https://medium.com/_/stat?event=post.clientViewed&referrerSource=full_rss&postId=4c86a5ab80a9" width="1" height="1" alt=""><hr><p><a href="https://medium.com/google-cloud/using-gemini-function-calling-in-java-for-deterministic-generative-ai-responses-4c86a5ab80a9">Deterministic Generative AI with Gemini Function Calling in Java</a> was originally published in <a href="https://medium.com/google-cloud">Google Cloud - Community</a> on Medium, where people are continuing the conversation by highlighting and responding to this story.</p>]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Multi-Stage Builds in Kubernetes]]></title>
            <description><![CDATA[<div class="medium-feed-item"><p class="medium-feed-image"><a href="https://medium.com/google-cloud/multi-stage-builds-in-kubernetes-83d9916c8ffa?source=rss----e52cf94d98af---4"><img src="https://cdn-images-1.medium.com/max/1400/1*rjQc0TCvBrqfDsDO-xlXGA.png" width="1400"></a></p><p class="medium-feed-snippet">As developers constantly seek ways to optimize our workflows without compromising on quality or security. Enter multi-stage builds in&#x2026;</p><p class="medium-feed-link"><a href="https://medium.com/google-cloud/multi-stage-builds-in-kubernetes-83d9916c8ffa?source=rss----e52cf94d98af---4">Continue reading on Google Cloud - Community ¬ª</a></p></div>]]></description>
            <link>https://medium.com/google-cloud/multi-stage-builds-in-kubernetes-83d9916c8ffa?source=rss----e52cf94d98af---4</link>
            <guid isPermaLink="false">https://medium.com/p/83d9916c8ffa</guid>
            <category><![CDATA[programming]]></category>
            <category><![CDATA[google-cloud-platform]]></category>
            <category><![CDATA[software-development]]></category>
            <category><![CDATA[kubernetes]]></category>
            <category><![CDATA[devops]]></category>
            <dc:creator><![CDATA[The kube guy]]></dc:creator>
            <pubDate>Wed, 03 Apr 2024 04:48:07 GMT</pubDate>
            <atom:updated>2024-04-03T04:48:07.575Z</atom:updated>
        </item>
        <item>
            <title><![CDATA[How Google Admins can Save Money by Understanding the Relationship between Google Cloud Identity‚Ä¶]]></title>
            <link>https://medium.com/google-cloud/how-google-admins-can-save-money-by-understanding-the-relationship-between-google-cloud-identity-e4ad6d3f844c?source=rss----e52cf94d98af---4</link>
            <guid isPermaLink="false">https://medium.com/p/e4ad6d3f844c</guid>
            <category><![CDATA[google-cloud-platform]]></category>
            <category><![CDATA[google-workspace]]></category>
            <category><![CDATA[identity-management]]></category>
            <category><![CDATA[cloud-identity]]></category>
            <category><![CDATA[google-cloud-identity]]></category>
            <dc:creator><![CDATA[Allan Alfonso]]></dc:creator>
            <pubDate>Wed, 03 Apr 2024 04:47:47 GMT</pubDate>
            <atom:updated>2024-04-03T16:01:41.269Z</atom:updated>
            <content:encoded><![CDATA[<h3>How Google Admins can Save Money by Understanding the Relationship between Google Cloud Identity, Google Workspace, and Google¬†Cloud</h3><figure><img alt="" src="https://cdn-images-1.medium.com/max/694/1*M8Tafmr1Dp7vaKFyAQZ8eQ.png" /><figcaption>Google Cloud¬†Identity</figcaption></figure><h3>What is Google Cloud Identity?</h3><p>Google Cloud Identity is Google‚Äôs identity provider (idP) that is used by both Workspace and Google¬†Cloud.</p><p>To access it, goto <a href="http://admin.google.com">admin.google.com</a>. There are <a href="https://support.google.com/cloudidentity/answer/7431902">two versions</a>: <strong>Cloud Identity Free and Cloud Identity Premium</strong>. The premium version includes all the features of the free version and adds endpoint device and security capabilities.</p><p>By default, <strong>Cloud Identity Free includes 50 free licenses</strong> but you can request more free licenses by following these <a href="https://cloud.google.com/identity/pricing">instructions</a>.</p><h3>Do I need to purchase a Google Workspace license to use Google¬†Cloud?</h3><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/1*Bl2gkJCR4jIX-yfbC7D10Q.png" /><figcaption>The Licenses Assigned to a¬†User</figcaption></figure><p>No.</p><p>Users think they need a Google Workspace license to use Google Cloud because Google asks you to try Google Workspace when you sign up using a <a href="mailto:you@your-company.com"><strong>you@your-company.com</strong></a> email address. You will have to select a Google Workspace trial but you can cancel it before the trial period ends so you are not charged. Behind the scenes, a Cloud Identity license is provisioned and you can verify the licenses a user has by going to ‚Äú<strong>Directory ‚Üí Users ‚Üí &lt;user&gt; ‚Üí Licenses</strong>‚Äù.</p><p>Google Workspace and Cloud Identity licenses are separated so Google Workspace does not become a requirement to use Google¬†Cloud.</p><figure><img alt="" src="https://cdn-images-1.medium.com/max/468/1*d4Gc71k1hISpOy1JQRECyA.png" /><figcaption>No Licenses¬†Error</figcaption></figure><p>Another source of confusion is when you get a ‚Äú<strong>No license available for new user</strong>‚Äù error when creating a new Google Cloud user in Cloud Identity.</p><p>The error message says to purchase more Google Workspace licenses so users think they need more Google Workspace licenses to use Google Cloud. To resolve this error, goto ‚Äú<strong>Billing ‚Üí License settings</strong>‚Äù and <a href="https://knowledge.workspace.google.com/kb/how-to-manage-automatic-licensing-settings-000006369"><strong>disable ‚ÄúAutomatic Licensing</strong></a><strong>‚Äù</strong>. Automatic Licensing automatically assigns a Google Workspace license and throws an error if there are no more Google Workspace licenses left. By disabling automatic licensing, only Cloud Identity Free licenses will be assigned to new users so you do not have to purchase additional Google Workspace licenses.</p><p>If you need a mix of Workspace and non-Workspace users, manually assign the Workspace and Cloud Identity licenses to the respective users.</p><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/1*avDprGdypI6xMAIFl-uWlg.png" /><figcaption>Disable Automatic Licensing</figcaption></figure><h3>Can I get Cloud Identity Premium for¬†Free?</h3><p>A lot of people don‚Äôt know that <a href="https://support.google.com/a/answer/6043385?co=DASHER._Family=Enterprise&amp;sjid=17574536566002910901-NA"><strong>Cloud Identity Premium is included with Google Workspace Enterprise Editions</strong></a><strong>.</strong></p><p>If you‚Äôre already a Google Workspace customer and are interested in the security and device management features of <a href="https://support.google.com/cloudidentity/answer/7431902">Cloud Identity Premium</a>, then talk to your account team about upgrading to <a href="https://support.google.com/a/answer/6043385?co=DASHER._Family%3DEnterprise&amp;oco=0">Google Workspace Enterprise Edition</a>. You can save money and get additional features by bundling Google Workspace and Cloud Identity Premium together.</p><p>From my experience, the additional features of Google Workspace Enterprise Edition that users find most valuable are data loss prevention, context-aware access (aka Zero Trust access), and a larger number of participants in Google¬†Meet.</p><h3>Summary</h3><ul><li>Google Cloud Identity is Google‚Äôs Identity Provider for Google Services.</li><li>Google Workspace is not required to use Google Cloud. Save money by not purchasing unnecessary Workspace licenses.</li><li>Disable Automatic Licensing and manually assign Workspace and Cloud Identity licenses to have a mix of Workspace and Non-Workspace users. Save money by only purchasing the correct number of licenses for your Workspace users.</li><li>Save money by getting Cloud Identity Premium free with a Google Workspace Enterprise Edition subscription.</li></ul><h3>Free Training</h3><p>Upgrade your Cloud Identity Skills with this FREE course from Coursera.</p><p><a href="https://www.coursera.org/learn/cloud-identity">Introduction to Cloud Identity</a></p><p>And this FREE YouTube course from <a href="https://www.goldyarora.com/">Goldy¬†Arora</a>.</p><iframe src="https://cdn.embedly.com/widgets/media.html?src=https%3A%2F%2Fwww.youtube.com%2Fembed%2Fs149kAiuCns%3Flist%3DPLTLVpWeD3u6GnRvDXAGt-oDNIS3gds-3R&amp;display_name=YouTube&amp;url=https%3A%2F%2Fwww.youtube.com%2Fwatch%3Fv%3Ds149kAiuCns&amp;image=https%3A%2F%2Fi.ytimg.com%2Fvi%2Fs149kAiuCns%2Fhqdefault.jpg&amp;key=a19fcc184b9711e1b4764040d3dc5c07&amp;type=text%2Fhtml&amp;schema=youtube" width="854" height="480" frameborder="0" scrolling="no"><a href="https://medium.com/media/96db9f22dc1ac6679bc5b0f36c3f18ed/href">https://medium.com/media/96db9f22dc1ac6679bc5b0f36c3f18ed/href</a></iframe><h3>Resources</h3><ul><li><a href="https://cloud.google.com/files/10909_Cloud_Identity_OnePager_V6.pdf">Cloud Identity One¬†Pager</a></li><li><a href="https://support.google.com/a/answer/6043385">Compare Google Workspace Editions</a></li><li><a href="https://www.goldyarora.com/blog/ci-gcp-ws">Google Cloud Identity vs Google Workspace vs Google Cloud¬†Platform</a></li><li><a href="https://support.google.com/cloudidentity/answer/7338389?hl=en">Turn off automatic Google Workspace licensing during¬†setup</a></li><li><a href="https://support.google.com/a/answer/6342682">About automatic licensing for organizational units</a></li><li><a href="https://knowledge.workspace.google.com/kb/how-to-manage-automatic-licensing-settings-000006369">How to manage automatic licensing settings</a></li><li><a href="https://cloud.google.com/resource-manager/docs/creating-managing-organization">Creating and managing organization resources</a></li><li><a href="https://cloud.google.com/blog/topics/developers-practitioners/identity-access-management-authentication-cloud-identity">Identity &amp; Access management: Authentication with Cloud¬†Identity</a></li></ul><img src="https://medium.com/_/stat?event=post.clientViewed&referrerSource=full_rss&postId=e4ad6d3f844c" width="1" height="1" alt=""><hr><p><a href="https://medium.com/google-cloud/how-google-admins-can-save-money-by-understanding-the-relationship-between-google-cloud-identity-e4ad6d3f844c">How Google Admins can Save Money by Understanding the Relationship between Google Cloud Identity‚Ä¶</a> was originally published in <a href="https://medium.com/google-cloud">Google Cloud - Community</a> on Medium, where people are continuing the conversation by highlighting and responding to this story.</p>]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Shh, It‚Äôs Free: But Let‚Äôs Not Tell Google! Exploring Gemini‚Äôs Multimodal Capabilities on Vertex AI]]></title>
            <link>https://medium.com/google-cloud/shh-its-free-but-let-s-not-tell-google-exploring-gemini-s-multimodal-capabilities-on-vertex-ai-ca3cb7e33c3e?source=rss----e52cf94d98af---4</link>
            <guid isPermaLink="false">https://medium.com/p/ca3cb7e33c3e</guid>
            <category><![CDATA[llm]]></category>
            <category><![CDATA[large-language-models]]></category>
            <category><![CDATA[google-gemini]]></category>
            <category><![CDATA[generative-ai]]></category>
            <category><![CDATA[google-cloud-platform]]></category>
            <dc:creator><![CDATA[Rif Kiamil]]></dc:creator>
            <pubDate>Wed, 03 Apr 2024 04:47:38 GMT</pubDate>
            <atom:updated>2024-04-04T17:01:00.109Z</atom:updated>
            <content:encoded><![CDATA[<figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/1*QNpoBmHA_tukDSw-Wt70QQ.jpeg" /></figure><p>Google might not trumpet the news, but there‚Äôs a quiet revolution unfolding on their platform. The Gemini Experimental model is our unheralded entry into the world of AI without the cost. This is where the multimodal capabilities of AI come to life, won‚Äôt cost you a dime. Consider this your backdoor pass into a free club, where the only membership requirement is your curiosity.</p><p><strong>Edited on 4th April 2024 to include new information.</strong></p><blockquote>Until now, the nature of Gemini Experimental was unclear. However, based on this Google Cloud console page, it appears to be related to Gemini 1.5¬†Pro.</blockquote><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/1*Ed4K7NQ_fSz6bHYaKCPlTA.png" /></figure><h3>Here‚Äôs the Whispered Truth:</h3><p>Google might play it cool, but they‚Äôve hinted at the excitement themselves:</p><blockquote><em>‚ÄúBy using the Gemini Experimental model, you are contributing to the development of even better responses. Results may be genius or delightfully unpredictable, all at no¬†cost.‚Äù</em></blockquote><p>üåü Try it out here: <a href="https://console.cloud.google.com/vertex-ai/generative/multimodal/create/">Google Vertex¬†AI</a></p><h3>How to Get¬†Involved</h3><p>Navigating through Google Vertex AI to tap into the powers of the Gemini Experimental model is your first step into a broader world of AI possibilities. Here‚Äôs a straightforward guide to get you¬†started:</p><h4>1. Select the¬†Model:</h4><p>1.1. Navigate to the model selection area of the Google Vertex AI platform. 1.2. Look for and select the ‚ÄòGemini Experimental‚Äô option. Once selected, you‚Äôll notice in the results section of the screen an ‚ÄúEXPERIMENTAL‚Äù label in blue, clearly indicating that you are using the Gemini Experimental mode. <br>1.3. To understand the current terms of use, hover your mouse over the information (i) icon. <br>1.4. At the time of writing, the terms stated: ‚Äú<strong><em>By using the Gemini Experimental model, you are contributing to the development of even better responses. Results may be genius or delightfully unpredictable, all at no¬†cost.</em></strong>‚Äù</p><figure><img alt="1.1 Navigate to the model selection area of the Google Vertex AI platform. 1.2 Look for the ‚ÄòGemini Experimental‚Äô option. You‚Äôll recognize it by the ‚ÄúEXPERIMENTAL‚Äù label in blue, indicating that it‚Äôs a model currently in testing." src="https://cdn-images-1.medium.com/max/1024/0*eUmRK39n7jDY_V56" /></figure><h4>2. Understand What You‚Äôre Getting¬†Into:</h4><p>Before you dive in, take a moment to understand what ‚ÄòExperimental‚Äô entails. As per the screenshot you provided, Google informs us that using the Gemini Experimental model allows you to contribute to the enhancement of the AI‚Äôs responses. The outcomes you receive may range from ‚Äúgenius‚Äù to ‚Äúdelightfully unpredictable.‚Äù</p><h4>3. Contribute to Development:</h4><p>By choosing the Gemini Experimental model, you‚Äôre not just accessing an AI tool; you‚Äôre part of a collaborative development effort. Your usage and feedback can help improve the model for future¬†users.</p><h4>4. Set Your Expectations:</h4><p>As with any experimental model, prepare for a range of results. They may not always be what you expect, but that‚Äôs part of the excitement and the learning experience.</p><h4>5. Monitor the Fine¬†Print:</h4><p>Stay informed about any updates to the terms and conditions related to the use of the experimental model. These can impact your usage and¬†data.</p><h4>6. Rate Limitations</h4><p>As an experimental model, Gemini Experimental is not designed for production-level tasks. It may come with rate limitations</p><h4>7. No documentation</h4><p>As a Google Developer Expert, I‚Äôve inquired about official documentation for the Gemini Experimental model within Google‚Äôs internal channels. It appears that, as of now, there is no formal documentation available. So, dive in, enjoy the novelty while it‚Äôs available, and remember‚Ää‚Äî‚Ääalways read the label for the most current information.</p><h4>Community</h4><p>Let the community know about your findings and experiences by using the hashtag #BuildWithGemini. Whether your results were unexpectedly brilliant or whimsically unpredictable, your insights are valuable to the ongoing development and understanding of Gemini‚Äôs potential.</p><p>Begin Your AI Journey üõ§Ô∏è: Navigate to the Gemini Experimental model via the <a href="https://console.cloud.google.com/vertex-ai/generative/multimodal/create/">Google Vertex¬†AI</a></p><h3>What else is free on¬†Google?</h3><p>BigQuery, Google Cloud‚Äôs serverless data warehouse, offers a powerful platform for data analysis. The best part? You can get started for free (like Google Gemini Experimental) without even having to provide a credit card. BigQuery‚Äôs Sandbox allows you to explore public datasets and run queries, making it perfect for learning and experimentation.</p><p>Ready to dive in? Here are some exciting public datasets and sample queries to get you¬†started:</p><p><strong>1. Hacker News: (bigquery-public-data.hacker_news.full)</strong></p><pre>-- This query finds the number of posts made by each author.<br>SELECT author, COUNT(*) AS post_count FROM `bigquery-public-data.hacker_news.full` GROUP BY author;</pre><p><strong>2. NOAA Weather Data: (bigquery-public-data.noaa_gsod.gsod2023)</strong></p><pre>-- This query calculates the average temperature for each weather station.<br>SELECT station_number, AVG(mean_temp) AS avg_temp FROM `bigquery-public-data.noaa_gsod.gsod2023` GROUP BY station_number;</pre><p><strong>3. Chicago Crime Data: (bigquery-public-data.chicago.crimes_2001_to_present)</strong></p><pre>-- This query shows the count of crimes for each primary type.<br>SELECT primary_type, COUNT(*) AS crime_count FROM `bigquery-public-data.chicago.crimes_2001_to_present` GROUP BY primary_type;</pre><p><strong>4. Ethereum Blockchain: (crypto_ethereum)</strong></p><pre>-- This query finds the number of transactions in each block.<br>SELECT block_number, COUNT(*) AS transaction_count FROM `crypto_ethereum.blocks` GROUP BY block_number;</pre><p>Ready to start exploring? Follow my <a href="https://rifkiamil.medium.com/step-by-step-guide-of-bigquery-sandbox-4429d9655d8e">step-by-step guide</a> on setting up your free BigQuery¬†Sandbox:</p><p>With just a few clicks, you‚Äôll be ready to analyze these datasets and many more, unlocking valuable insights with BigQuery‚Äôs powerful analytics engine.</p><img src="https://medium.com/_/stat?event=post.clientViewed&referrerSource=full_rss&postId=ca3cb7e33c3e" width="1" height="1" alt=""><hr><p><a href="https://medium.com/google-cloud/shh-its-free-but-let-s-not-tell-google-exploring-gemini-s-multimodal-capabilities-on-vertex-ai-ca3cb7e33c3e">Shh, It‚Äôs Free: But Let‚Äôs Not Tell Google! Exploring Gemini‚Äôs Multimodal Capabilities on Vertex AI</a> was originally published in <a href="https://medium.com/google-cloud">Google Cloud - Community</a> on Medium, where people are continuing the conversation by highlighting and responding to this story.</p>]]></content:encoded>
        </item>
    </channel>
</rss>