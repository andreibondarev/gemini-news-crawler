<?xml version="1.0" encoding="UTF-8"?><rss xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" version="2.0" xmlns:cc="http://cyber.law.harvard.edu/rss/creativeCommonsRssModule.html">
    <channel>
        <title><![CDATA[Google Cloud - Community - Medium]]></title>
        <description><![CDATA[A collection of technical articles and blogs published or curated by Google Cloud Developer Advocates. The views expressed are those of the authors and don&#39;t necessarily reflect those of Google. - Medium]]></description>
        <link>https://medium.com/google-cloud?source=rss----e52cf94d98af---4</link>
        <image>
            <url>https://cdn-images-1.medium.com/proxy/1*TGH72Nnw24QL3iV9IOm4VA.png</url>
            <title>Google Cloud - Community - Medium</title>
            <link>https://medium.com/google-cloud?source=rss----e52cf94d98af---4</link>
        </image>
        <generator>Medium</generator>
        <lastBuildDate>Sun, 31 Mar 2024 21:01:20 GMT</lastBuildDate>
        <atom:link href="https://medium.com/feed/google-cloud" rel="self" type="application/rss+xml"/>
        <webMaster><![CDATA[yourfriends@medium.com]]></webMaster>
        <atom:link href="http://medium.superfeedr.com" rel="hub"/>
        <item>
            <title><![CDATA[Google Cloud Platform Technology Nuggets — March 16–31, 2024 Edition]]></title>
            <link>https://medium.com/google-cloud/google-cloud-platform-technology-nuggets-march-16-31-2024-edition-beddfd742deb?source=rss----e52cf94d98af---4</link>
            <guid isPermaLink="false">https://medium.com/p/beddfd742deb</guid>
            <category><![CDATA[tech-nuggets]]></category>
            <category><![CDATA[gcp-weekly]]></category>
            <category><![CDATA[google-cloud-platform]]></category>
            <dc:creator><![CDATA[Romin Irani]]></dc:creator>
            <pubDate>Sun, 31 Mar 2024 11:51:20 GMT</pubDate>
            <atom:updated>2024-03-31T11:51:20.433Z</atom:updated>
            <content:encoded><![CDATA[<h3>Google Cloud Platform Technology Nuggets — March 16–31, 2024 Edition</h3><p>Welcome to the March 16–31, 2024 edition of Google Cloud Platform Technology Nuggets.</p><p>Please feel free to give <a href="https://forms.gle/UAsAS7YLxYSBTNBy9">feedback</a> on this issue and share the <a href="https://gcptechnuggets.substack.com/">subscription form</a> with your peers.</p><h3>Google Cloud Next 2024</h3><p>We are less than 10 days away from the biggest Google Cloud Event of the year and the excitement is building up. This year, the event is expected to have a large number of technical sessions, based on the feedback received last year.</p><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/0*QCWF8kgUU95aY0HA.jpg" /></figure><p>Several blog posts have started to highlight key sessions to attend from the respective areas: Networking, Dev Practitioners and more. Even if you are not there at the conference, these posts are good reference points to start building out sessions that you would like to watch once they are posted online.</p><p>Here are some of them:</p><ul><li><strong>Dev Connect at Next ’24</strong>: This is one of the key themes of the conference and the <a href="https://cloud.google.com/blog/topics/google-cloud-next/dev-connect-at-next24">post</a> highlights some specific sessions, areas to hang out with fellow practitioners and this is not just for Google Cloud but how all other services Firebase, Android and more come together.</li><li><strong>Networking Sessions</strong>: 12 must attend networking and network security sessions at Next ’24. Check out the <a href="https://cloud.google.com/blog/products/networking/networking-session-preview-at-next24">post</a>.</li></ul><p>If you are into managing IT, then there is a constant pressure to streamline your infrastructure, manage it seamlessly and keep costs at a minimum. Right, isn’t it? An interesting <a href="https://cloud.google.com/blog/products/compute/breakout-sessions-for-it-pros-at-next24">post</a> highlights top 5 questions IT pros have been asking ranging from reducing costs, evaluating reliability of cloud providers, AI infrastructure, scalability and control requirements and more. The post further highlights the sessions where these questions are likely to get answered. Build out that agenda, I tell you.</p><h3>Infrastructure</h3><p>Forrester Research has recognized Google as a Leader in The Forrester Wave™: AI Infrastructure Solutions, Q1 2024. Google received the highest scores of any vendor evaluated in both Current Offering and Strategy categories in the report. Check out the <a href="https://cloud.google.com/blog/products/infrastructure-modernization/google-named-a-leader-in-the-forrester-wave-ai-infrastructure-solutions-q1-2024">post</a> and download the <a href="https://inthecloud.withgoogle.com/forrester-2024-ai-infra-wave/dl-cd.html?_ga=2.73419927.-428458833.1709094666&amp;_gac=1.195768030.1710843694.CjwKCAjwzN-vBhAkEiwAYiO7oHLj_RGrKSAo4oJDQU2SjU77HFVCySA9Xf8sfel4d3tEe32CenfQghoCEcAQAvD_BwE&amp;_gl=1*1t5omrr*_ga*NDI4NDU4ODMzLjE3MDkwOTQ2NjY.*_ga_WH2QY8WWF5*MTcxMTg3Njc5MS4yLjEuMTcxMTg3OTIwMi4wLjAuMA..">report</a>.</p><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/1*dtl-shtgVZJt9TX7IzHaYw.png" /></figure><p>NVIDIA NeMo is an open-source, end-to-end platform purpose-built for developing custom, enterprise-grade generative AI models. Looking to train models on Google Kubernetes Engine (FGKE) using NVIDIA accelerated computing and NVIDIA NeMo framework? Check out the <a href="https://cloud.google.com/blog/products/compute/gke-and-nvidia-nemo-framework-to-train-generative-ai-models">blog post</a> also discusses a reference architecture that highlights the major components, tools and common services used to train the NeMo large language model using GKE.</p><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/0*zk2fdOnHrZN2_Qj1.png" /></figure><p>Google Cloud VMware Engine is now integrated with Google Cloud NetApp Volumes. This availability enables customers to resize volumes without interruption. Separating out the scaling of compute and storage gives lots of flexiblity and cost control too. Check out the <a href="https://cloud.google.com/blog/products/infrastructure-modernization/google-cloud-netapp-volumes-integrates-with-vmware-engine">post</a> for more details.</p><p>Persistent Disk Asynchronous Replication (PD Async Replication) provides low recovery point objective (RPO) and low recovery time objective (RTO) block storage replication for cross-region active-passive disaster recovery (DR). It is a storage option that provides asynchronous replication of data between two regions. It can be used to manage replication for Compute Engine workloads at the infrastructure-level, instead of the workload-level. Check out the <a href="https://cloud.google.com/blog/products/compute/using-pd-async-replication-for-windows-server-disaster-recovery">blog post</a> with an example of how it works.</p><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/0*iSe8yCNZwpzG6SXr.png" /></figure><h3>Customers</h3><p>VPC service Controls (VPC-SC) is a foundational security control that creates an isolation perimeter around managed cloud resources and networks. Via granular ingress and egress rules, you can selectively approve access across perimeter boundaries and play a key role in preventing data exfiltration. Consider CommerzBank, a leading German bank, that is a trusted partner to approx. 26000 corporate client groups and 11 million private and small business customers. With the shift from IP addresses to API endpoints, a new approach was needed to address data sharing and movement needs. Especially around data sharing, CommerzBank had some clear criteria to evaluate any solution and VPC-SC met all these requirements. Check out the <a href="https://cloud.google.com/blog/topics/customers/how-commerzbank-safeguards-its-data-with-vpc-service-controls">post</a> to learn more.</p><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/0*PsWNx1LNe_XuC3GQ.png" /></figure><p>In another interesting customer case study, consider that of Palo Alto Networks. Their solid growth coupled with mergers and acquisitions had lead to more than 170,000 projects on Google Cloud. They did a large exercise a few years back around labelling that helped that identify the team, owner, cost center and environment for these projects (95% coverage). But the final 5% proved to be a challenge till they achieved that with BigQuery ML, which is the built-in machine learning feature in BigQuery. Check out the <a href="https://cloud.google.com/blog/products/data-analytics/how-palo-alto-networks-uses-bigquery-ml">post</a>.</p><h3>Containers and Kubernetes</h3><p>Managing the growth of your GKE clusters required that you had insights into each specific limits like Nodes per cluster, Noder per node pool, pods per cluster and more. Your task just got easier with the introduction of directly monitoring and setting alerts for crucial scalability limits. Check out the <a href="https://cloud.google.com/blog/products/containers-kubernetes/gke-gets-new-quota-monitoring-feature">post</a> for more details.</p><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/0*8X7HfXAqrPH2RIRz.png" /></figure><p>Ray, an open-source Python framework designed for scaling and distributing AI workloads is gaining widespread acceptance. While you can run Ray deployments on VMs, the traditional challenges that come with running workloads on your own on VMs i.e. resource efficiency and managing infrastructure come up. A suggested alternative is to deploy Ray on GKE with KubeRay, an open-source Kubernetes operator that simplifies Ray deployment and management. Check out this <a href="https://cloud.google.com/blog/products/containers-kubernetes/the-benefits-of-using-gke-for-running-ray-ai-workloads">post</a> that dives into the details on why running Ray on GKE would be the best way for you to go forward.</p><p>Continuing with Ray, are you running Ray on Google Kubernetes Engine (GKE)? Here is an essential blog post to read to run Ray securely on GKE. The post delves into areas that you need to address to harden your Ray installation on GKE and a solid summarization of best practices vis-a-vis Kubernetes and GKE constructs like namespaces, RBAC, NetworkPolicy and more. Safer defaults for running Ray with Kubernetes using KubeRay is a focus area and <a href="https://github.com/GoogleCloudPlatform/ai-on-gke/blob/main/ray-on-gke/README.md">Terraform templates</a> are available to spin up a multi-team environment with sample security configurations.</p><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/0*WY1oRpGnazhikqte.jpg" /></figure><p>The final piece on Ray is that of Kueue, a cloud-native queueing system that provides advanced scheduling for Ray applications on GKE. Check out this <a href="https://cloud.google.com/blog/products/containers-kubernetes/using-kuberay-and-kueue-to-orchestrate-ray-applications-in-gke">blog post</a> that shows how KubeRay and Kueue work together to achieve the same.</p><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/0*q1spCntYfLdXRIC5.png" /></figure><p>Speak of training AI models and the need for NVIDIA GPUs comes up regularly. GKE is probably one of the best choices available to deploy, scale and manage custom ML platforms. In an added boost, GKE can now automatically install NVIDIA GPU drivers. This process was manually done before and the automatic installation now even allows for the drivers to be precompiled for the GKE node, which can reduce the time it takes for GPU nodes to startup. Check out the <a href="https://cloud.google.com/blog/products/containers-kubernetes/gke-can-now-automatically-install-nvidia-gpu-drivers">post</a> for more details.</p><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/0*-IfpWIT5x9drgypU.png" /></figure><p>Stanford’s Brain Inferencing Laboratory explore motor systems neuroscience and neuroengineering applications. The relevant data for their research is obtained from experiments on preclininal models and human clinical studies. This data is handled via a complex platform that they have setup for standardized analyses and adhoc analyses. The components of the architecture include Containers, Git, CI/CD and compute clusters, specifically GKE running in Autopilot mode. Check out the <a href="https://cloud.google.com/blog/products/containers-kubernetes/stanford-team-uses-devops-tools-to-manage-research-data">blog post</a> for more details.</p><figure><img alt="" src="https://cdn-images-1.medium.com/max/512/0*-ez2Hh1aqKPxtFWz.png" /></figure><h3>Identity and Security</h3><p>This edition is heavy with security updates and let’s begin with zero-day vulnerabilities but what does that mean? A zero-day vulnerability is a security flaw in an application or operating system that has not been discovered, and there is no defense or patch for it. Did you know Google’s Threat Analysis Group (TAG) and Mandiant showed 97 zero-day vulnerabilities were exploited in 2023. Is that an improvement over 2022 or 2021. Find about this and more in this <a href="https://cloud.google.com/blog/topics/threat-intelligence/2023-zero-day-trends">post</a>.</p><p>You must have heard about Assured Workloads, which allows companies to run regulated workloads in several Google Cloud’s global regions. Consider the requirement then for your organization to adhere to compliance requirements in more than one geographic region, how do you then use Assured Workloads to create regulatory boundaries using a folder structure? Check out this <a href="https://cloud.google.com/blog/products/identity-security/how-to-set-compliance-controls-for-your-google-cloud-organization">post</a>.</p><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/1*YXPQRu5G853XXc3MRAue6Q.png" /></figure><p>In Google Cloud, we have the Organization resource right at the top in hierarchy. With the creation of this resource, you get access to Organization Policy Service. As part of a new release, a set of organization policies have been released that enforce the need to fix potentially insecure postures. These policies scan across IAM, Storage and Essential Contacts. For e.g. a few of the policies at the IAM level include disabling service account key creation, disabling service account key upload and more. Check out the <a href="https://cloud.google.com/blog/products/identity-security/introducing-stronger-default-org-policies-for-our-customers">post</a> to learn more of these policies that are available to all customers who are creating organization resources and for existing customers, who already have done that, these policies are available with no change required.</p><p>Cloud Armor plays an important role in enabling organizations to create a comprehensive DDOS mitigation strategy for their applications. One of the capabilities that plays a key role is that of rate-limiting via which you can curtail traffic to backend resources based on request volume. Check out this <a href="https://cloud.google.com/blog/products/identity-security/how-to-improve-resilience-to-ddos-attacks-with-cloud-armor-advanced-rate-limiting-capabilities">post</a> that highlights the rate-limiting features of Cloud Armor, the two types of actions available for rate-based rules (Throttle, Rate-based ban), planning your rate limiting deployment and more.</p><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/0*gUDRcmgcFoTaX_s0.png" /></figure><p>Handling sensitive data vis-a-vis security, privacy and compliance is an essential requirement for any application handling customer data. Discovery Service, that is part of Google Cloud’s Sensitive Data Protection helps to identify where Sensitive Data resides, which is the first step. Cloud SQL is now supported by the Discovery Service. Earlier it supported BigQuery and BigLake. Check out the <a href="https://cloud.google.com/blog/products/identity-security/expanding-sensitive-data-protection-to-make-it-easier-to-protect-data-in-cloud-sql">post</a> for more details.</p><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/0*ujrb4T08v6Ekjnth.png" /></figure><p>Software Supply Chain attacks are common and organizations need to bring in strict controls, especially when they modern applications have heavy dependency on open source software. Check out this joint <a href="https://cloud.google.com/blog/products/identity-security/how-to-choose-a-known-trusted-supplier-for-open-source-software">blog post</a> from Citi and Google, on common open source attack vectors and 3 main criteria to evaluate an OSS vendor.</p><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/0*s38cJUiBW3x3vtTq.png" /></figure><p>Security will continue to be a big topic at Cloud Next ’24. The 2nd CISO bulletin for March 2024 drops a hint on key security topics and discussion to expect at the conference. In an earlier edition, we had covered the intersection of Gen AI and Security and the <a href="https://cloud.google.com/blog/products/identity-security/cloud-ciso-perspectives-get-ready-for-next-24-what-you-need-to-know">post</a> seems to point towards that and of course, multiple other security areas that will receive attention during the event. The <a href="https://cloud.google.com/blog/products/identity-security/cloud-ciso-perspectives-easing-the-psychological-burden-of-leadership">first CISO bulletin for March</a> this month, focused on psychological resilience in cybersecurity leadership.</p><p>To end the security updates, a slightly different area this time but nevertheless an important one. Data shows that Knowledge workers spend an average of 63% of their productive time in the browser and nearly half (48%) of all business-critical applications are now browser-based and more. Given this, organizations would be served well to consider an enterprise ready browser like Chrome Enterprise. Check out a recent report by Enterprise Strategy Group, titled “ <a href="https://chromeenterprise.google/esg-security-report-2023/">Assessing Enterprise Browser Market Dynamics: Why Organizations Are Turning to Enterprise Browsers to More Effectively Secure Modern Work Styles,</a>” and the <a href="https://cloud.google.com/blog/products/chrome-enterprise/optimize-security-and-productivity-starting-with-the-browser-insights-from-new-report">blog post</a> for more details.</p><h3>Machine Learning</h3><p>The popular Anthropic’s Claude 3 family of models has started to be available on Vertex AI Model Garden. <a href="https://console.cloud.google.com/vertex-ai/publishers/anthropic/model-garden/claude-3-sonnet">Claude 3 Sonnet</a> and <a href="https://console.cloud.google.com/vertex-ai/publishers/anthropic/model-garden/claude-3-haiku">Claude 3 Haiku</a> are generally available to all customers on Vertex AI. Check out the <a href="https://cloud.google.com/blog/products/ai-machine-learning/anthropics-claude-3-models-go-ga-on-vertex-ai">post</a> on the details and steps to getting started.</p><h3>Storage, Databases and Data Analytics</h3><p>BigQuery’s data processing has been extended to Apache Spark. Now announced is the general availability (GA) of Apache Spark stored procedures in BigQuery. It brings Spark together with BigQuery under a single experience, including management, security and billing. Spark procedures are supported using PySpark, Scala and Java code. Check out the <a href="https://cloud.google.com/blog/products/data-analytics/apache-spark-stored-procedures-in-bigquery-are-ga">post</a> for more details.</p><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/0*Vm0Qlq0bQYYvSr4d.png" /></figure><p>Two new SQL features (windowing and gap filling) are now available in preview in BigQuery that simplify time series analysis. The RANGE data type and supporting functions are also available now to complement the analysis. Check out the <a href="https://cloud.google.com/blog/products/data-analytics/bigquery-sql-gets-time-windowing-and-gap-filling">post</a> for more details.</p><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/1*lNTSQwG_8v4vkUH8KxwS4g.png" /></figure><p>What are Dataflow streaming modes? Do exactly-once and at-least-once-processing mode ring a bell? Both of these modes are supported now and understanding them is key to addressing scenarios that need low latency , overall cost and more. Check out the <a href="https://cloud.google.com/blog/products/data-analytics/dataflow-at-least-once-vs-exactly-once-streaming-modes">post</a> for more details.</p><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/0*7_Uu02LGD0BNaUue.jpg" /></figure><p>High-volume data feeds coming in which need data enrichment to be actionable? A Bigtable and Dataflow combination as illustrated in this blog post can address this requirement. Check out the <a href="https://cloud.google.com/blog/products/data-analytics/enrich-streaming-data-in-bigtable-with-dataflow">post</a>.</p><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/1*kJws2k2KqcFwACgmWuUXwQ.png" /></figure><p>If you’d like to read reports, TechTarget’s Enterprise Strategy Group (ESG) did an extensive study to compare the quantitative and qualitative benefits that organizations can realize with Google Cloud BigQuery when compared with alternative solutions. Download the full report <a href="https://cloud.google.com/resources/esg-ultimate-ai-ready-data-platform?utm_source=cgc-blog&amp;utm_medium=blog&amp;utm_campaign=FY24-Q1-global-ENDM297-website-dl-ultimate-AI-ready-platform-price-performance&amp;utm_content=-&amp;utm_term=-">here</a> and read the post <a href="https://cloud.google.com/blog/products/data-analytics/enterprise-strategy-group-evaluates-bigquery-tco">here</a>.</p><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/0*waJlOLNhrBi4y6hm.png" /></figure><p>Datastream, the change data capture (CDC) service now supports SQL Server data sources. The addition of this support now provides a way to replicate data from a range of relational sources to several Google Cloud services, such as BigQuery, Cloud Storage, AlloyDB, and Spanner. Check out the <a href="https://cloud.google.com/blog/products/databases/datastream-supports-sql-server-sources">post</a> for more details and various possibilities with the new feature.</p><figure><img alt="" src="https://cdn-images-1.medium.com/max/1000/0*-u2LiYhim0jvzlGY.png" /></figure><p>Finally, cross-cloud functionality of BigQuery Omni and data sharing capabilities of Analytics Hub has made possible access to data stored in Salesforce Data Cloud and combine it with data in Google Cloud in a secure and zero ETL fashion. Check out the <a href="https://cloud.google.com/blog/products/data-analytics/salesforce-data-cloud-bidirectional-data-sharing-with-bigquery">post</a> for more details.</p><h3>Developers and Practitioners</h3><p>Cloud Run keeps getting better and better. Now available in preview is volume mounts, which enables access to shared data stored in a local file system, across applications. Check out the <a href="https://cloud.google.com/blog/products/serverless/introducing-cloud-run-volume-mounts">blog post</a> that highlights how to mount volumes using gcloud commands and scenarios (load vector database, serve static website, etc) where this feature is very useful.</p><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/0*LcxXg8osEDKPp06B.png" /></figure><p>If you are using the popular NoSQL database Couchbase, here is an update that you can now integrate the database to the wider range of Google Cloud services via the Couchbase connector inside of Google’s Integration-Platform-as-a-Service (iPass) solution. Check out this post that highlights how you can use this connector include key features, using other Google Cloud services to analyse Couchbase data and more.</p><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/0*W-cOtKp9eiZany07.png" /></figure><h3>Learn Google Cloud</h3><p>If you are taking your first steps with Data on Google Cloud or even otherwise and if PostgreSQL is your database of your choice, you have to choose between Spanner, AlloyDB and Cloud SQL. How do you chose one of these services. Check out this <a href="https://cloud.google.com/blog/products/databases/alloydb-and-spanner-databases-for-startups">post</a>, that focuses on AlloyDB and Spanner and determine if you’d like to chose a specific one or in combination too!</p><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/1*KUgiMJoDPLxLPIoFSJj4IA.png" /></figure><h3>Stay in Touch</h3><p>Have questions, comments, or other feedback on this newsletter? Please send <a href="https://forms.gle/UAsAS7YLxYSBTNBy9">Feedback</a>.</p><p>If any of your peers are interested in receiving this newsletter, send them the <a href="https://gcptechnuggets.substack.com/">Subscribe</a> link.</p><img src="https://medium.com/_/stat?event=post.clientViewed&referrerSource=full_rss&postId=beddfd742deb" width="1" height="1" alt=""><hr><p><a href="https://medium.com/google-cloud/google-cloud-platform-technology-nuggets-march-16-31-2024-edition-beddfd742deb">Google Cloud Platform Technology Nuggets — March 16–31, 2024 Edition</a> was originally published in <a href="https://medium.com/google-cloud">Google Cloud - Community</a> on Medium, where people are continuing the conversation by highlighting and responding to this story.</p>]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[A Visual Remix : Swap Objects with Ease]]></title>
            <link>https://medium.com/google-cloud/a-visual-remix-swap-objects-with-ease-8718b040723c?source=rss----e52cf94d98af---4</link>
            <guid isPermaLink="false">https://medium.com/p/8718b040723c</guid>
            <category><![CDATA[imagen]]></category>
            <category><![CDATA[machine-learning]]></category>
            <category><![CDATA[vertex-ai]]></category>
            <category><![CDATA[generative-ai]]></category>
            <category><![CDATA[google-cloud-platform]]></category>
            <dc:creator><![CDATA[Bhushan Garware]]></dc:creator>
            <pubDate>Sun, 31 Mar 2024 02:52:00 GMT</pubDate>
            <atom:updated>2024-03-31T02:52:00.014Z</atom:updated>
            <content:encoded><![CDATA[<h3>A Visual Remix : Swap Objects with Ease</h3><p>Artificial intelligence (AI) has revolutionized the way we create marketing images. With a simple text prompt, we can generate stunning visuals tailored to our campaigns. Following image, generated using <a href="https://cloud.google.com/vertex-ai/generative-ai/docs/image/quickstart-image-generate-console">ImageGen on Veretx AI</a>, illustrates a sample of marketing image for a targeted campaign.</p><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/1*WJ0fbhfKcffRBx0ptsjA9A.png" /><figcaption>AI Generated Image with Google’s Imagegeneration@005 model from Vertex AI Studio</figcaption></figure><p><strong>The Missing Piece: Real Products</strong></p><p>AI image generators are amazing at producing synthetic images from prompts like “A young woman standing in a gym and holding a ‘Specific Brand ’ sneaker in her hand”. The problem? Even if the brand logo appears correctly, that sneaker may not be an actual, purchasable brand product. These images, while visually appealing, lack the crucial link to real merchandise, making them less useful for personalized marketing campaigns. Techniques like subject tuning are promising but not yet refined enough to consistently produce marketing-grade quality content.</p><p><strong>The Solution: Product Replacement</strong></p><p>What if we could easily replace generic products in AI-generated images with the specific products we want to promote? Imagine you have a stock image of a shoe from a particular brand as shown below-</p><figure><img alt="" src="https://cdn-images-1.medium.com/max/1004/1*ZxaVsfEvp5AtT8RAhz8Pxw.jpeg" /><figcaption>Sample AI generated imaginary product [Replace with your branded product stock image]</figcaption></figure><p><em>We can achieve easy object replacement with out manually drawing any bounding boxes or marking segmentation mask with the help of following steps -</em></p><p>(1) <a href="https://ai.google.dev/?gad_source=1&amp;gclid=CjwKCAjw7-SvBhB6EiwAwYdCAZ_hrzfyMCDhNj_y3_EXPb2nwTbkGBDHvfzvqIA6_Bu2KI0QyIoU9RoCFnQQAvD_BwE">Gemini Model</a>: LLM for understanding the name (subject) of the product to be replaced.</p><p>(2) <a href="https://cloud.google.com/vision?hl=en">Google Cloud Vision API</a>: Object detection to find the subject in the source images</p><p>(3) <a href="https://segment-anything.com/">Segment Anything (SAM) Model</a>: for Image Segmentation</p><p>(4) <a href="https://github.com/huggingface/diffusers">Diffuser Model</a>: for Image Impainting</p><p>Let’s understand each step with some derails below -</p><h4><strong>(1) Gemini for Text processing</strong> :</h4><p>Imaging the end user of your tool with use a simple english command like — replace ‘object name’ in the given image with target. As a first step you need to find which object is to be replaced.</p><h4><strong>(2) Google Cloud Vision API:</strong></h4><p>Use Google Cloud Visio API to detect the desired object in the given image</p><figure><img alt="" src="https://cdn-images-1.medium.com/max/980/1*Pral-XFsh2m95co2Z9gXHA.png" /><figcaption>Object detection using Google Cloud Vision API and segmentation with SAM model</figcaption></figure><h4><strong>(3) Segment Anything (SAM) Model:</strong></h4><p>Once the object is detected from Google Vision API, we use SAM model to segment the object. Perform similar operations on the target images as shown below -</p><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/1*Eas2gVkGfSwZnXui9zOPDA.png" /><figcaption>Auto segmentation using SAM model</figcaption></figure><h4><strong>(4) Diffuser Model:</strong></h4><p>In most of the cases, the object in the AI generated image or in the given input image will be of different shape and size. Hence, if we just resize the target image and superimpose with the given image, it would look like below image</p><figure><img alt="" src="https://cdn-images-1.medium.com/max/990/1*W9QBKCE_1wwmMzRjap5rFQ.png" /><figcaption>Superimposed masked images of the object and the target product</figcaption></figure><p>The black portion in the above image represents the part of the original object where the target image has no appearance. This region need to be filled intelligently. We use image impainting technique using diffusers model to perform the task. Following image shows the final output -</p><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/1*dz9bs5ygWOkOBQ6iDLMpGA.png" /><figcaption>A Visual Remix output</figcaption></figure><p>We can use methods like ‘Haugh Transform’ to calculate the angle of rotation as well. However this method can work only if the desired objects are inclined in the 2D plain. As a future step, we need to incorporate 3D roations.</p><img src="https://medium.com/_/stat?event=post.clientViewed&referrerSource=full_rss&postId=8718b040723c" width="1" height="1" alt=""><hr><p><a href="https://medium.com/google-cloud/a-visual-remix-swap-objects-with-ease-8718b040723c">A Visual Remix : Swap Objects with Ease</a> was originally published in <a href="https://medium.com/google-cloud">Google Cloud - Community</a> on Medium, where people are continuing the conversation by highlighting and responding to this story.</p>]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Analyzing Trends of Google Apps Script from Questions on Stackoverflow using Gemini 1.5 API]]></title>
            <link>https://medium.com/google-cloud/analyzing-trends-of-google-apps-script-from-questions-on-stackoverflow-using-gemini-1-5-api-c6b448e36461?source=rss----e52cf94d98af---4</link>
            <guid isPermaLink="false">https://medium.com/p/c6b448e36461</guid>
            <category><![CDATA[google-cloud-platform]]></category>
            <category><![CDATA[generative-ai]]></category>
            <category><![CDATA[machine-learning]]></category>
            <category><![CDATA[google-apps-script]]></category>
            <category><![CDATA[gemini]]></category>
            <dc:creator><![CDATA[Kanshi Tanaike]]></dc:creator>
            <pubDate>Sun, 31 Mar 2024 02:51:15 GMT</pubDate>
            <atom:updated>2024-03-31T02:51:15.186Z</atom:updated>
            <content:encoded><![CDATA[<figure><img alt="" src="https://cdn-images-1.medium.com/max/1000/0*2828W-RsKQh10X2F.png" /></figure><h3>Abstract</h3><p>A new large language model (LLM) called Gemini with an API is now available, allowing developers to analyze vast amounts of data. This report explores trends in Google Apps Script by using the Gemini 1.5 API to analyze questions on Stack Overflow.</p><h3>Introduction</h3><p>The release of the LLM model Gemini as an API on Vertex AI and Google AI Studio has opened a world of possibilities. <a href="https://deepmind.google/technologies/gemini/#introduction">Ref</a> The Gemini API significantly expands the potential of various scripting languages, paving the way for diverse applications. Additionally, Gemini 1.5 has recently been released in AI Studio. <a href="https://blog.google/technology/ai/google-gemini-next-generation-model-february-2024/#sundar-note">Ref</a> We can expect the Gemini 1.5 API to follow suit soon.</p><p>The difference between Gemini 1.0 and Gemini 1.5 is as following table created by Gemini.</p><iframe src="" width="0" height="0" frameborder="0" scrolling="no"><a href="https://medium.com/media/9bfb36b70efe743ac9169ae744e6fe3e/href">https://medium.com/media/9bfb36b70efe743ac9169ae744e6fe3e/href</a></iframe><p>Given Gemini 1.5’s ability to analyze large data, this report leverages the Gemini 1.5 API to analyze trends in Google Apps Script from the data of questions on Stackoverflow. We achieve this by examining all questions tagged google-apps-script from 2008 to 2024 (only 2024, from January to March 28) on Stack Overflow.</p><h3>Step</h3><p>The steps of this analysis are as follows.</p><h3>1. Retrieve questions from Stackoverflow</h3><figure><img alt="" src="https://cdn-images-1.medium.com/max/889/0*PENJvQbml73daj2L.png" /></figure><p>As the base data of Stackoverflow, I used the data retrieved at “<a href="https://medium.com/google-cloud/trend-of-google-apps-script-tag-on-stackoverflow-2024-584e20fb892c">Trend of google-apps-script Tag on Stackoverflow 2024</a>”. In that report, all questions including a tag google-apps-script from 2008 to 2024 have already been retrieved. The data from January 1, 2024, to March 28, 2024, was retrieved in this report. All data is retrieved by StackExchange API. <a href="https://api.stackexchange.com/docs">Ref</a> This flow can be seen in the above image. As a result, 17 CSV files including the data from Stackoverflow were created. The total number of questions including google-apps-script tag from 2008 to March 28, 2024, on Stackoverflow was 54,135.</p><h3>2. Generate texts for each year</h3><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/0*ldN8YDuXzi6_uqmS.png" /></figure><p>As the next step, each summary is created from the retrieved 17 CSV files using Gemini 1.5 API. Because in the current stage, all 17 CSV data cannot be directly used by one API call. So, I separated them. This flow can be seen in the above image. By this flow, a text file including the summaries of each year was created.</p><h3>3. Generate text from all year</h3><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/0*ZSv82VONRiP7AFS8.png" /></figure><p>As the next step, a summary is created from a text file including summaries from 2008 to 2024. This flow can be seen in the above image. By this flow, the summary of all data from 2008 to 2024 is created.</p><h3>Usage</h3><p>In order to test this script, please do the following steps.</p><h3>1. Create an API key</h3><p>Please access <a href="https://makersuite.google.com/app/apikey">https://makersuite.google.com/app/apikey</a> and create your API key. At that time, please enable Generative Language API at the API console. This API key is used for this sample script.</p><p>This official document can be also seen. <a href="https://ai.google.dev/">Ref</a>.</p><h3>2. Create a Google Apps Script project</h3><p>In this report, Google Apps Script is used. Of course, the method introducing this report can be also used in other languages.</p><p>Please create a standalone Google Apps Script project. Of course, this script can be also used with the container-bound script.</p><p>And, please open the script editor of the Google Apps Script project.</p><h3>3. Base data</h3><p>Here, prepare the data as described in the section “1. Retrieve questions from Stack Overflow.” In this report, we focus on the values of “creation_date,” “title,” “score,” and “tags.” While I initially wanted to include the body of the question, it significantly increased the number of tokens for processing. Therefore, the body was excluded. However, I believe the trend can still be obtained from the remaining values: “creation_date,” “title,” “score,” and “tags.”</p><h3>4. Base script</h3><p>The base script for processing this analysis is as follows. Please copy and paste the following script to the script editor of Google Apps Script and save the script.</p><p>In this script, the model models/gemini-1.5-pro-latest was used for generating texts.</p><pre>/**<br> * Sample script for this report.<br> */<br>class DoGemini {<br>  /**<br>   * @param {Object} object Object using this library.<br>   */<br>  constructor(object = {}) {<br>    const model = &quot;models/gemini-1.5-pro-latest&quot;;<br><br>    this.baseUrl = `https://generativelanguage.googleapis.com/v1beta/${model}`;<br>    this.apiKey = object.apiKey || null;<br>    this.headers = object.apiKey<br>      ? null<br>      : {<br>          authorization: `Bearer ${object.token || ScriptApp.getOAuthToken()}`,<br>        };<br>    this.retry = 5;<br>    this.folderId = object.folderId || &quot;root&quot;;<br><br>    this.object = object;<br>  }<br><br>  /**<br>   * ### Description<br>   * Create summaries for each year of the data.<br>   *<br>   * @returns {String} A file ID of the file including the created summaries.<br>   */<br>  createSummariesOfEachYear() {<br>    const headerText = [&quot;creation_date&quot;, &quot;title&quot;, &quot;score&quot;, &quot;tags&quot;].join(&quot;,&quot;);<br>    const files = DriveApp.getFolderById(this.folderId).getFilesByType(<br>      MimeType.CSV<br>    );<br>    const fileList = [];<br>    while (files.hasNext()) {<br>      const file = files.next();<br>      const csv = file.getBlob().getDataAsString().trim() || &quot;No data.&quot;;<br>      const filename = file.getName();<br>      fileList.push({ filename, csv });<br>    }<br>    if (fileList.length == 0) {<br>      throw new Error(&quot;No CSV files.&quot;);<br>    }<br>    fileList.sort((a, b) =&gt; (a.filename &gt; b.filename ? 1 : -1));<br>    console.log(<br>      `--- File list\n${JSON.stringify(<br>        fileList.map(({ filename }) =&gt; filename),<br>        null,<br>        2<br>      )}`<br>    );<br><br>    const res = fileList.map(({ filename, csv }) =&gt; {<br>      console.log(`Now processing: ${filename}`);<br>      const q = [<br>        `Summary the trend from the following CSV data. The CSV data is questions related to Google Apps Script in Stackoverflow. Namely, summarize the trend of questions on Stackoverflow from CSV data.`,<br>        `Consider the creation date of the first column.`,<br>        `Consider the affection of the advent of AI.`,<br>        `Consider the history of Google Apps Script.`,<br>        `Include a value, that you evaluated the activity level of Google Apps Script between 1 and 100, in the response without overestimating.`,<br>        ``,<br>        `${filename}`,<br>        `The format of CSV data is as follows.`,<br>        ``,<br>        `[Format of CSV data]`,<br>        `Created date of the question, Title of the question, Score of the question, Tags related to the question`,<br>        ``,<br>        `[CSV data]`,<br>        `${headerText}`,<br>        `${csv}`,<br>      ].join(&quot;\n&quot;);<br>      const summary = this.generateContent_(q);<br>      return { filename, ...summary };<br>    });<br>    return DriveApp.getFolderById(this.folderId)<br>      .createFile(&quot;summariesOfEachYear.txt&quot;, JSON.stringify(res))<br>      .getId();<br>  }<br><br>  /**<br>   * ### Description<br>   * Create a summary of all years.<br>   *<br>   * @param {String} fileId File ID including summaries of each year.<br>   * @returns {String} A file ID of the file including the created summary.<br>   */<br>  createSummaryOfAllYears(fileId) {<br>    if (!fileId) {<br>      throw new Error(<br>        &quot;Please set the file ID of the file including summaries of each year.&quot;<br>      );<br>    }<br>    const headerText = [&quot;year&quot;, &quot;summary&quot;].join(&quot;,&quot;);<br>    const data = JSON.parse(<br>      DriveApp.getFileById(fileId).getBlob().getDataAsString()<br>    );<br>    const csv = data.map((e) =&gt; `${e.filename},${e.response}`).join(&quot;\n&quot;);<br><br>    // const csv = data.map(e =&gt; `${e.filename},&#39;${JSON.stringify(e.response).replace(/&#39;/, &quot;\&#39;&quot;)}&#39;`).join(&quot;\n&quot;);<br>    const q = [<br>      `Summary the trend from the following CSV data. The CSV data is the summary of trend of questions related to Google Apps Script in Stackoverflow every year. The summaries were created by Gemini API.`,<br>      `Consider the each year of the first column.`,<br>      `Consider the affection of the advent of AI.`,<br>      `Consider the history of Google Apps Script.`,<br>      `At the last of summary, add all values, that you evaluated the activity level of Google Apps Script between 1 and 100, in the response without overestimating. Output the values as an array. The array format is [[&quot;year&quot;, &quot;activity value&quot;],[&quot;year&quot;, &quot;activity value&quot;],,,].`,<br>      ``,<br>      `The format of CSV data is as follows.`,<br>      ``,<br>      `[Format of CSV data]`,<br>      `year, Summary of trend of questions`,<br>      ``,<br>      `[CSV data]`,<br>      `${headerText}`,<br>      `${csv}`,<br>    ].join(&quot;\n&quot;);<br>    const { response } = this.generateContent_(q);<br>    return DriveApp.getFolderById(this.folderId)<br>      .createFile(&quot;summaryOfAllYears.txt&quot;, response)<br>      .getId();<br>  }<br><br>  /**<br>   * ### Description<br>   * Count tokens of inputted values with Gemini API.<br>   *<br>   * @param {Object} options Object for UrlFetchApp.<br>   * @returns {Object} totalTokens<br>   */<br>  countToken_(options) {<br>    const url =<br>      `${this.baseUrl}:countTokens` +<br>      (this.apiKey ? `?key=${this.apiKey}` : &quot;&quot;);<br>    const res = this.fetch_({ url, ...options });<br>    return JSON.parse(res.getContentText());<br>  }<br><br>  /**<br>   * ### Description<br>   * Generate content with Gemini API.<br>   *<br>   * @param {String} q Text for prompt.<br>   * @returns {UrlFetchApp.HTTPResponse|String[]} Response from API. When pageToken is used, String[] is returned.<br>   */<br>  generateContent_(q) {<br>    const payload = { contents: [{ parts: [{ text: q }], role: &quot;user&quot; }] };<br>    const options = {<br>      payload: JSON.stringify(payload),<br>      contentType: &quot;application/json&quot;,<br>      muteHttpExceptions: true,<br>    };<br>    if (this.headers) {<br>      options.headers = headers;<br>    }<br>    const totalTokens = this.countToken_(options);<br><br>    console.log(totalTokens); // Confirm the total tokens in the log.<br><br>    const url =<br>      `${this.baseUrl}:generateContent` +<br>      (this.apiKey ? `?key=${this.apiKey}` : &quot;&quot;);<br>    const res = this.fetch_({ url, ...options });<br>    const obj = JSON.parse(res.getContentText());<br>    if (<br>      obj.candidates &amp;&amp;<br>      obj.candidates.length &gt; 0 &amp;&amp;<br>      obj.candidates[0].content.parts.length &gt; 0<br>    ) {<br>      return { totalTokens, response: obj.candidates[0].content.parts[0].text };<br>    } else {<br>      this.retry--;<br>      console.warn(&quot;No response. Retry again.&quot;);<br>      if (this.retry &gt; 0) {<br>        this.generateContent_(q);<br>      } else {<br>        console.error(&quot;No response.&quot;);<br>      }<br>    }<br>  }<br><br>  /**<br>   * ### Description<br>   * Request Gemini API.<br>   *<br>   * @param {Object} obj Object for using UrlFetchApp.fetchAll.<br>   * @returns {UrlFetchApp.HTTPResponse} Response from API.<br>   */<br>  fetch_(obj) {<br>    obj.muteHttpExceptions = true;<br>    const res = UrlFetchApp.fetchAll([obj])[0];<br>    if (res.getResponseCode() != 200) {<br>      throw new Error(res.getContentText());<br>    }<br>    return res;<br>  }<br>}</pre><h3>5. Script for “Generate texts for each year”</h3><p>This script creates a text file including summaries from 2008 to 2024. The file is created in the same folder as the CSV files. Of course, you can also see each summary from the file.</p><pre>function process1() {<br>  const apiKey = &quot;###&quot;; // Please set your API key.<br><br>  const object = {<br>    apiKey,<br>    folderId: &quot;###&quot;, // Please set the folder ID of the folder including 17 CSV files including data from Stackoverflow.<br>  };<br>  const dg = new DoGemini(object);<br>  const res = dg.createSummariesOfEachYear();<br>  console.log(res);<br>}</pre><p>When this script is run, the number of tokens for each year can be seen at the following chart.</p><figure><img alt="" src="https://cdn-images-1.medium.com/max/981/0*bSWLQd16SvydbZbD.png" /></figure><p>This chart reveals that the number of tokens exceeds 32,000 in most years. In this context, the Gemini 1.5 API has proven to be a valuable tool.</p><h3>6. Script for “Generate text from all year”</h3><p>This script creates a text file of a summary of the trend of all questions including a tag google-apps-script posted from 2008 to 2024. In this case, the result file is created in the root folder.</p><pre>function process2() {<br>  const apiKey = &quot;###&quot;; // Please set your API key.<br>  const fileId = &quot;###&quot;; // Please set the file ID of a text file including summaries of each year.<br><br>  const object = { apiKey };<br>  const dg = new DoGemini(object);<br>  const res = dg.createSummaryOfAllYears(fileId);<br>  console.log(res);<br>}</pre><h3>Result</h3><p>When the above scripts are run, the following result is obtained.</p><pre>## Summary of Google Apps Script Activity on Stack Overflow:<br><br>Based on the provided summaries of Google Apps Script questions on Stack Overflow from 2008 to 2024, we can observe the following trends:<br><br>**Early Stage (2008-2009):**<br><br>* Minimal activity as the platform was in its early stages of development and adoption.<br><br>**Growth and Adoption (2010 onwards):**<br><br>* Gradual increase in questions, indicating growing interest and adoption.<br>* Focus on basic functionalities initially, followed by more complex and diverse topics as the platform matured.<br>* Active community participation and knowledge sharing.<br><br>**Impact of AI:**<br><br>* While not explicitly evident in the earlier data, the potential for AI integration with Google Apps Script is recognized and may influence future trends.<br><br>**Activity Level:**<br><br>* Estimated activity level between **60 and 70 out of 100**, indicating a healthy and active community with room for further growth.<br><br>**Specific Observations:**<br><br>* Common topics include:<br>    * Basic syntax and functionality<br>    * Integration with Google Sheets, Forms, and other Google products<br>    * Email automation<br>    * Data manipulation<br>    * Triggering scripts<br>    * Web app development<br>* Recurring challenges faced by users:<br>    * Authorization and permission errors<br>    * Understanding specific methods and syntax<br>    * Debugging scripts<br>    * Optimizing script performance<br><br>**Overall, the data suggests a steady and ongoing interest in Google Apps Script, with a growing user base and increasingly complex use cases. While AI integration is not yet a dominant theme, it has the potential to influence future trends and applications.**<br><br>**Estimated Activity Levels:**<br><br>Based on the analysis of each year&#39;s data, here&#39;s an array summarizing the estimated activity levels of Google Apps Script on Stack Overflow:<br><br>```<br>[<br>  [&quot;2008-2009&quot;, 10], // Estimated low activity due to early stage<br>  [&quot;2010-2011&quot;, 30], // Moderate activity during early growth<br>  [&quot;2011-2012&quot;, 60], // Increasing activity and diversification of topics<br>  [&quot;2012-2013&quot;, 60], // Steady growth and expanding capabilities<br>  [&quot;2013-2014&quot;, 60], // Moderately active and engaged community<br>  [&quot;2014-2015&quot;, 65], // Consistent activity with focus on both basic and advanced functionalities<br>  [&quot;2015-2016&quot;, 75], // Healthy and active community, diverse topics covered<br>  [&quot;2016-2017&quot;, 70], // Consistent activity, focus on integrations and web app development<br>  [&quot;2017-2018&quot;, 70], // Steady interest, diverse use cases, and demand for advanced functionalities<br>  [&quot;2018-2019&quot;, 65], // Consistent activity, potential for future AI integration<br>  [&quot;2019-2020&quot;, 65], // Sustained interest, potential influence of AI in automation<br>  [&quot;2020-2021&quot;, 65], // Consistent activity, continued relevance and adoption<br>  [&quot;2021-2022&quot;, 75], // Vibrant and active community, growing adoption and complex use cases<br>  [&quot;2022-2023&quot;, 75], // Consistent activity, potential for AI integration in specific areas<br>  [&quot;2023-2024&quot;, 65], // Steady interest, focus on basic functionalities and integrations<br>]<br>```<br><br>**Note:** These activity levels are estimations based on the provided data and general knowledge of Google Apps Script&#39;s adoption and development. A more precise assessment would require access to a larger dataset and more detailed information about question topics and user engagement.</pre><p>When the activity level is evaluated by Gemini 1.5 API for each year is exported as a chart, it becomes as follows.</p><figure><img alt="" src="https://cdn-images-1.medium.com/max/981/0*Y_vIz1H0Xoz6yVBb.png" /></figure><p>The above results confirm various insights about the trend of Google Apps Script on Stack Overflow. Additionally, the Gemini 1.5 API emerged as a valuable tool for data analysis.</p><h3>Note</h3><ul><li>The top illustration was created by <a href="https://gemini.google.com/">Gemini</a> with giving the abstract.</li></ul><img src="https://medium.com/_/stat?event=post.clientViewed&referrerSource=full_rss&postId=c6b448e36461" width="1" height="1" alt=""><hr><p><a href="https://medium.com/google-cloud/analyzing-trends-of-google-apps-script-from-questions-on-stackoverflow-using-gemini-1-5-api-c6b448e36461">Analyzing Trends of Google Apps Script from Questions on Stackoverflow using Gemini 1.5 API</a> was originally published in <a href="https://medium.com/google-cloud">Google Cloud - Community</a> on Medium, where people are continuing the conversation by highlighting and responding to this story.</p>]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Generating Texts using Files Uploaded by Gemini 1.5 API]]></title>
            <link>https://medium.com/google-cloud/generating-texts-using-files-uploaded-by-gemini-1-5-api-5777f1c902ab?source=rss----e52cf94d98af---4</link>
            <guid isPermaLink="false">https://medium.com/p/5777f1c902ab</guid>
            <category><![CDATA[gemini]]></category>
            <category><![CDATA[google-apps-script]]></category>
            <category><![CDATA[generative-ai]]></category>
            <category><![CDATA[google-cloud-platform]]></category>
            <category><![CDATA[machine-learning]]></category>
            <dc:creator><![CDATA[Kanshi Tanaike]]></dc:creator>
            <pubDate>Sun, 31 Mar 2024 02:50:43 GMT</pubDate>
            <atom:updated>2024-03-31T02:50:43.081Z</atom:updated>
            <content:encoded><![CDATA[<figure><img alt="" src="https://cdn-images-1.medium.com/max/1000/0*4xCKDkXmAXkIXMbs.png" /></figure><h3>Abstract</h3><p>The Gemini API allows the generating of text from uploaded files using Google Apps Script. It expands the potential of various scripting languages for diverse applications.</p><h3>Introduction</h3><p>With the release of the LLM model Gemini as an API on Vertex AI and Google AI Studio, a world of possibilities has opened up. <a href="https://deepmind.google/technologies/gemini/#introduction">Ref</a> The Gemini API significantly expands the potential of various scripting languages and paves the way for diverse applications. Also, recently, Gemini 1.5 in AI Studio has been released. <a href="https://blog.google/technology/ai/google-gemini-next-generation-model-february-2024/#sundar-note">Ref</a> In the near future, Gemini 1.5 API will be also released soon.</p><p>Recently, the files got to be able to be uploaded with Gemini API. <a href="https://ai.google.dev/api/rest/v1beta/files">Ref1</a> and <a href="https://ai.google.dev/api/rest/v1beta/media">Ref2</a> When this is used, the text is generated using the uploaded files. This report introduces the sample scripts for uploading the files and generating the texts using Google Apps Script.</p><h3>Usage</h3><p>In order to test this script, please do the following steps.</p><h3>1. Create an API key</h3><p>Please access <a href="https://makersuite.google.com/app/apikey">https://makersuite.google.com/app/apikey</a> and create your API key. At that time, please enable Generative Language API at the API console. This API key is used for this sample script.</p><p>This official document can be also seen. <a href="https://ai.google.dev/">Ref</a>.</p><h3>2. Create a Google Apps Script project</h3><p>In this report, Google Apps Script is used. Of course, the method introducing this report can be also used in other languages.</p><p>Please create a standalone Google Apps Script project. Of course, this script can be also used with the container-bound script.</p><p>And, please open the script editor of the Google Apps Script project.</p><h3>3. Steps of script</h3><p>Here, it introduces the following 4 sample scripts.</p><ol><li>Upload a file with <a href="https://ai.google.dev/api/rest/v1beta/media">“Method: files.list”</a>.</li><li>Confirm the uploaded file with <a href="https://ai.google.dev/api/rest/v1beta/files">“Method: media.upload”</a>.</li><li>Generate content using the uploaded file with <a href="https://ai.google.dev/api/rest/v1beta/models/generateContent">“Method: models.generateContent”</a>.</li><li>Delete the uploaded file with <a href="https://ai.google.dev/api/rest/v1beta/files/delete">“Method: files.delete”</a>.</li></ol><p>Limitation of the uploaded file <a href="https://github.com/google-gemini/gemini-api-cookbook/blob/main/preview/file-api/File_API.ipynb">Ref</a></p><blockquote><em>Can only be used with model.generateContent or model.streamGenerateContent Automatic file deletion after 2 days Maximum 2GB per file, 20GB limit per project No downloads allowed</em></blockquote><h3>4. Script</h3><h3>Upload a file</h3><p>You can see the official document at <a href="https://ai.google.dev/api/rest/v1beta/media/upload">Method: media.upload</a>. The sample script of Google Apps Script is as follows.</p><p>Please set your API key and the file ID of the image file. Here, PNG image is used.</p><pre>function sample1() {<br>  const apiKey = &quot;###&quot;; // Please set your API key.<br>  const fileId = &quot;###&quot;; // Please set the file ID of the image file. Here, PNG image is used.<br><br>  const url = `https://generativelanguage.googleapis.com/upload/v1beta/files?uploadType=multipart&amp;key=${apiKey}`;<br>  const metadata = {<br>    file: { displayName: DriveApp.getFileById(fileId).getName() },<br>  };<br>  const payload = {<br>    metadata: Utilities.newBlob(JSON.stringify(metadata), &quot;application/json&quot;),<br>    file: UrlFetchApp.fetch(<br>      `https://drive.google.com/thumbnail?sz=w1000&amp;id=${fileId}`,<br>      { headers: { authorization: &quot;Bearer &quot; + ScriptApp.getOAuthToken() } }<br>    ).getBlob(),<br>  };<br>  const options = {<br>    method: &quot;post&quot;,<br>    payload: payload,<br>    muteHttpExceptions: true,<br>  };<br>  const res = UrlFetchApp.fetch(url, options).getContentText();<br>  console.log(res);<br>}</pre><p>When this script is run, the following value is returned.</p><pre>{<br>  &quot;file&quot;: {<br>    &quot;name&quot;: &quot;files/###&quot;,<br>    &quot;displayName&quot;: &quot;###&quot;,<br>    &quot;mimeType&quot;: &quot;image/jpeg&quot;,<br>    &quot;sizeBytes&quot;: &quot;123456&quot;,<br>    &quot;createTime&quot;: &quot;2024-03-30T01:23:00.000000Z&quot;,<br>    &quot;updateTime&quot;: &quot;2024-03-30T01:23:00.000000Z&quot;,<br>    &quot;expirationTime&quot;: &quot;2024-04-01T01:23:00.000000Z&quot;,<br>    &quot;sha256Hash&quot;: &quot;###&quot;,<br>    &quot;uri&quot;: &quot;https://generativelanguage.googleapis.com/v1beta/files/###&quot;<br>  }<br>}</pre><p>The values of mimeType and uri are used with generateContent.</p><p>In this sample, I used uploadType=multipart because of the small size of the image file. If you want to upload a large file, I think that resumable upload can be also used.</p><h3>Get the file list</h3><p>You can see the official document at <a href="https://ai.google.dev/api/rest/v1beta/files/list">Method: files.list</a>. The sample script of Google Apps Script is as follows.</p><p>Please set your API key.</p><pre>function sample2() {<br>  const apiKey = &quot;###&quot;; // Please set your API key.<br><br>  const url = `https://generativelanguage.googleapis.com/v1beta/files?pageSize=100&amp;key=${apiKey}`;<br>  const res = UrlFetchApp.fetch(url);<br>  console.log(res.getContentText());<br>}</pre><p>When this script is run, the following value is returned.</p><pre>{<br>  &quot;files&quot;: [<br>    {<br>      &quot;name&quot;: &quot;files/###&quot;,<br>      &quot;displayName&quot;: &quot;###&quot;,<br>      &quot;mimeType&quot;: &quot;image/jpeg&quot;,<br>      &quot;sizeBytes&quot;: &quot;123456&quot;,<br>      &quot;createTime&quot;: &quot;2024-03-30T01:23:00.000000Z&quot;,<br>      &quot;updateTime&quot;: &quot;2024-03-30T01:23:00.000000Z&quot;,<br>      &quot;expirationTime&quot;: &quot;2024-04-01T01:23:00.000000Z&quot;,<br>      &quot;sha256Hash&quot;: &quot;###&quot;,<br>      &quot;uri&quot;: &quot;https://generativelanguage.googleapis.com/v1beta/files/###&quot;<br>    },<br>    ,<br>    ,<br>    ,<br>  ]<br>}</pre><p>When the number of files is more than 100, please retrieve all files using pageToken.</p><h3>Generate content from the uploaded file</h3><p>You can see the official document at <a href="https://ai.google.dev/api/rest/v1beta/models/generateContent">Method: models.generateContent</a>. The sample script of Google Apps Script is as follows.</p><p>Please set your API key, the URI of the uploaded file, and the mimeType of the file.</p><pre>function sample3() {<br>  const apiKey = &quot;###&quot;; // Please set your API key.<br>  const fileUri = &quot;https://generativelanguage.googleapis.com/v1beta/files/###&quot;; // Please set your file uri of the uploaded file.<br>  const mimeType = &quot;image/jpeg&quot;; // Please set the mimeType of the uploaded file.<br><br>  const q = &quot;Describe the image and count apples in the image.&quot;;<br>  const model = &quot;models/gemini-1.5-pro-gf-fc&quot;;<br>  const baseUrl = `https://generativelanguage.googleapis.com/v1beta/${model}`;<br>  const payload = {<br>    contents: [{ parts: [{ text: q }, { fileData: { fileUri, mimeType } }] }],<br>  };<br>  const options = {<br>    payload: JSON.stringify(payload),<br>    contentType: &quot;application/json&quot;,<br>    muteHttpExceptions: true,<br>  };<br>  const res = UrlFetchApp.fetch(<br>    `${baseUrl}:generateContent?key=${apiKey}`,<br>    options<br>  );<br>  console.log(res.getContentText());<br>}</pre><p>In this sample, the following image created by Gemini was uploaded as a sample file and was used.</p><figure><img alt="" src="https://cdn-images-1.medium.com/max/800/0*2K3xjxp7uwYgCx7-.png" /></figure><p>There are 12 apples including 7 red apples, 4 green apples, and 1 yellow apple are shown in the image. This image was generated by Gemini.</p><p>When this script is run, the following generated contents are returned.</p><ul><li>At the model models/gemini-1.0-pro-latest, Image input modality is not enabled for models/gemini-1.0-pro-latest was returned.</li><li>At the model models/gemini-1.0-pro-vision-latest, There are 10 apples in the image. Four red, five green, and one yellow. was returned.</li><li>At the model models/gemini-1.5-pro-latest, The image shows a group of apples on a wooden table. There are red, green, and yellow apples. There are 14 apples in total. was returned.</li><li>At the model models/gemini-1.5-pro-gf-fc, The image shows a group of apples on a wooden table. There are 13 apples in total. The apples are of different colors, including red, green, and yellow. The apples are arranged in a random pattern on the table. The light is coming from the left side of the image, and it is casting shadows on the apples and the table. was returned.</li></ul><h3>Delete the uploaded file</h3><p>You can see the official document at <a href="https://ai.google.dev/api/rest/v1beta/files/delete">Method: files.delete</a>. The sample script of Google Apps Script is as follows.</p><p>Please set your API key and the name of the uploaded file.</p><pre>function sample4() {<br>  const apiKey = &quot;###&quot;; // Please set your API key.<br>  const name = &quot;files/###&quot;; // Please set the name of the uploaded file.<br><br>  const url = `https://generativelanguage.googleapis.com/v1beta/${name}?key=${apiKey}`;<br>  const res = UrlFetchApp.fetch(url, { method: &quot;delete&quot; });<br>  console.log(res.getContentText()); // {}<br>}</pre><p>In this case, an empty object like {} is returned.</p><p>In the current stage, the expiration time of the uploaded file is 2 days. So, the uploaded file is automatically deleted 2 days later.</p><h3>Summary</h3><p>In this report, we present sample scripts for using the Gemini API’s generateContent function with uploaded files. Our findings are as follows:</p><ul><li>Uploading files, retrieving file lists, and deleting files all functioned smoothly using an API key. Also, I heard that at Google APIs, both “snake_case” and “camelCase” within the request body. This was confirmed through testing.</li><li>For generating content from uploaded image files, Gemini 1.5 API models models/gemini-1.5-pro-latest and models/gemini-1.5-pro-gf-fc can be used for image analysis. However, accurately counting objects within the image might still be challenging.</li><li>Currently, uploading text, CSV, and PDF files results in an error message like “Request contains an invalid argument.” It appears that only image and movie files are supported at this stage. We anticipate this limitation to be addressed in a future update.</li></ul><h3>Note</h3><ul><li>The top illustration was created by <a href="https://gemini.google.com/">Gemini</a> with giving the abstract.</li></ul><img src="https://medium.com/_/stat?event=post.clientViewed&referrerSource=full_rss&postId=5777f1c902ab" width="1" height="1" alt=""><hr><p><a href="https://medium.com/google-cloud/generating-texts-using-files-uploaded-by-gemini-1-5-api-5777f1c902ab">Generating Texts using Files Uploaded by Gemini 1.5 API</a> was originally published in <a href="https://medium.com/google-cloud">Google Cloud - Community</a> on Medium, where people are continuing the conversation by highlighting and responding to this story.</p>]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Demystifying Google Cloud Networking for Cloud SQL Setup with IAC — Part II]]></title>
            <link>https://medium.com/google-cloud/demystifying-google-cloud-networking-for-cloud-sql-setup-with-iac-part-ii-ae36432d313b?source=rss----e52cf94d98af---4</link>
            <guid isPermaLink="false">https://medium.com/p/ae36432d313b</guid>
            <category><![CDATA[private-service-connect]]></category>
            <category><![CDATA[infrastructure]]></category>
            <category><![CDATA[google-cloud-platform]]></category>
            <category><![CDATA[terraform]]></category>
            <category><![CDATA[cloud-networking]]></category>
            <dc:creator><![CDATA[paras mamgain]]></dc:creator>
            <pubDate>Sun, 31 Mar 2024 02:50:19 GMT</pubDate>
            <atom:updated>2024-03-31T02:50:19.343Z</atom:updated>
            <content:encoded><![CDATA[<h3><strong>Demystifying Google Cloud Networking for Cloud SQL Setup with IAC — Part II</strong></h3><figure><img alt="" src="https://cdn-images-1.medium.com/proxy/1*O2A2IBNzegsOF79melvcjA.png" /><figcaption>Simplifying Cloud Networking (Private Service Connect) for Cloud SQL</figcaption></figure><p>In our <a href="https://medium.com/google-cloud/demystifying-google-cloud-networking-for-cloud-sql-setup-with-infrastructure-as-code-iac-2873d4068ed8">previous write up</a> we described and shared the IaC code that uses the <a href="https://cloud.google.com/sql/docs/mysql/configure-private-services-access"><strong>Private Service Access (PSA)</strong></a> and its unique ability in google cloud to enable the accessiblity with the managed service using the private IP address of the managed service. <br>This means a client can connect to the managed service wiithout there instance being ever exposed to outside world via public IP address thus providing better and a more granular approach to finetune security.</p><p>In short, private service access enables the client to reach the internal IP address of the google managed service and third part service by using secure and private connections. This becomes very useful when we want to use the private IP address instead of external IP address.</p><p>This article dives into Google Cloud’s Private Service Connect (PSC). We’ll explore the challenges it solves and how terraform can automate infrastructure management for Cloud SQL instance using PSC mode of connectivity.</p><h3>The Problem: Simplify Private Service Connect in Cloud Networking for Cloud SQL instance</h3><p>Configuring Google Cloud networking for Cloud SQL instances can be challenging especially for users who are not familiar with the intricacies of VPCs, subnets, private service connect and firewall rules. To simplify this process, we’ve bundled Terraform modules into a single repository to handle the networking configuration seamlessly.</p><p><strong>e.g.</strong> A VM instance present in our google cloud network can use the internal IP address of the google cloud sql instance instead of its public IP address to establish a private connection using private service connect.</p><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/1*5GI9oZ_Pw_d5gxsIfY6O8w.png" /></figure><p>Private service connect aims to incrementally address secure private connections providing greater flexibility and a centralized way to manage private connections compared to setting up individial VPC peering within cloud environments.</p><p>While PSA (Private Service Access) and PSC (Private Service Connect) are both the functionality that enables safe, secure and private connection to services they differ slightly in there approach.</p><h3>Simplify Private Service Connect (PSC)</h3><p><a href="https://cloud.google.com/vpc/docs/private-service-connect"><strong>Private Service Connect</strong></a> facilitates the private connection between your google cloud VPC and services running in another VPC network by means of creating a dedicated connection which is referred as service attachment. Service attachment then routes the traffic between your VPC and the target service’s VPC.</p><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/1*uxOmjYS1IYT3X8W6dbHZ6A.png" /></figure><h4><strong>Utilizing Private Service Connect (PSC)</strong></h4><p>As an end user, following are the high level overview and essential steps required in the configuration of the private service connect (PSC) :</p><ol><li><strong>Create a Private Connection : </strong>When creating a google cloud service instance supporting private service connect (PSC) like Cloud SQL instance we need to enable/configure the instance to use the PSC. When enabled, the Cloud SQL instance creates a service attachment for the instance automatically. <br>The <strong>service attachment</strong> acts as a point that VPC networks use to access the instance.</li><li><strong>Allowed Private Service Connect projects : </strong>Allowed projects are associated with VPC networks &amp; are associated to each Cloud SQL instance. If an instance isn’t contained in any allowed projects, then you can’t enable Private Service Connect for the instance.</li><li><strong>Configure DNS : </strong>While this is an<strong> optional but still a recommended step</strong> to set up a DNS name like <em>myCloudSQLInstance.myProject</em> which resolves to internal IP address assigned by the PSC endpoint.</li><li><strong>Manage Networking: </strong>The way you set up your network for Cloud SQL depends on where your clients are located.</li></ol><ul><li><strong>Clients on-premises or in another cloud:</strong> If your clients are not within Google Cloud, you’ll need a secure connection like Cloud VPN (HA VPN) or Cloud Interconnect to establish a secure connection between your external network and google cloud network.</li><li><strong>Clients within Google Cloud:</strong> If your clients are in the same Google Cloud project or a different project within the same google cloud organization, a simpler approach using VPC peering between your VPCs can be used for communication.</li></ul><p><strong>5</strong>. <strong>Security and IAM Permissions :</strong> Make sure the necessary the firewalls rules are configured appropriately to allow the client to connect to the instance via its whitelisted ip address &amp; ports along with the necessary IAM permissions to the client so that the user account, service account at the client side is able to establish a client connection.</p><p><strong>e.g.</strong> <em>roles/cloudsql.client</em> permission would be required for the compute service account expecting to establish a connection to cloud sql instance.</p><h3><strong>The Solution: Terraform Modules for Simplifying the configuration and usage of Google Cloud SQL with private service connect</strong></h3><p>The pre-built modules bundle everything you need to connect securely to a private Cloud SQL instance using Private Service Connect. No need to be a cloud networking expert — the modules handle the complexity of setting up Private Service Connect endpoints, service attachments etc. <br>Database administrators and application engineers can easily configure Cloud SQL with the required network components.</p><h3>Supported Usage Scenarios</h3><p>To further assist you in using our simplified networking cloud sql modules, we’ve included multiple examples in the <a href="https://github.com/GoogleCloudPlatform/terraform-google-cloudsqlnetworking/tree/main/examples">examples</a> folder of the github code repository.</p><p>These examples cover different scenarios, complete with implementation guides and architecture designs. Here is a short description about them that you can explore:</p><ol><li><a href="https://github.com/GoogleCloudPlatform/terraform-google-cloudsqlnetworking/blob/main/examples/3.PSC"><strong>PSC Scenario</strong></a><strong> (within same google cloud org) :</strong> This solution guides a user to create a PSC enabled Cloud SQL instance with a consumer and producer project setup having a compute VM instance created in the consumer project connecting to the Cloud SQL instance through PSC service endpoint.</li><li><a href="https://github.com/GoogleCloudPlatform/terraform-google-cloudsqlnetworking/blob/main/examples/4.PSC-Across-VPN"><strong>PSC across VPN Scenario</strong></a><strong> : </strong>This solution helps user with the IaC code to create a HA VPN connection between user and consumer project to connect to a PSC enabled Cloud SQL instance in a producer project from a compute VM instance through PSC service endpoint.</li></ol><p>If you’re ready to supercharge your Google Cloud SQL configuration with private service connect, explore our repository and discover how Terraform modules and the simplified samples can make your life easier. Say goodbye to complex networking configurations and hello to simplified Cloud SQL deployment.</p><p><a href="https://github.com/GoogleCloudPlatform/terraform-google-cloudsqlnetworking/tree/main">Explore the Simplified Cloud Sql Networking Terraform Module Repository</a></p><p>You can also refer to previous write up <a href="https://medium.com/google-cloud/demystifying-google-cloud-networking-for-cloud-sql-setup-with-infrastructure-as-code-iac-2873d4068ed8">Demystifying Google Cloud Networking for Cloud SQL Setup with IAC — Part I</a></p><p>If you have any specific suggestions, scenarios or ideas that you would like to cover then feel free to reach out to us.</p><img src="https://medium.com/_/stat?event=post.clientViewed&referrerSource=full_rss&postId=ae36432d313b" width="1" height="1" alt=""><hr><p><a href="https://medium.com/google-cloud/demystifying-google-cloud-networking-for-cloud-sql-setup-with-iac-part-ii-ae36432d313b">Demystifying Google Cloud Networking for Cloud SQL Setup with IAC — Part II</a> was originally published in <a href="https://medium.com/google-cloud">Google Cloud - Community</a> on Medium, where people are continuing the conversation by highlighting and responding to this story.</p>]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[GKE + Gemma + Ollama: The Power Trio for Flexible LLM Deployment ]]></title>
            <link>https://medium.com/google-cloud/gke-gemma-ollama-the-power-trio-for-flexible-llm-deployment-5f1fa9223477?source=rss----e52cf94d98af---4</link>
            <guid isPermaLink="false">https://medium.com/p/5f1fa9223477</guid>
            <category><![CDATA[llm]]></category>
            <category><![CDATA[google-cloud-platform]]></category>
            <category><![CDATA[kubernetes]]></category>
            <category><![CDATA[gemma]]></category>
            <category><![CDATA[ollama]]></category>
            <dc:creator><![CDATA[Federico Iezzi]]></dc:creator>
            <pubDate>Fri, 29 Mar 2024 03:27:33 GMT</pubDate>
            <atom:updated>2024-03-29T08:13:48.579Z</atom:updated>
            <cc:license>http://creativecommons.org/licenses/by/4.0/</cc:license>
            <content:encoded><![CDATA[<p>In today’s exploration, we delve into the intricacies of deploying a variety of LLMs, focusing particularly on <a href="https://ai.google.dev/gemma/docs">Google</a> <a href="https://huggingface.co/google/gemma-7b">Gemma</a>. The platform of choice will be GKE with invaluable assistance from the <a href="https://github.com/ollama/ollama">Ollama</a> framework. Our journey to achieving this milestone will be facilitated by the <a href="https://github.com/open-webui/open-webui">Open WebUI</a>, which bears a remarkable resemblance to the original OpenAI ChatGPT prompt interface, ensuring a seamless and intuitive user experience.</p><p>Before going into the nitty and gritty details, let’s address the elephant in the room: why pursue this route in the first place? To me, the rationale is crystal clear and can be distilled into several compelling factors:</p><ol><li><strong>Cost-Effectiveness</strong>: Operating LLMs on public cloud infrastructures could potentially offer a more economical solution, especially for smaller organizations or research entities constrained by budgetary limitations. It’s essential, however, to underscore the conditional nature of this benefit, as platforms like Vertex AI Studio and the OpenAI Developer Platform already provide cost-effective, fully flashed, managed services. Vertex AI will also manage life-cycle and observability of your models. Bear that in mind.</li><li><strong>Customization and Flexibility</strong>: Ollama is crafted with customization, flexibility, and open-source principles at its core. Despite the comprehensive model offerings available through cloud providers’ model registries — Google’s one being the <a href="https://cloud.google.com/vertex-ai/generative-ai/docs/model-garden/explore-models">Model Garden that features a more than comprehensive offering</a> — there may be scenarios where a specific model you’re interested in isn’t readily available. This is where Ollama steps in, offering a solution.</li><li><strong>Portability across environments</strong>: Ollama’s design is cloud and platform-agnostic, granting the freedom to deploy it on any private or public platform that accommodates Docker, even on your own laptop. This stands in contrast to other powerful solutions like Vertex AI and SageMaker, which are inherently tied to their respective cloud environments. There is a reason why Docker and Kubernetes took over the entire market. And the very same thing is also valid for x86.</li><li><strong>Privacy and Data Control</strong>: For those inclined towards harnessing fully open-source models, such as 🌋 <a href="https://github.com/haotian-liu/LLaVA">LLaVA</a> and Gemma, within a wholly private framework, this approach offers an optimal path to ensuring data privacy and full control over the deployment environment.</li></ol><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/1*5M-E3pGI5YYeRTXG4rauRQ.png" /></figure><p>∘ <a href="#1234">The GKE Platform</a><br> ∘ <a href="#a10a">Deploying Ollama and Open WebUI (Formerly Ollama WebUI)</a><br> ∘ <a href="#cf41">GPU vs. CPU — a matter of speed</a><br> ∘ <a href="#6f00">Ollama’s Current Limitations: A Deeper Dive</a><br> ∘ <a href="#b26c">Key Takeaways</a></p><h4>The GKE Platform</h4><p>For this experiment, my GKE platform setup prioritized efficiency and performance:</p><ul><li><strong>GKE 1.27 (Regular channel)</strong>: Ensures compatibility and access to recent Google Kubernetes Engine features.</li><li><strong>Container-Optimized OS</strong>: Reduces node startup time for faster workload deployment (<a href="https://medium.com/google-cloud/cut-container-startup-time-for-better-performance-and-costs-part1-02ff48178aff">you can read more on my former article</a>).</li><li>g2-standard-4 <strong>Node Pool (NVIDIA L4 GPU)</strong>: Powerful combination of GPU and CPU resources, ideal for ML tasks. <em>Benchmark results will illustrate the advantages</em>.</li><li><strong>Managed NVIDIA GPU drivers</strong>: Streamlined setup process by integrating drivers directly into GKE, ensuring seamless experience just a flag away gpu-driver-version. <a href="https://cloud.google.com/kubernetes-engine/docs/how-to/gpus#:~:text=DRIVER_VERSION%3A%20the%20NVIDIA%20driver%20version%20to%20install.%20Can%20be%20one%20of%20the%20following%3A">Once the cluster is up it’s also ready to go</a>.</li></ul><p>The <a href="https://www.nvidia.com/en-us/data-center/l4/">NVIDIA L4 GPU</a> pack a punch when it comes to raw specs and results in robust processing capabilities for compute-intensive ML workloads:</p><ul><li>7680 Shader Processors, 240 TMUs, 80 ROPs, 60 RT cores, 240 Tensor Cores.</li><li>24GB GDDR6 memory at 300GB/s bandwidth.</li><li>485 teraFLOPs (FP8 throughput).</li></ul><p><a href="https://cloud.google.com/compute/docs/accelerator-optimized-machines#g2-vms">The G2 Machine Series</a> is the underline platform, based on Intel Cascade Lake and it provides excellent all-around processing to complement the GPU and keep it fed.</p><p>G2 supports <a href="https://cloud.google.com/compute/docs/instances/spot">Spot VM</a>: Offers substantial cost savings (approximately 67% discount) for suitable ML workloads that can tolerate interruptions.</p><h4>Deploying Ollama and Open WebUI (Formerly Ollama WebUI)</h4><p>The K8s ecosystem’s maturity has simplified the deployment process, now essentially a matter of executing helm install and kubectl apply commands. For Ollama, the deployment leverages a community-driven <a href="https://github.com/otwld/ollama-helm">Helm Chart available on GitHub</a>, outlining a canonical values.yaml file to guide the configuration:</p><pre>ollama:<br>  gpu:<br>    enabled: true<br>    type: &#39;nvidia&#39;<br>    number: 1<br>  models:<br>    - gemma:7b<br>    - llava:13b<br>    - llama2:7b<br>persistentVolume:<br>  enabled: true<br>  size: 100Gi<br>  storageClass: &quot;premium-rwo&quot;</pre><p>Conversely, for deploying Open WebUI, the choice veered towards an official Chart and Kustomize template from the community, offering a more fitting approach for this implementation:</p><p><a href="https://github.com/open-webui/open-webui/tree/main/kubernetes/manifest">open-webui/kubernetes/manifest at main · open-webui/open-webui</a></p><p>While Open WebUI offers manifests for Ollama deployment, I preferred the feature richness of the Helm Chart. After deployment, you should be able to access the Open WebUI login screen by navigating to the GCP Load Balancer’s IP address on port 8080.</p><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/1*3NgC2Pj4BjXnbY2hzLCMaA.png" /></figure><p>Simple checks in the ollama namespace should show all systems operational.</p><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/1*RsYpDtZ--YH9DC1pP0N5tg.png" /></figure><p>Let’s tackle a classic science question: Why is the sky blue?</p><figure><img alt="" src="https://cdn-images-1.medium.com/max/694/1*0CM7W3rKWJbuMEGsAGkC5Q.gif" /></figure><p>This is real-time footage — Gemma 7B on the NVIDIA L4 delivers results at lightning speed! Want to try it yourself? Deploying models on Ollama couldn’t be easier: just use ollama run gemma:7b.</p><h4>GPU vs. CPU — a matter of speed</h4><p>Now that the platform is ready to rock, you know I can’t resist a good benchmark session 😉. I ran two types of benchmarks across different models:</p><ul><li>The classic Why is the sky blue? question: Put to Gemma 2B and 7B, as well as LLaMA v1.6 7B and 13B. Gotta test those multimodal and unimodal LLMs!</li><li><a href="https://ollama.com/library/llava#:~:text=of%20the%20picture.-,API%20Usage,-curl%20http%3A//localhost">What’s in this picture?</a> for LLaMA v1.6 7B and 13B: Focusing on image analysis here.</li></ul><p>Don’t worry, I’m not about to start a full-blown LLM showdown — that’s a whole different rabbit hole and way above my understanding. My goal was to track how different machine types impact speed and responsiveness.</p><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/1*Huo2-5vD6eTN6N6uT9qFCQ.png" /><figcaption>Prices comparison for europe-west4 region</figcaption></figure><p>Without GPU acceleration, inference performance depended entirely on raw CPU power and memory bandwidth. Naturally, I deployed Ollama without CPU or memory limits and verified full CPU utilization. However, inference tasks often become bottlenecked by memory bandwidth availability and memory architecture.</p><p>This first graph illustrates several key metrics:</p><ul><li>total duration: How long the model takes to process the input and generate a response.</li><li>response_token/s: A measure of how quickly the model produces output.</li><li>monthly cost: The financial impact of running the chosen configuration for an entire month.</li></ul><figure><img alt="" src="https://cdn-images-1.medium.com/max/778/1*sWBP22YhgTooiCwY1oephw.png" /></figure><p>A lot needs to be unpacked here but I want to start with a warning: the performance numbers you are about to witness are representative just of this specific scenarios. The world of LLM is so vast and fast, that this current picture could be completely irrelevant in a matter of days and even with slightly different scenarios.</p><p><strong>GPU Dominance:</strong></p><ul><li>GPUs deliver drastically lower latency (higher tokens per second) than CPUs. Even 180 dedicated CPU cores at $12k/month can’t compete.</li><li>The NVIDIA L4 offers a 15% speed advantage over the older T4, with a 78% cost increase. Sustained Use Discounts were factored in.</li><li>While the A100 is lightning-fast, about three times faster than L4, its high price and focus on training make it overkill for most inference tasks. Yet it managed to answer in just shy of 3.6 seconds 🤯.</li></ul><p><strong>CPU Struggles:</strong></p><ul><li>Smaller CPUs are undeniably slow and surprisingly expensive.</li><li>Even cost-comparable CPUs (c3-highcpu-22 / c3d-highcpu-16) lag behind the L4 and T4 in throughput.</li><li>The largest CPUs (c3-standard-176 / c3d-standard-360) offer poor performance for their exorbitant cost.</li><li>C3 scale badly, this could be a potential issues with ollama/llama.cpp, my setup, or C3 instance and their lack of vNUMA topology. Regardless, the price makes it pointless.</li></ul><p>Now, looking at an image recognition prompt, this time the model of choice was LLaVA v1.6 with 13B parameters.</p><figure><img alt="" src="https://cdn-images-1.medium.com/max/778/1*QUTVen_J89VgeLOuUKWaEA.png" /></figure><p>The GPU’s performance advantage holds true here as well, demonstrating that CPUs simply can’t compete in this domain. Interestingly, the c3-standard-176 finally outperformed the c3-highcpu-22, which dispels any suspicions of bugs in C3 or my setup.</p><p>As per tradition, all results are publicly available at the following Google Sheet:</p><p><a href="https://docs.google.com/spreadsheets/d/1WUBMBfEtK6TXbo0yTZbjwk-72vvM_S8gsiCNXHf6VUY/edit?usp=sharing">[ollama][medium] - GPU vs. CPU - Mar 28th 2024</a></p><p>Before discussing a few points about Ollama, I’d like to share the exact SHA and tags used in this environment. The AI world is moving so fast that anybody attempting at reproducing my work could discover a different landscape just a few weeks down the road:</p><ul><li>ollama <a href="https://github.com/ollama/ollama/releases/tag/v0.1.29">v0.1.29</a>;</li><li>Gemma 2B SHA b50d6c999e59</li><li>Gemma 7B SHA 430ed3535049</li><li>LLaVA v1.6 7B SHA 8dd30f6b0cb1</li><li>LLaVA v1.6 13B SHA 0d0eb4d7f485</li></ul><p>And on the how the benchmark were executed:</p><pre>curl http://localhost:8080/api/generate -d \<br>&#39;{<br>  &quot;model&quot;: &quot;gemma:7b&quot;,<br>  &quot;prompt&quot;: &quot;Why is the sky blue?&quot;,<br>  &quot;stream&quot;: false,<br>  &quot;options&quot;: {&quot;seed&quot;: 100}<br>}&#39;</pre><pre>curl http://localhost:8080/api/generate -d \<br>&#39;{<br>  &quot;model&quot;: &quot;llava:13b&quot;,<br>  &quot;prompt&quot;:&quot;What is in this picture?&quot;,<br>  &quot;images&quot;: [&quot;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&quot;],<br>  &quot;stream&quot;: false,<br>  &quot;options&quot;: {&quot;seed&quot;: 100}<br>}&#39;</pre><p>As you can see, while recording the results:</p><ul><li>Direct Ollama API communication.</li><li>Streaming disabled.</li><li>Same seed across all prompts.</li></ul><h4>Ollama’s Current Limitations: A Deeper Dive</h4><p>While it’s important to remember that Ollama is a rapidly evolving project, it’s useful to examine some key constraints that power users should be aware of:</p><ul><li><strong>The Repository Bottleneck</strong>: Being locked into <a href="https://github.com/ollama/ollama/blob/v0.1.29/server/modelpath.go#L22">registry.ollama.ai</a> stifles innovation and experimentation. Imagine if Docker had never expanded beyond Quay.io! While a workaround might be possible, a native solution for diverse model sources would be a huge step forward and <a href="https://github.com/ollama/ollama/issues/962">the community has already made a proposal</a>.</li><li><strong>Missed Opportunities with Parallelism</strong>: Ollama’s sequential request handling limits its real-world throughput. Imagine a high-traffic scenario where users experience frustrating delays. The good news is that parallel decoding <a href="https://github.com/ollama/ollama/pull/3348">was merged in </a><a href="https://github.com/ollama/ollama/pull/3348">llama.cpp and pulled in during the v0.1.30</a> cycle — something to keep a close eye on <a href="https://github.com/ollama/ollama/issues/358">is issue #358 open upstream</a>.</li><li><strong>The AVX512 Letdown and an Emerging Option</strong>: It’s disappointing that AVX512 optimizations don’t deliver the expected performance boost in Ollama. <a href="https://github.com/ollama/ollama/issues/2205#issuecomment-2013087742">I even made an attempt at making it better</a> before facing reality: AVX512 sucks, it’s slower than AVX2 😭 (of course the core clock is more than halve), and “<a href="https://www.extremetech.com/computing/312673-linus-torvalds-i-hope-avx512-dies-a-painful-death">I Hope AVX512 Dies a Painful Death</a>”. Intel AMX paints a brighter picture. Its competitive pricing, <a href="https://github.com/ggerganov/llama.cpp/issues/2555">early benchmark results</a>, and the potential to outpace GPUs in certain workloads make it an exciting alternative. On this topic, I strongly encourage a deep look at The Next Platform take on why AI Inference will remain largely on CPUs.</li></ul><p><a href="https://www.nextplatform.com/2023/04/05/why-ai-inference-will-remain-largely-on-the-cpu/">Why AI Inference Will Remain Largely On The CPU</a></p><h4>Key Takeaways</h4><p>Deploying LLMs on GKE with Ollama offers a compelling option for users prioritizing customization, flexibility, potential cost savings, and privacy within their LLM solutions. This approach unlocks the ability to use models unavailable on commercial platforms and provides complete control over the deployment environment. Crucially, GPU acceleration is indispensable for optimal LLM performance, drastically outpacing even powerful CPU-based instances. However, it’s essential to stay mindful of Ollama’s current limitations, such as the registry dependency and sequential request handling, which may impact real-world scenarios. As Ollama continues to evolve, these limitations are likely to be addressed, further enhancing its potential.</p><p><em>I hope you had fun, this was a new journey also for me. If you have any questions, do not hesitate and leave a comment.</em></p><img src="https://medium.com/_/stat?event=post.clientViewed&referrerSource=full_rss&postId=5f1fa9223477" width="1" height="1" alt=""><hr><p><a href="https://medium.com/google-cloud/gke-gemma-ollama-the-power-trio-for-flexible-llm-deployment-5f1fa9223477">GKE + Gemma + Ollama: The Power Trio for Flexible LLM Deployment 🚀</a> was originally published in <a href="https://medium.com/google-cloud">Google Cloud - Community</a> on Medium, where people are continuing the conversation by highlighting and responding to this story.</p>]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Gemini codelab for Java developers using LangChain4j]]></title>
            <link>https://medium.com/google-cloud/gemini-codelab-for-java-developers-using-langchain4j-769fbd419756?source=rss----e52cf94d98af---4</link>
            <guid isPermaLink="false">https://medium.com/p/769fbd419756</guid>
            <category><![CDATA[langchain4j]]></category>
            <category><![CDATA[gemini]]></category>
            <category><![CDATA[google-cloud-platform]]></category>
            <category><![CDATA[gcp-app-dev]]></category>
            <category><![CDATA[java]]></category>
            <dc:creator><![CDATA[Guillaume Laforge]]></dc:creator>
            <pubDate>Fri, 29 Mar 2024 03:27:13 GMT</pubDate>
            <atom:updated>2024-03-29T03:27:13.378Z</atom:updated>
            <content:encoded><![CDATA[<figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/0*f6qD8NYosB2mVZD2.jpg" /></figure><p>No need to be a Python developer to do Generative AI! If you’re a Java developer, you can take advantage of <a href="https://docs.langchain4j.dev/">LangChain4j</a> to implement some advanced LLM integrations in your Java applications. And if you’re interested in using <a href="https://blog.google/technology/ai/google-gemini-next-generation-model-february-2024/">Gemini</a>, one of the best models available, I invite you to have a look at the following “codelab” that I worked on:</p><p><a href="https://codelabs.developers.google.com/codelabs/gemini-java-developers">Codelab — Gemini for Java Developers using LangChain4j</a></p><p>In this workshop, you’ll find various examples covering the following use cases, in <em>crescendo</em> approach:</p><ul><li>Making your fist call to Gemini (streaming &amp; non-streaming)</li><li>Maintaining a conversation</li><li>Taking advantage of multimodality by analysing images with your prompts</li><li>Extracting structured information from unstructured text</li><li>Using prompt templates</li><li>Doing text classification with few-shot prompting</li><li>Implementing Retrieval Augmented Generation to chat with your documentation</li><li>How to do Function Calling to expand the LLM to interact with external APIs and services</li></ul><p>You’ll find all the <a href="https://github.com/glaforge/gemini-workshop-for-java-developers">code samples on Github</a>.</p><p>If you’re attending Devoxx France, be sure to attend the <a href="https://www.devoxx.fr/en/schedule/talk/?id=40285">Hands-on-Lab workshop</a> with my colleagues <a href="https://twitter.com/meteatamel">Mete Atamel</a> and <a href="https://twitter.com/val_deleplace">Valentin Deleplace</a> who will guide you through this codelab.</p><p><em>Originally published at </em><a href="https://glaforge.dev/posts/2024/03/27/gemini-codelab-for-java-developers/"><em>https://glaforge.dev</em></a><em> on March 27, 2024.</em></p><img src="https://medium.com/_/stat?event=post.clientViewed&referrerSource=full_rss&postId=769fbd419756" width="1" height="1" alt=""><hr><p><a href="https://medium.com/google-cloud/gemini-codelab-for-java-developers-using-langchain4j-769fbd419756">Gemini codelab for Java developers using LangChain4j</a> was originally published in <a href="https://medium.com/google-cloud">Google Cloud - Community</a> on Medium, where people are continuing the conversation by highlighting and responding to this story.</p>]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Secure  Together — Federated Learning for Decentralized Security on GCP]]></title>
            <link>https://medium.com/google-cloud/secure-together-federated-learning-for-decentralized-security-on-gcp-4c6219ba8f09?source=rss----e52cf94d98af---4</link>
            <guid isPermaLink="false">https://medium.com/p/4c6219ba8f09</guid>
            <category><![CDATA[technology]]></category>
            <category><![CDATA[ai]]></category>
            <category><![CDATA[google-cloud-platform]]></category>
            <category><![CDATA[machine-learning]]></category>
            <category><![CDATA[python]]></category>
            <dc:creator><![CDATA[Imran Roshan]]></dc:creator>
            <pubDate>Thu, 28 Mar 2024 10:20:14 GMT</pubDate>
            <atom:updated>2024-03-28T10:20:14.333Z</atom:updated>
            <content:encoded><![CDATA[<h3>Secure Together — Federated Learning for Decentralized Security on GCP</h3><p>Integrating security mechanisms to enhance organization posture with FL</p><figure><img alt="" src="https://cdn-images-1.medium.com/max/500/0*yCOc3CDRbhGEVJwn.jpeg" /></figure><p>As I might have emphasized enough, I am not a machine learning guy, neither am I able to be the AI boss around people talking deep about models and other jargons that I am falling short of even talking about it right now. But you, you can be rest assured that if you’re reading this article to learn, you’ll be able to because if I could, you can as well.</p><p>Federated Learning (FL) enables cooperative training on decentralized data. By maintaining sensitive data on individual devices or inside organizational silos, this strategy promotes security and privacy in security-sensitive applications. Google Cloud is a desirable choice for developing decentralized security solutions because it provides a stable platform for implementing FL workflows.</p><p>This article explores the fundamental ideas of Federated Learning (FL), looks at how it can help with decentralized security on Google Cloud, and presents use cases along with tools and code samples.</p><h3>Understanding FL</h3><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/0*if1Dz3C2Ej8Nx9D5.png" /></figure><p>Large volumes of data must frequently be centrally located in order for traditional machine learning algorithms to be trained. Privacy issues are brought up by this method, particularly when handling sensitive data such as medical records or financial transactions. Federated learning presents a strong substitute.</p><p>In FL, the training procedure is managed by a central coordinator who does not have direct access to each individual data point. The workflow is broken down as follows:</p><ul><li>Model Distribution: To enable devices or organizations to participate, the coordinator distributes a preliminary global model to them.</li><li>Local Training: Using their own data, each participant trains the model locally. Privacy is guaranteed by this localized training because the raw data never leaves the device or silo.</li><li>Model Updates: In contrast to sending raw data, participants send the coordinator only the model updates, or gradients, greatly cutting down on communication overhead.</li><li>Aggregation of the Global Model: The coordinator compiles the updates that are received and applies them to enhance the global model.</li><li>Iteration: The global model is improved iteratively without jeopardizing data privacy by repeating steps 1–4 for a number of rounds.</li></ul><h4>So what are the benefits?</h4><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/0*cUasHA5oNG5hzkMY.png" /></figure><p>FL offers a number of benefits for developing private-preserving and safe security solutions on Google Cloud:</p><ul><li>Enhanced Data Privacy: FL reduces the possibility of data breaches and unauthorized access by maintaining data decentralization. Organizations handling sensitive security data, such as threat intelligence or user behavior patterns, will especially benefit from this.</li><li>Enhanced Regulatory Compliance: By reducing data collection and sharing, FL can assist businesses in complying with stringent data privacy laws like the California Consumer Privacy Act and the General Data Protection Regulation.</li><li>Collaborative Threat Intelligence Sharing: FL allows security teams from different organizations to securely collaborate with one another. Without disclosing their unique threat intelligence datasets, they can jointly train a threat detection model. This promotes a more thorough comprehension of the changing threat environment.</li><li>On-Device Security Training: FL enables security model training on user devices directly. This protects user privacy while enabling real-time, personalized threat detection and anomaly identification.</li><li>Federated Learning for Secure Multi-party Computation (SMC): To conduct secure computations on sensitive data dispersed among several parties, FL can be coupled with SMC methodologies. This creates opportunities for sophisticated analytics in security applications that protect privacy.</li></ul><h3>Getting to work</h3><figure><img alt="" src="https://cdn-images-1.medium.com/max/453/0*Nk2dhSQSVM-GBvrX.jpg" /></figure><p>Let’s talk about some of the ways we can use FL for securing postures</p><h4><strong>Collaborative Malware Detection</strong></h4><p>Conventional methods of malware detection frequently rely on signature-based techniques. These techniques compare files with known malicious patterns to identify malware. On the other hand, zero-day attacks — attackers who employ novel tactics — are difficult for signature-based methods to identify.</p><p>This restriction is addressed by collaborative malware detection, which shares threat intelligence amongst various systems. This knowledge may consist of:</p><ul><li>File hashes of known malware: Systems can swiftly recognize malware that has already been encountered by exchanging file hashes.</li><li>Data from behavioral analysis: Exchanging information about how files work with the system makes it easier to spot questionable patterns of behavior.</li><li>Compromise Indicators (IOCs): Collective defense is strengthened when information related to malware campaigns, such as URLs, IP addresses, and domain names, are shared.</li></ul><p>Collaborative detection systems are better able to recognize new malware variants and emerging threats by pooling this shared intelligence.</p><p><strong><em>Prepping ourselves</em></strong></p><ul><li>Collect Data: Compile a wide range of benign and malware samples, such as PE and APK files. Online public malware datasets are accessible, but make sure to observe ethical and legal requirements.</li></ul><pre>import apache_beam as beam<br><br>class IngestMalware(beam.DoFn):<br>    def process(self, element):<br>        # element: Malware sample metadata (e.g., filename, source)<br>        file_name = element[&#39;filename&#39;]<br>        # Download malware sample from source based on metadata<br>        download_and_save_malware(file_name)<br>        yield {&#39;filePath&#39;: f&#39;gs://your-bucket/{file_name}&#39;}  # Upload to GCS<br><br>with beam.Pipeline() as pipeline:<br>    malware_data = (<br>        pipeline<br>        | &#39;ReadMetadata&#39; &gt;&gt; beam.io.ReadFromText(&#39;path/to/metadata.csv&#39;)<br>        | &#39;IngestMalware&#39; &gt;&gt; beam.ParDo(IngestMalware())<br>    )</pre><ul><li>Data Labeling: Assign a malicious or benign label to every file. Crowdsourcing platforms or security experts can perform this manually.</li><li>Data Preprocessing: Prepare and clean the data in accordance with the specifications of the selected machine learning model. This could entail formatting, normalization, and feature extraction.</li></ul><pre>import kfp.components as comp<br><br># Download and pre-process internal security data<br>download_security_data = comp....(source=&quot;internal_security_logs&quot;)<br>preprocess_security_data = comp....(inputs=[download_security_data.outputs[&quot;data&quot;]])<br><br># Download and pre-process public threat intelligence data<br>download_threat_intel = comp....(source=&quot;public_threat_feed_url&quot;)<br>preprocess_threat_intel = comp....(inputs=[download_threat_intel.outputs[&quot;data&quot;]])<br><br># Merge both pre-processed datasets<br>merged_data = comp....(inputs=[preprocess_security_data.outputs[&quot;data&quot;], preprocess_threat_intel.outputs[&quot;data&quot;]])<br><br># Create a Vertex AI Pipeline with these components<br>training_pipeline = comp.pipeline(<br>    name=&quot;data_preprocessing_pipeline&quot;,<br>    description=&quot;Preprocesses data for malware detection model training&quot;,<br>    components=[<br>        download_security_data,<br>        preprocess_security_data,<br>        download_threat_intel,<br>        preprocess_threat_intel,<br>        merged_data,<br>    ],<br>)</pre><p>I know you guys are professionals so we won’t delve deeper into this with code. Moving On!</p><p><strong><em>Training Our Model</em></strong></p><ul><li>Select a Model: Depending on the format of your data, choose an appropriate machine learning model (e.g., image classification for executables, NLP for scripts). Scikit-learn models and TensorFlow are popular options.</li><li>Create a Training Script: To load, preprocess, and train the model using your labeled data, write a Python script. For resource management and dispersed training, use Vertex AI Training.</li></ul><pre>from google.cloud importaiplatform<br><br>project = &quot;your-project-id&quot;<br>location = &quot;us-central1&quot;<br><br>endpoint = aiplatform.Endpoint.create(<br>    display_name=&quot;malware-detection-endpoint&quot;,<br>    project=project,<br>    location=location,<br>)<br><br>dataset = aiplatform.Dataset.create(<br>    display_name=&quot;malware-dataset&quot;,<br>    project=project,<br>    location=location,<br>)<br><br># Define training and validation splits<br>train_split = 0.8<br><br>training_job = aiplatform.TrainingJob.create(<br>    display_name=&quot;malware-detection-training&quot;,<br>    project=project,<br>    location=location,<br>    dataset=dataset,<br>    split=train_split,<br>    machine_type=&quot;n1-standard-4&quot;,  # Adjust machine type as needed<br>    target_rotation_period=&quot;30d&quot;,  # Periodic retraining to stay up-to-date<br>    encryption_spec_key_name=&quot;your-encryption-key&quot;,  # Optional encryption<br>)<br><br># Monitor training job progress using aiplatform.TrainingJob.get(training_job.name)</pre><p><strong><em>Alert generation</em></strong></p><p>This sample of code shows how a Cloud Function is started by a Pub/Sub message that contains a malware detection from Vertex AI. Based on collaborative detection results, the function determines the threat type of the finding and, if it indicates malware, generates an alert.</p><pre>import json<br><br>def analyze_malware_finding(data, context):<br>  # Access the Pub/Sub message data<br>  payload = json.loads(data.pubsubj)<br>  finding = payload[&quot;finding&quot;]<br><br>  # Check if the finding indicates malware based on collaborative detection results<br>  if finding[&quot;threat_type&quot;] == &quot;MALWARE&quot;:<br>    # Generate an alert with details from the finding<br>    alert_message = f&quot;Potential Malware Detected: {finding[&#39;file_hash&#39;]}&quot;<br>    # Send the alert using a notification service (e.g., Cloud Monitoring)<br><br></pre><p><strong><em>Alert Integration (Cloud Monitoring API)</em></strong></p><pre>from google.cloud import monitoring_v3<br><br>alerts_service = monitoring_v3.AlertingPolicyServiceClient()<br><br># Define the alert policy details<br>alert_policy = monitoring_v3.AlertPolicy(<br>    name=f&quot;projects/{project}/locations/{location}/alertPolicies/malware_detection_alert&quot;,<br>    # ... other policy configuration options<br>)<br><br># Create the alert policy<br>alerts_service.CreateAlertPolicy(request={&quot;parent&quot;: parent, &quot;alert_policy&quot;: alert_policy})</pre><p><strong>Note: </strong>This is a simplified overview. You’ll need to fill in the details based on your specific requirements and chosen tools. Refer to the Vertex AI and Cloud Monitoring documentation for comprehensive instructions and code examples.</p><h3>Resources</h3><ul><li>Vertex AI Pipelines: <a href="https://cloud.google.com/vertex-ai/docs/pipelines/introduction">https://cloud.google.com/vertex-ai/docs/pipelines/introduction</a></li><li>Custom Training in Vertex AI: <a href="https://cloud.google.com/vertex-ai/docs/training/overview">https://cloud.google.com/vertex-ai/docs/training/overview</a></li><li>Cloud Monitoring Metrics: <a href="https://cloud.google.com/monitoring/api/metrics_gcp">https://cloud.google.com/monitoring/api/metrics_gcp</a></li><li>Alerting Policies in Cloud Monitoring: <a href="https://cloud.google.com/monitoring/alerts">https://cloud.google.com/monitoring/alerts</a></li><li><a href="https://federated.withgoogle.com/">https://federated.withgoogle.com/</a></li></ul><h3>Get in Touch?</h3><p><a href="https://imranfosec.linkb.org/">Imran Roshan</a></p><img src="https://medium.com/_/stat?event=post.clientViewed&referrerSource=full_rss&postId=4c6219ba8f09" width="1" height="1" alt=""><hr><p><a href="https://medium.com/google-cloud/secure-together-federated-learning-for-decentralized-security-on-gcp-4c6219ba8f09">Secure  Together — Federated Learning for Decentralized Security on GCP</a> was originally published in <a href="https://medium.com/google-cloud">Google Cloud - Community</a> on Medium, where people are continuing the conversation by highlighting and responding to this story.</p>]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Upgrades!!! — Everything new with Kubernetes 1.30]]></title>
            <link>https://medium.com/google-cloud/upgrades-everything-new-with-kubernetes-1-30-b539ebfad4ea?source=rss----e52cf94d98af---4</link>
            <guid isPermaLink="false">https://medium.com/p/b539ebfad4ea</guid>
            <category><![CDATA[cloud-computing]]></category>
            <category><![CDATA[cybersecurity]]></category>
            <category><![CDATA[kubernetes]]></category>
            <category><![CDATA[google-cloud-platform]]></category>
            <dc:creator><![CDATA[Imran Roshan]]></dc:creator>
            <pubDate>Thu, 28 Mar 2024 10:20:01 GMT</pubDate>
            <atom:updated>2024-03-28T10:20:01.029Z</atom:updated>
            <content:encoded><![CDATA[<h3>Upgrades!!! — Everything new with Kubernetes 1.30</h3><p>New features, enhancements and everything exciting with Kubernetes 1.30</p><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/1*pruZc4fqDQ7V6hN6z7dnpg.png" /></figure><p>Excited? Aren’t we all? A slew of innovative features aimed at enhancing security, simplifying pod management, and empowering developers are included in this version. Now let’s explore the main features that take Kubernetes 1.30 to the next level.</p><h3>Enhanced Security Again</h3><p>With the introduction of various improvements, Kubernetes 1.30 further establishes itself as a safe platform for workload deployment and management.</p><h4>User namespaces for greater pod isolation [beta]</h4><p>This ground-breaking feature gives users within pods fine-grained control over their identities; it will graduate to beta in 1.30. It permits mapping the various values on the host system to the UIDs (User IDs) and GIDs (Group IDs) used inside a pod. By drastically lowering the attack surface, this isolation method makes it more difficult for compromised containers to abuse privileges on the underlying host.</p><pre>apiVersion: v1<br>kind: Pod<br>metadata:<br>  name: my-secure-pod<br>spec:<br>  securityContext:<br>    userNamespace: true<br>  containers:<br>  - name: my-app<br>    image: my-secure-image:latest</pre><p>To effectively isolate the container from other processes on the host, the Kubelet is instructed to run it with a unique user namespace in this example by setting the userNamespace: true property within the securityContext.</p><h4>Bound service account tokens [beta]</h4><p>For service account authentication, bound service account tokens (SATs) provide a more secure option than conventional, non-bound tokens. Bound SATs, first released in 1.30 as beta, are associated with particular pods and only provide access to the resources needed by those pods. As a result, the potential damage is minimized by reducing the blast radius of compromised tokens.</p><pre>apiVersion: v1<br>kind: Pod<br>metadata:<br>  name: my-pod-with-bound-sat<br>spec:<br>  serviceAccountName: my-service-account<br>  template:<br>    spec:<br>      securityContext:<br>        # Enables the use of the bound service account token<br>        podSecurityContext: {}</pre><p>The pod can utilize the bound service account token linked to the designated service account (my-service-account) by incorporating the podSecurityContext: {} section.</p><h4>Node log queries</h4><p>Understanding node logs is essential for security analysis and troubleshooting. With the beta release of Node Log Query in Kubernetes 1.30, administrators can use the kubelet API to directly query system service logs on nodes. This reduces the attack surface and expedites log collection without requiring additional system access, thereby improving security.</p><p>Imagine running the following command to search logs for kubelet process-related errors:</p><pre>kubectl get --raw &quot;/api/v1/nodes/worker/proxy/logs/?query=kubelet&amp;pattern=error&quot;</pre><p>With this command, logs from the kubelet process running on the “worker” node that specifically contain the keyword “error” are retrieved.</p><h4>AppArmor profile configurations using Pod Security Contexts</h4><p>Within containers, AppArmor profiles offer a potent way to enforce application security policies. By enabling administrators to specify profiles directly within the PodSecurityContext and container.securityContext fields, Kubernetes 1.30 streamlines the configuration of AppArmor. As a result, policy management is simplified and beta AppArmor annotations are no longer required.</p><pre>apiVersion: v1<br>kind: Pod<br>metadata:<br>  name: my-pod-with-apparmor<br>spec:<br>  securityContext:<br>    apparmorProfile: &quot;restricted-runtime&quot;<br>  containers:<br>  - name: my-app<br>    image: my-app-image:latest<br>    securityContext:<br>      apparmorProfile: &quot;runtime/default&quot;</pre><p>Here, the container called “my-app” uses the “runtime/default” profile, but the pod itself is assigned the “restricted-runtime” profile. This provides both pod and container level granular control over AppArmor policies.</p><h3>Enhanced Pod Management</h3><h4>Node Memory Swap</h4><p>Node memory swapping is now supported in Kubernetes 1.30. This may enhance system stability when memory pressure is applied by enabling the kernel to use swap space on nodes for memory management.</p><p>In Kubernetes 1.30, the node memory swap feature has been redesigned to prioritize stability while providing more control. With the introduction of LimitedSwap in place of UnlimitedSwap, Kubernetes offers a more controlled and predictable method for handling swap usage on Linux nodes. Don’t forget to assess your unique requirements prior to activating swap and to put appropriate monitoring procedures in place.</p><pre>kind: KubeletConfiguration<br>apiVersion: kubelet.config.k8s.io/v1beta1<br># ... other kubelet configurations<br>featureGates:<br>  NodeSwap: &quot;true&quot;<br>memorySwap:<br>  swapBehavior: LimitedSwap</pre><h4>Container resource based pod autoscaling</h4><p>By using this feature, horizontal pod autoscaling (HPA) based on memory or CPU metrics of the container is enabled. This makes it possible to scale more precisely depending on the real needs for containers. You can make the most of your Kubernetes clusters’ resource allocation and scaling strategy by concentrating on the metrics of individual containers.</p><pre>apiVersion: autoscaling/v2beta2<br>kind: HorizontalPodAutoscaler<br>metadata:<br>  name: my-hpa<br>spec:<br>  scaleTargetRef:<br>    apiVersion: apps/v1<br>    kind: Deployment<br>    name: my-deployment<br>  minReplicas: 2<br>  maxReplicas: 5<br>  metrics:<br>  - type: Resource<br>    resource:<br>      name: cpu<br>      target:<br>        type: Utilization<br>        averageUtilization: 80<br>  containerMetrics:<br>  - name: web-container # Target container within the Pod</pre><p>During the deployment, the HPA keeps an eye on how much CPU resource each pod is using. The HPA will scale the deployment to maintain an average CPU usage of 80% across all instances of the web container since the average utilization is set to 80. The container name (web-container) for which the CPU metric is to be monitored is specified in the containerMetrics section.</p><h4>Dynamic resource allocation</h4><p>Structured parameters increase the flexibility of resource allocation for pods. By defining resource requests and limits more precisely, developers can optimize the use of available resources.</p><p>In this case, the pod makes a minimum and maximum request for one GPU resource (nvidia.com/gpu [invalid URL removed]). It also uses the standard memory resource definition to request 8GB of memory.</p><pre>apiVersion: v1<br>kind: Pod<br>metadata:<br>  name: my-gpu-app<br>spec:<br>  containers:<br>  - name: gpu-container<br>    resources:<br>      requests:<br>        resource.k8s.io/nvidia.com/gpu:<br>          type: Resource<br>          minimum: 1<br>          maximum: 1<br>        resource.k8s.io/memory:<br>          type: Resource<br>          requests:<br>            memory: &quot;8Gi&quot;</pre><p>DRA in Kubernetes 1.30 opens the door to a more dynamic and effective resource management environment with its structured parameters. As the feature develops, we should anticipate a broader audience and the emergence of a vibrant third-party resource driver ecosystem that meets a variety of application requirements.</p><h3>To Conclude</h3><p>Now, obviously I am not part of the AI fleet to write down every single one of the feature parameters in details so I would redirect you now to the best thing to exist after Ice Cream. THE DOCUMENTATION!</p><ul><li><a href="https://github.com/kubernetes/sig-release/blob/master/releases/release_phases.md#docs-freeze">sig-release/releases/release_phases.md at master · kubernetes/sig-release</a></li><li><a href="https://www.kubernetes.dev/resources/release/">Kubernetes 1.30 Release Information</a></li></ul><h3>Connect with me?</h3><p><a href="https://imranfosec.linkb.org/">Imran Roshan</a></p><img src="https://medium.com/_/stat?event=post.clientViewed&referrerSource=full_rss&postId=b539ebfad4ea" width="1" height="1" alt=""><hr><p><a href="https://medium.com/google-cloud/upgrades-everything-new-with-kubernetes-1-30-b539ebfad4ea">Upgrades!!! — Everything new with Kubernetes 1.30</a> was originally published in <a href="https://medium.com/google-cloud">Google Cloud - Community</a> on Medium, where people are continuing the conversation by highlighting and responding to this story.</p>]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Design your Landing Zone — Design Considerations Part 3 — Monitoring, Logging, Billing and…]]></title>
            <link>https://medium.com/google-cloud/design-your-landing-zone-design-considerations-part-3-monitoring-logging-billing-and-7b40189a3c81?source=rss----e52cf94d98af---4</link>
            <guid isPermaLink="false">https://medium.com/p/7b40189a3c81</guid>
            <category><![CDATA[labelling]]></category>
            <category><![CDATA[gcp-security-operations]]></category>
            <category><![CDATA[logging-and-monitoring]]></category>
            <category><![CDATA[google-cloud-platform]]></category>
            <category><![CDATA[landingzone]]></category>
            <dc:creator><![CDATA[Dazbo (Darren Lester)]]></dc:creator>
            <pubDate>Thu, 28 Mar 2024 02:45:19 GMT</pubDate>
            <atom:updated>2024-03-29T11:17:27.910Z</atom:updated>
            <content:encoded><![CDATA[<h3>Design your Landing Zone — Design Considerations Part 3 — Monitoring, Logging, Billing and Labelling (Google Cloud Adoption Series)</h3><p>Welcome to Part 3 of Landing Zone Design Considerations. This is part of the <a href="https://medium.com/google-cloud/google-cloud-adoption-for-the-enterprise-from-strategy-to-operation-part-0-overview-9091f5a1ddfc">Google Cloud Adoption and Migration: From Strategy to Operation</a> series.</p><p>In this part I’ll cover:</p><ul><li><strong>Monitoring strategy</strong></li><li><strong>Logging strategy</strong></li><li><strong>Billing management and billing exports, and labelling</strong></li></ul><h3>9. Monitoring Strategy</h3><p><strong>Monitoring is the process of collecting, processing, aggregating and displaying real time and historical quantitative data about a system.</strong></p><h4>Metrics</h4><p>Google Cloud provides out-of-the-box monitoring, through the <a href="https://cloud.google.com/monitoring/docs">Cloud Monitoring</a> component (formerly known as Stackdriver) of Google Cloud Operations (GCO) Suite. Cloud Monitoring automatically ingests over 1500 different metrics from over 100 different Google Cloud resources. There is <strong>no cost</strong> for ingestion of these metrics. For example:</p><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/0*z2cAyus-9hJwGMOI" /><figcaption>Cloud Monitoring ingests metrics from Google Cloud services and applications</figcaption></figure><p>In addition, we can ingest metrics such as:</p><ul><li><strong>Custom metrics</strong>, where we programmatically create custom telemetry using, e.g. with the Cloud Monitoring API, with OpenCensus, and (for GKE) with Prometheus.</li><li><strong>Log-based metrics</strong>, i.e. where real-time information is derived from logs.</li><li>Additional VM process metrics, via the <strong>Cloud Ops Agent</strong>.</li><li>Out-of-the-box <strong>application metrics</strong>, such as nginx, Apache web server, MongoDB, Tomcat.</li><li><strong>GKE workloads</strong>, using natively-integrated <strong>Prometheus and OpenTelemetry.</strong></li><li><strong>Hybrid cloud monitoring</strong> — e.g. monitoring signals from on-prem, AWS and Azure — using Blue Medora BindPlane.</li></ul><figure><img alt="" src="https://cdn-images-1.medium.com/max/876/1*Z13YCBUiR0Dwvk26zdWbdw.png" /><figcaption>Types of metrics collected by Google Cloud Monitoring</figcaption></figure><p>Be mindful that certain metrics — such as custom metrics and logs-based metrics — have an ingestion cost. So for such metrics, only ingest what is truly valuable.</p><h4>Visualisation and Analysis</h4><p>Of course, it’s not much use collecting metrics if you don’t do anything with this data. Cloud Monitoring allows you to:</p><ul><li>Create charts</li><li>Use predefined and custom dashboards</li><li>Share charts and dashboards</li></ul><figure><img alt="" src="https://cdn-images-1.medium.com/max/947/0*nYnr6VuP1KsB6enp" /><figcaption>Custom dashboards are assembled from charts</figcaption></figure><ul><li>Create healthchecks</li><li>Define services and <a href="https://medium.com/@derailed.dash/google-cloud-adoption-site-reliability-engineering-sre-and-best-practices-for-sli-slo-sla-6670c864c96b">SLOs</a></li><li>Create <a href="https://medium.com/@derailed.dash/google-cloud-adoption-site-reliability-engineering-sre-and-best-practices-for-sli-slo-sla-6670c864c96b">alerting policies</a></li></ul><p>So the end-to-end consumption and use of metrics looks something like this:</p><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/0*RXYR2m78q2tVDiOq" /><figcaption>Making use of your metrics in Google Cloud Monitoring</figcaption></figure><h4>Metrics Scope Strategy</h4><p>Google Cloud Monitoring defines an object called a <strong>metrics scope</strong> (formerly called a workspace). Such a scope defines the set of Google Cloud projects who metrics are visible from a <em>“single pane of glass”</em>. Each scope contains:</p><ul><li>Predefined and custom dashboards</li><li>Alerting policies</li><li>Uptime checks</li><li>Notification channels</li><li>(Resource) group definitions</li></ul><p>Every project has its own metrics scope, and — by default — this metrics scope only has visibility of the resources in <em>that </em>project. However, we can extend this scope to include the metrics from other projects. And <strong>this is how we can centralise and aggregate monitoring across projects</strong>.</p><figure><img alt="" src="https://cdn-images-1.medium.com/max/953/1*GZkybWPHuPjzDJsWo794TQ.png" /><figcaption>Using a single metrics scope to monitor production projects</figcaption></figure><p>And consequently, it is important to design your metrics scope strategy. Broadly, you have three options:</p><ol><li><strong>One metrics scope for many related projects, across different environments</strong>. Here we have a single pane of glass for all related projects. However, anyone with the monitoring.viewer IAM role for the monitoring project can see all metrics for all of the projects. Thus, we have no granular control over monitoring.</li><li><strong>Maximum isolation</strong> — every project is monitored by a separate scope. Viewers in one project can’t (by default) see any metrics from another. This provides the highest degree of separation, but also potentially the higest operational management overheads.</li><li><strong>In-between</strong> — i.e. one scope for a small number of related projects. For example, we might have different scopes for production versus non-production. We do need to think about our project groupings.</li></ol><h4>Decision Points</h4><p>Here’s a recap of some of the key decisions that need to be made</p><ul><li><strong>Where is your monitoring single pane of glass? </strong>Where possible, I’d recommend using only GCO Cloud Monitoring for the monitoring of Google Cloud infrastructure, services and applications. I.e. align to the “Cloud native / Cloud managed” principle. However, in hybrid environments, organisations may want to make use of existing external monitoring tools, such as New Relic. Be advised that this can considerably increase monitoring costs, e.g. through licensing of the third party monitoring tool, as well as egress costs.</li><li><strong>Organisational granularity and visibility of monitoring</strong>? SRE approach? Metrics scope strategy? Here we should consider our <a href="https://medium.com/@derailed.dash/google-cloud-adoption-site-reliability-engineering-sre-and-best-practices-for-sli-slo-sla-6670c864c96b">organisational SRE model</a>. And we should decide on the appropriate level of metrics scope granularity.</li><li><strong>Establish your organisational best practices</strong> <strong>for what will be monitored</strong>, e.g. golden signals (latency, traffic, errors, saturation), SLIs, SLOs, and alerting policies, defined at application level. You will want to make this easily consumable and repeatable.</li><li><strong>Decide which chargeable metrics you want and need.</strong></li><li><strong>Establish your alerting channels and best practices.</strong> E.g. define what sorts of alerts are urgent and require human interaction, and will therefore generate pages. Other alerts should generate tickets, and use alternative notification approaches.</li></ul><h3>10. Logging Strategy</h3><p>Also part of the Google Cloud Operations suite, <a href="https://cloud.google.com/logging/docs/overview"><strong>Cloud Logging</strong></a><strong> is a fully-managed serverless service for the ingestion, storing, viewing, searching and analysis of logs.</strong> Cloud Logging components are exposed through the Logging API.</p><figure><img alt="" src="https://cdn-images-1.medium.com/max/887/1*FhJ1xCaL1dwx3u62_AUCyQ.png" /><figcaption>Google Cloud Logging Capabilities</figcaption></figure><p>Logs are ingested from various sources, such as Google Cloud resources, GKE, third party applications, and user applications runing on Google Cloud.</p><p>The overall Cloud Logging architecture looks like this:</p><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/0*p9T72CmrW-fwRJGS" /><figcaption>Google Cloud Logging architecture</figcaption></figure><h4>Log Routing and Sinks</h4><p>The <strong>Log Router</strong> is responsible for ensuring that logs are reliably and efficiently streamed to logging destinations, called <strong>Log Sinks</strong>. A log sink is actually the combination of a destination, along with inclusion and exclusion filters:</p><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/0*5YgTa_Bo_gtxyIDz" /><figcaption>A Log Sink</figcaption></figure><p>Possible sinks include:</p><ul><li><strong>Cloud Logging buckets</strong> — special storage buckets optimised for storing logging data, and which can be interrogated directly from the Logs Explorer in the Google Cloud Console.</li><li><strong>Google Cloud Storage</strong> — ideal for cheap long-term and automated log archiving.</li><li><strong>BigQuery </strong>— which is ideal for long-term storage, SQL-based analytics, and dashboarding.</li><li><strong>Pub/Sub topics</strong> — perfect for sending log data to downstream systems, such as on-prem Splunk. But also, we can use this to stream logs via Dataflow. This can be useful if we want to process the logging data on the fly.</li></ul><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/0*WV4rFpxQFqh5aGR9" /><figcaption>Example: Real-time processing of streaming log data</figcaption></figure><p>Two predefined sinks are created in each Google Cloud project:</p><ul><li><strong>_Required </strong>— where all admin, system, and access transparency <strong>audit logs</strong> go. These logs are retained for 400 days. The _Required log bucket cannot be modified or deleted.</li><li><strong>_Default </strong>—all logs go here, unless they are are sent to _Required or user-defined sinks. By default, retention is 30 days, but it can be increased to 3650 days (10 years). The _Default bucket cannot be deleted, but the sink can be disabled.</li></ul><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/0*dUjAw5dmLhwyPJ8s" /><figcaption>Routing to log sinks</figcaption></figure><p>Note that it is possible export logs using a sink, whilst also EXCLUDING logs from being ingested in Cloud Logging buckets. This is very useful for managing logging costs.</p><p><strong>We can aggregate logging to folder, or even organisational sinks</strong>. This logging aggregation works by including logs from child resources. We do this by creating an aggregated sink at folder or org level, and setting the includeChildren parameter to True. Then we select the destination for the sink, just like any other sink.</p><p>(When doing this, it is wise to add an exclusion filter to the _Defaultsink, so that logs are not retained in both sinks.)</p><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/0*6m9WRUCCmclDayVj" /><figcaption>Logging aggregation</figcaption></figure><p>It is a good idea to aggregate logs from across the organisation into a few logging buckets. Consider subdividing these buckets based on properties such as:</p><ul><li>Retention period</li><li>User access requirements</li><li>Data residency requirements</li><li>Where you may need to use customer-managed encryption keys.</li></ul><p>We can then use Log views and IAM bindings to determine who can see the logs.</p><h4>Audit Logs</h4><p>Most Google Cloud services create audit logs. <strong>They are intended to answer the question of: <em>“Who did what, where, and when?” </em></strong>These are incredibly important for compliance in regulated industries.</p><p>There are five categories of audit logs:</p><figure><img alt="" src="https://cdn-images-1.medium.com/max/789/1*Q9VSfFfNwSbVHJNacC0UBA.png" /><figcaption>Google Cloud audit logs</figcaption></figure><ul><li>The <strong>Admin logs</strong> are always enabled, retained for 400 days, and have no charge. They record any API calls that modify the configuration of resources, such as creating networks, creating or modifying instances, etc.</li><li>The <strong>System Event</strong> logs are always enabled, retained for 400 days, and have no charge. They record activities that modify the configuration of resources, but which occur due to Google-initiated events, rather than direct user interactions. For example, live migrations.</li><li>The <strong>Data Access logs</strong> are disabled by default, and chargeable. They are useful for identifying costly data queries.</li><li>The <strong>Policy Denied logs</strong> are enabled by default, but can be disabled. They are chargeable.</li><li><strong>Access transparency logs</strong> give visibility of any actions performed by Googel staff. For example, as part of an open incident with Google.</li></ul><h4>Network Logs</h4><p><strong>VPC flow logs allow you to record samples of network flows sent or received by VM instances, including GKE nodes. </strong>These logs are useful for diagnosing network issues, network and security analytics, and forensics. They are disabled by default, but can be enabled on a per-VPC subnet basis.</p><p>Logging volumes can be significant, so it’s important to optimise the aggregation interval and sampling rate.</p><figure><img alt="" src="https://cdn-images-1.medium.com/max/655/0*2EfSemOhFN9WD1Ru" /><figcaption>Configuring VPC Flow logs</figcaption></figure><p><strong>Cloud Firewall Rules Logging</strong> can be used to answer questions like:</p><blockquote>“How many connections match this rule?”<br>“Did this rule cause my application outage?”<br>“Is this rule incorrectly stopping traffic?”</blockquote><p>Like VPC Flow logs, Firewall Rule Logging is disabled by default. It can be enabled on a per-rule basis. E.g.</p><pre>gcloud compute firewall-rules update &lt;rule-name&gt; --enable-logging</pre><p>And as with VPC Flow logs, this can result in a lot of logging, and it can get expensive quickly. A common strategy is to NOT enable rules logging by default, but to only turn on rules logging when diagnosing issues. And you can always start by creating a <em>low priority</em> allow-all rule, to verify that the traffic is hitting the firewall in the first place.</p><p>Also worth mentioning: we can use <strong>Cloud NAT logs</strong> to capture connections created and packets dropped by Cloud NAT.</p><h4>Summary of Cloud Logging Decision Points</h4><ul><li><strong>Will you use Google Cloud Logging only, or do you need to export logs to downstream systems, like Splunk?</strong> Some organisations use Splunk for SIEM, so you may have a requirement to export audit logs to Splunk. But be careful not to do this for ALL logs, since Splunk is extremely expensive when working with large volumes of logs.</li><li>What are log <strong>compliance, data residency, and retention requirements</strong>?</li><li><strong>Which logs will you exclude?</strong></li><li>Will you <strong>enable VPC flow logs?</strong> If so, what sampling rate?</li><li>Will you <strong>archive logs</strong> for long-term storage? Will you use GCS lifecycle management to automate this?</li><li>Will you <strong>export logs to BigQuery</strong> for analytics?</li><li>Which <strong>aggregated log sinks</strong> will you define?</li><li><strong>Who will be given access to logs?</strong> Who will be given access to aggregated logs?</li><li><strong>When writing logs from applications, what standards will you follow?</strong> A good practice is to write structured JSON log entries, since these can then be easily parsed and filtered.</li><li>Will we implement a mechanism to dynamically enable logging for troubleshooting?</li></ul><h3>11. Billing Management, Billing Exports, and Labelling</h3><p>One of the big advantages of cloud is that it makes your costs visible and transparent. It’s easy to see how much you’re paying, what you’re paying for, and who’s using the resources that you’re paying for. But to do this effectively, a bit of planning is required.</p><p><strong>Google Cloud accumulates costs at the project level</strong>. I.e. every resource belongs to a project. Furthermore, <strong>projects are associated with one and only one billing account</strong>. This is how your organisation actually gets billed by Google.</p><p>A project <em>must </em>be associated with a billing account, in order to consume any chargeable services. A billing account can be associated with many projects. Some organisations — typically Google resellers — will have billing sub-accounts, which can be used to aggregate billing for specific clients.</p><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/0*o8wlVb62rCLnk4ok.png" /><figcaption>Billing hierarchy</figcaption></figure><h4>Some Roles to Care About</h4><p>The <strong>Billing Account Admin</strong> role is typically given to individuals with financial responsibility. They will be able to:</p><ul><li>Link and unlink billing accounts to projects.</li><li>Enable billing exports.</li><li>View spend and costs.</li><li>Set budgets and alerts.</li></ul><p>The <strong>Billing Account Viewer</strong> can view billing accounts, but can’t make any changes.</p><p>The <strong>Project Billing Manager</strong> can assign a billing account to a project, and disable billing of a project. (Though you’d normally automate this.)</p><h4>Billing Visibility</h4><p>The Google Cloud Console includes built-in Billing Reports:</p><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/0*jtzMGJZGGeNTD-ar" /><figcaption>Billing in the Google Console</figcaption></figure><p>This information can be filtered based on properties such as project, date, and products.</p><figure><img alt="" src="https://cdn-images-1.medium.com/max/577/0*stN9KLwKvRD0ems6" /></figure><p>A really useful feature is the ability to view cost trends:</p><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/0*bxkRUqpZ1APVqmkj" /><figcaption>Cost trends in the Billing Report</figcaption></figure><p>We can also export this billing data into BigQuery, which allows for much more sophisticated analysis. Not only can we then query the data using SQL, but we can then easily visualise and analyse the data using tools like Google Looker Studio.</p><h4>Labelling</h4><p>Labelling (not to be confused with network tags) is incredibly important!! They are key-value pairs which we can assign to any Google Cloud project or resource.</p><p>We can then use these labels to help us analyse our consumption and billing data. For example, we can run something like this in BigQuery:</p><pre>SELECT <br>  project.labels.key, <br>  project.labels.value, <br>  sum(cost) as cost_total, <br>  sum(usage.amount) as usage_total<br>FROM billing_table<br>WHERE <br>  Start_Time &gt;= &#39;2024-02-01 00:00:00&#39; AND Start_Time &lt; &#39;2024-03-01 00:00:00&#39;<br>GROUP BY <br>  project.labels.key, <br>  project.labels.value</pre><p>Consequently, it’s a good idea to come up with a labelling strategy and label naming standards. Wherever possible, we should set labels in an automated fashion, when we create resources using infrastructure-as-code.</p><p>We can define any labels we want. But here are some suggestions:</p><ul><li>Team / cost centre — e.g. “team:research”</li><li>Environment — e.g. “environment:staging”</li><li>Component — e.g. “component:fe”</li><li>State — e.g. “state:pending-deletion”</li><li>Shared resource — e.g. “shared:true”. This can be useful for identifying projects that are used by many tenants, and for subsequently attributing costs.</li></ul><h4>Key Design Considerations</h4><ul><li><strong>What organisational changes do you need to make</strong>, in order to take advantage of consumption-based (pay-as-you-go) resources, and to drive cost-savvy decisions?</li><li><strong>How many billing accounts do we need?</strong></li><li><strong>Who will be given the Billing Administrator role? </strong>(Note that Org Admins do not have Billing Admin by default, but they can grant this role to others, and to themselves.)</li><li><strong>Who will be Billing Viewers?</strong></li><li><strong>How will projects be linked with billing accounts? Using IaC?</strong></li><li>Will we <strong>export billing data to BigQuery?</strong></li><li><strong>What is our labelling strategy? What are our label naming standards?</strong></li></ul><p>By the way, I’ve intentionally steered clear of FinOps. I’ll be covering that in a later article in this series.</p><h3>Wrap-Up</h3><p>Here we’ve covered the key LZ design considerations for monitoring, logging, and billing. In the next part, we’ll cover the last major LZ design consideration topic: infra-as-code (IaC) and GitOps.</p><h3>Before You Go</h3><ul><li><strong>Please share</strong> this with anyone that you think will be interested. It might help them, and it really helps me!</li><li>Feel free to <strong>leave a comment</strong> 💬.</li><li><strong>Follow</strong> and <strong>subscribe, </strong>so you don’t miss my content. Go to my <a href="https://medium.com/@derailed.dash">Profile Page</a>, and click on these icons:</li></ul><figure><img alt="" src="https://cdn-images-1.medium.com/max/163/0*fF62z2-FT03ui0O5.png" /><figcaption>Follow and Subscribe</figcaption></figure><h3>Links</h3><ul><li><a href="https://medium.com/google-cloud/landing-zones-on-google-cloud-b42b08e1abaa">Landing Zones on Google Cloud: What It Is, Why You Need One, and How to Create One</a></li><li><a href="https://cloud.google.com/architecture/landing-zones">Landing zone design in Google Cloud</a></li><li><a href="https://medium.com/@derailed.dash/google-cloud-adoption-site-reliability-engineering-sre-and-best-practices-for-sli-slo-sla-6670c864c96b">Google Cloud Adoption: SRE and Best Practices for SLI / SLO / SLA</a></li><li><a href="https://cloud.google.com/stackdriver/docs">Observability in Google Cloud</a></li><li><a href="https://cloud.google.com/architecture/framework/operational-excellence/set-up-monitoring-alerting-logging">Setup monitoring, alerting and logging</a></li><li><a href="https://cloud.google.com/monitoring/docs">Google Cloud Monitoring</a></li><li><a href="https://cloud.google.com/blog/products/management-tools/use-bluemedoras-bindplane-with-google-cloud">Blue Medora BindPlane</a></li><li><a href="https://cloud.google.com/logging/docs/overview">Google Cloud Logging</a></li><li><a href="https://cloud.google.com/billing/docs/concepts">Cloud Billing Overview</a></li><li><a href="https://www.google.com/url?q=https://cloud.google.com/billing/docs/how-to/export-data-bigquery&amp;sa=D&amp;source=docs&amp;ust=1711378716658242&amp;usg=AOvVaw0qPvb7L1IfJwwK_2In8wjl">Export Cloud Billing Data to BigQuery</a></li><li><a href="https://cloud.google.com/billing/docs/how-to/bq-examples">Example queries for Cloud Billing data export</a></li><li><a href="https://cloud.google.com/architecture/framework">Google Cloud Architecture Framework</a></li><li><a href="https://cloud.google.com/architecture/security-foundations">Enterprise Foundations Blueprint</a></li></ul><h3>Series Navigation</h3><ul><li><a href="https://medium.com/google-cloud/google-cloud-adoption-for-the-enterprise-from-strategy-to-operation-part-0-overview-9091f5a1ddfc">Series overview and structure</a></li><li>Previous: <a href="https://medium.com/google-cloud/design-your-landing-zone-design-considerations-part-2-kubernetes-and-gke-google-cloud-5a500384cb03">Design your Landing Zone — Design Considerations Part 2: Kubernetes</a></li><li>Next: Design your Landing Zone — Design Considerations Part 4: IaC, GitOps and CI/CD</li></ul><img src="https://medium.com/_/stat?event=post.clientViewed&referrerSource=full_rss&postId=7b40189a3c81" width="1" height="1" alt=""><hr><p><a href="https://medium.com/google-cloud/design-your-landing-zone-design-considerations-part-3-monitoring-logging-billing-and-7b40189a3c81">Design your Landing Zone — Design Considerations Part 3 — Monitoring, Logging, Billing and…</a> was originally published in <a href="https://medium.com/google-cloud">Google Cloud - Community</a> on Medium, where people are continuing the conversation by highlighting and responding to this story.</p>]]></content:encoded>
        </item>
    </channel>
</rss>