# [NewsFiler v2] NewsPaper: Guillaume Laforge - Medium (this should go in the Entries as of v2)
# [NewsFiler v2] GUID: https://medium.com/p/1585c044d28d
# [NewsFiler v2] entries.keys: ["title", "url", "author", "categories", "published", "entry_id", "content"]
--- !ruby/object:Feedjira::Parser::RSSEntry
title: Gemini Function Calling
url: https://medium.com/google-cloud/gemini-function-calling-1585c044d28d?source=rss-431147437aeb------2
author: Guillaume Laforge
categories:
- java
- gcp-app-dev
- google-cloud-platform
- vertex-ai
- gemini
published: 2023-12-22 00:00:37.000000000 Z
entry_id: !ruby/object:Feedjira::Parser::GloballyUniqueIdentifier
  is_perma_link: 'false'
  guid: https://medium.com/p/1585c044d28d
carlessian_info:
  news_filer_version: 2
  newspaper: Guillaume Laforge - Medium
  macro_region: Blogs
rss_fields:
- title
- url
- author
- categories
- published
- entry_id
- content
content: '<figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/1*yW4nG0dXoxO1tsdaOYzWuA.png"
  /></figure><p>A promising feature of the Gemini large language model released recently
  by <a href="https://deepmind.google/">Google DeepMind</a>, is the support for <a
  href="https://ai.google.dev/docs/function_calling">function calls</a>. It’s a way
  to supllement the model, by letting it know an external functions or APIs can be
  called. So you’re not limited by the knowledge cut-off of the model: instead, in
  the flow of the conversation with the model, you can pass a list of functions the
  model will know are available to get the information it needs, to complete the generation
  of its answer.</p><p>For example, if you want to ask the model about the weather,
  it doesn’t have the realtime information about the weather forecast. But we can
  tell it that there’s a function that can be called, to get the forecast for a given
  location. Internally, the model will acknowledge it doesn’t know the answer about
  the weather, but it will request that you call an external function that you describe,
  using a specific set of parameters which correspond to the user’s request.</p><p>Just
  days ago, I wrote about how to <a href="https://glaforge.dev/posts/2023/12/13/get-started-with-gemini-in-java/">get
  started with Gemini in Java</a>. In that article, we explored how to use the hand-written
  Java SDK that is available to interact with Gemini from Java. However, the Java
  SDK doesn’t yet expose all the features of the model: in particular, function calling
  is missing. But not all hope is lost! Because under the hood, the SDK relies on
  the generated protobuf classes library, which exposes everything!</p><blockquote><em>Soon,
  Gemini will be supported by </em><a href="https://github.com/langchain4j/langchain4j"><em>LangChain4j</em></a><em>,
  and the Java SDK will also provide an easier way to take care of function calling.
  But in this article, I wanted to explore the use of the internal protobuf classes,
  to see how to best implement its support in the SDK.</em></blockquote><p>Let’s go
  step by step!</p><p>Instead of using the GenerativeModel API from the SDK, we&#39;ll
  go straight with the PredictionServiceClient:</p><pre>try (VertexAI vertexAI = new
  VertexAI(projectId, location)) {<br>  PredictionServiceClient client = vertexAI.getPredictionServiceClient();<br>  ...<br>}</pre><p>We
  need to prepare a function declaration to describe the kind of functions that the
  LLM can ask us to call, and we’ll wrap it in a Tool:</p><pre>FunctionDeclaration
  functionDeclaration = FunctionDeclaration.newBuilder()<br>    .setName(&quot;getCurrentWeather&quot;)<br>    .setDescription(&quot;Get
  the current weather in a given location&quot;)<br>    .setParameters(<br>        Schema.newBuilder()<br>            .setType(Type.OBJECT)<br>            .putProperties(&quot;location&quot;,
  Schema.newBuilder()<br>                .setType(Type.STRING)<br>                .setDescription(&quot;location&quot;)<br>                .build()<br>            )<br>            .addRequired(&quot;location&quot;)<br>            .build()<br>    )<br>    .build();<br><br>Tool
  tool = Tool.newBuilder()<br>    .addFunctionDeclarations(functionDeclaration)<br>    .build();</pre><p>Functions
  are described using classes that represent a subset of the OpenAPI 3 specification.</p><blockquote><em>This
  is important to provide descriptions for the functions and its parameters, as the
  LLM will use that information to figure out which function to call, and which parameters
  should be passed.</em></blockquote><p>Next, let’s prepare a question asking about
  the weather in Paris, and configuring the text generation request with that prompt
  and the tool defined above:</p><pre>String resourceName = String.format(<br>    &quot;projects/%s/locations/%s/publishers/google/models/%s&quot;,<br>    vertexAI.getProjectId(),
  vertexAI.getLocation(), modelName);<br><br>Content questionContent =<br>    ContentMaker.fromString(&quot;What&#39;s
  the weather in Paris?&quot;);<br><br>GenerateContentRequest questionContentRequest
  =<br>    GenerateContentRequest.newBuilder()<br>        .setEndpoint(resourceName)<br>        .setModel(resourceName)<br>        .addTools(tool)<br>        .addContents(questionContent)<br>        .build();<br><br>ResponseStream&lt;GenerateContentResponse&gt;
  responseStream =<br>    new ResponseStream&lt;&gt;(new ResponseStreamIteratorWithHistory&lt;&gt;(<br>        client<br>            .streamGenerateContentCallable()<br>            .call(questionContentRequest)<br>            .iterator())<br>);<br><br>GenerateContentResponse
  generateContentResponse =<br>    responseStream.stream().findFirst().get();<br>Content
  callResponseContent =<br>    generateContentResponse.getCandidates(0).getContent();</pre><p>If
  you print the callResponseContent variable, you&#39;ll see that it contains a function
  call request, suggesting that you should call the predefined function with the parameter
  of Paris:</p><pre>role: &quot;model&quot;<br>parts {<br>  function_call {<br>    name:
  &quot;getCurrentWeather&quot;<br>    args {<br>      fields {<br>        key: &quot;location&quot;<br>        value
  {<br>          string_value: &quot;Paris&quot;<br>        }<br>      }<br>    }<br>  }<br>}</pre><p>At
  that point, as the developer, it’s your turn to work a little, and make the call
  to that function yourself! Let’s pretend I called an external Web Service that gives
  weather information, and that it returns some JSON payload that would look like so:</p><pre>{<br>  &quot;weather&quot;:
  &quot;sunny&quot;,<br>  &quot;location&quot;: &quot;Paris&quot;<br>}</pre><p>We
  need now to create a function response structure to pass that information back to
  the LLM:</p><pre>Content contentFnResp = Content.newBuilder()<br>    .addParts(Part.newBuilder()<br>        .setFunctionResponse(<br>            FunctionResponse.newBuilder()<br>                .setResponse(<br>                    Struct.newBuilder()<br>                        .putFields(&quot;weather&quot;,<br>                            Value.newBuilder().setStringValue(&quot;sunny&quot;).build())<br>                        .putFields(&quot;location&quot;,<br>                            Value.newBuilder().setStringValue(&quot;Paris&quot;).build())<br>                        .build()<br>                )<br>                .build()<br>        )<br>        .build())<br>    .build();</pre><p>Then,
  since LLMs are actually stateless beasts, we need to give it the whole context of
  the conversation again, passing the query, the function call response the model
  suggested us to make, as well as the response we got from the external weather service:</p><pre>GenerateContentRequest
  generateContentRequest = GenerateContentRequest.newBuilder()<br>    .setEndpoint(resourceName)<br>    .setModel(resourceName)<br>    .addContents(questionContent)<br>    .addContents(callResponseContent)<br>    .addContents(contentFnResp)<br>    .addTools(tool)<br>    .build();</pre><p>And
  to finish, we’ll invoke the client one last time with that whole dialog and information,
  and print a response out:</p><pre>responseStream = new ResponseStream&lt;&gt;(new
  ResponseStreamIteratorWithHistory&lt;&gt;(<br>    client<br>        .streamGenerateContentCallable()<br>        .call(generateContentRequest)<br>        .iterator())<br>);<br><br>for
  (GenerateContentResponse resp : responseStream) {<br>    System.out.println(ResponseHandler.getText(resp));<br>}</pre><p>And
  happily, Gemini will reply to us that:</p><pre>The weather in Paris is sunny.</pre><p>What
  a lovely way to start the holiday season with a nice and sunny weather!</p><p>I
  wish you all happy year end festivities, and I look forward to seeing you next year.
  Hopefully next month, I’ll be able to show you some cool new SDK features or the
  LangChain4j integration! Thanks for reading.</p><p><em>Originally published at </em><a
  href="https://glaforge.dev/posts/2023/12/22/gemini-function-calling/"><em>https://glaforge.dev</em></a><em>
  on December 22, 2023.</em></p><img src="https://medium.com/_/stat?event=post.clientViewed&referrerSource=full_rss&postId=1585c044d28d"
  width="1" height="1" alt=""><hr><p><a href="https://medium.com/google-cloud/gemini-function-calling-1585c044d28d">Gemini
  Function Calling</a> was originally published in <a href="https://medium.com/google-cloud">Google
  Cloud - Community</a> on Medium, where people are continuing the conversation by
  highlighting and responding to this story.</p>'
